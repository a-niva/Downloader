{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928df514-3be7-4add-a016-877b1602f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall -y yfinance\n",
    "\n",
    "pip install curl_cffi\n",
    "import curl_cffi\n",
    "\n",
    "# Remplacer vos sessions requests par curl_cffi\n",
    "session = curl_cffi.Session(impersonate=\"chrome\", timeout=15)\n",
    "\n",
    "# Puis utiliser cette session avec yfinance\n",
    "data = yf.download(ticker, session=session, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "575ad930-ed5e-4a5f-b4a3-bf9b72cad48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (0.2.59)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from yfinance) (2.1.2)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from yfinance) (2025.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from yfinance) (3.17.9)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from yfinance) (0.10.0)\n",
      "Requirement already satisfied: protobuf<6,>=5.29.0 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from yfinance) (5.29.4)\n",
      "Requirement already satisfied: websockets>=11.0 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from yfinance) (15.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from requests>=2.31->yfinance) (2.3.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade yfinance --no-cache-dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b37a94ff-14ec-4e09-baf0-e72b15fbff63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: curl_cffi in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from curl_cffi) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from curl_cffi) (2025.1.31)\n",
      "Requirement already satisfied: pycparser in c:\\users\\alex\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from cffi>=1.12.0->curl_cffi) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990dd0b9-020c-473c-b385-62d1b4794318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "2025-05-12 19:16:24,281 - PriorityDownloader - INFO - Starting download with quotas: 10000 total batches\n",
      "2025-05-12 19:16:24,283 - PriorityDownloader - INFO - Prioritized 2 tickers for interval 15m\n",
      "2025-05-12 19:16:24,284 - PriorityDownloader - INFO - Found 2 tickers to update for interval 15m\n",
      "2025-05-12 19:16:24,287 - PriorityDownloader - INFO - Prioritized 573 tickers for interval 1h\n",
      "2025-05-12 19:16:24,288 - PriorityDownloader - INFO - Found 573 tickers to update for interval 1h\n",
      "2025-05-12 19:16:24,291 - PriorityDownloader - INFO - Prioritized 1540 tickers for interval 1d\n",
      "2025-05-12 19:16:24,291 - PriorityDownloader - INFO - Found 1540 tickers to update for interval 1d\n",
      "2025-05-12 19:16:24,294 - PriorityDownloader - INFO - Prioritized 1540 tickers for interval 1m\n",
      "2025-05-12 19:16:24,295 - PriorityDownloader - INFO - Found 1540 tickers to update for interval 1m\n",
      "2025-05-12 19:16:24,299 - PriorityDownloader - INFO - Prioritized 1540 tickers for interval 5m\n",
      "2025-05-12 19:16:24,299 - PriorityDownloader - INFO - Found 1540 tickers to update for interval 5m\n",
      "2025-05-12 19:16:24,303 - PriorityDownloader - INFO - Prioritized 1540 tickers for interval 30m\n",
      "2025-05-12 19:16:24,304 - PriorityDownloader - INFO - Found 1540 tickers to update for interval 30m\n",
      "2025-05-12 19:16:24,304 - PriorityDownloader - INFO - Assigned quotas: {'15m': 2, '1h': 850, '1d': 2286, '1m': 2286, '5m': 2286, '30m': 2286}\n",
      "2025-05-12 19:16:24,305 - PriorityDownloader - INFO - Processing 2 tickers for interval 15m (quota: 2 batches)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données sauvegardées dans RISK_FREE_TICKER.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 19:16:24,311 - StockDownloader - INFO - Downloading 2 tickers for interval 15m\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "2025-05-12 19:16:24,531 - StockDownloader - WARNING - No data found for  (interval 15m)\n",
      "2025-05-12 19:16:25,325 - PriorityDownloader - INFO - Added 5 new rows for 0DYZ.IL (15m)\n",
      "Downloading 15m: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]\n",
      "2025-05-12 19:16:34,338 - PriorityDownloader - INFO - Processing 573 tickers for interval 1h (quota: 850 batches)\n",
      "2025-05-12 19:16:34,339 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  29 of 29 completed\n",
      "2025-05-12 19:16:35,606 - yfinance - ERROR - \n",
      "13 Failed downloads:\n",
      "2025-05-12 19:16:35,607 - yfinance - ERROR - ['0MPY.IL']: YFPricesMissingError('possibly delisted; no price data found  (period=730d) (Yahoo error = \"1h data not available for startTime=1682665200 and endTime=1747070196. The requested range must be within the last 730 days.\")')\n",
      "2025-05-12 19:16:35,607 - yfinance - ERROR - ['GGLL', 'MSFU']: YFPricesMissingError('possibly delisted; no price data found  (period=730d) (Yahoo error = \"1h data not available for startTime=1662557400 and endTime=1747070196. The requested range must be within the last 730 days.\")')\n",
      "2025-05-12 19:16:35,607 - yfinance - ERROR - ['RSHO']: YFPricesMissingError('possibly delisted; no price data found  (period=730d) (Yahoo error = \"1h data not available for startTime=1683811800 and endTime=1747070196. The requested range must be within the last 730 days.\")')\n",
      "2025-05-12 19:16:35,608 - yfinance - ERROR - ['V3SU.L']: YFPricesMissingError('possibly delisted; no price data found  (period=730d) (Yahoo error = \"1h data not available for startTime=1668499200 and endTime=1747070196. The requested range must be within the last 730 days.\")')\n",
      "2025-05-12 19:16:35,608 - yfinance - ERROR - ['WNDI.L']: YFPricesMissingError('possibly delisted; no price data found  (period=730d) (Yahoo error = \"1h data not available for startTime=1663052400 and endTime=1747070196. The requested range must be within the last 730 days.\")')\n",
      "2025-05-12 19:16:35,608 - yfinance - ERROR - ['DFLV']: YFPricesMissingError('possibly delisted; no price data found  (period=730d) (Yahoo error = \"1h data not available for startTime=1670423400 and endTime=1747070196. The requested range must be within the last 730 days.\")')\n",
      "2025-05-12 19:16:35,609 - yfinance - ERROR - ['MAGS']: YFPricesMissingError('possibly delisted; no price data found  (period=730d) (Yahoo error = \"1h data not available for startTime=1681219800 and endTime=1747070196. The requested range must be within the last 730 days.\")')\n",
      "2025-05-12 19:16:35,609 - yfinance - ERROR - ['TBIL']: YFPricesMissingError('possibly delisted; no price data found  (period=730d) (Yahoo error = \"1h data not available for startTime=1660051800 and endTime=1747070196. The requested range must be within the last 730 days.\")')\n",
      "2025-05-12 19:16:35,610 - yfinance - ERROR - ['CLOZ']: YFPricesMissingError('possibly delisted; no price data found  (period=730d) (Yahoo error = \"1h data not available for startTime=1674570600 and endTime=1747070197. The requested range must be within the last 730 days.\")')\n",
      "2025-05-12 19:16:35,610 - yfinance - ERROR - ['AAPU']: YFPricesMissingError('possibly delisted; no price data found  (period=730d) (Yahoo error = \"1h data not available for startTime=1660051800 and endTime=1747070197. The requested range must be within the last 730 days.\")')\n",
      "2025-05-12 19:16:35,611 - yfinance - ERROR - ['EWSP.L']: YFPricesMissingError('possibly delisted; no price data found  (period=730d) (Yahoo error = \"1h data not available for startTime=1659423600 and endTime=1747070197. The requested range must be within the last 730 days.\")')\n",
      "2025-05-12 19:16:35,611 - yfinance - ERROR - ['PPWLM']: YFPricesMissingError('possibly delisted; no price data found  (period=730d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "2025-05-12 19:16:35,878 - StockDownloader - WARNING - Empty data for PPWLM (interval 1h)\n",
      "2025-05-12 19:16:35,913 - StockDownloader - WARNING - Empty data for EWSP.L (interval 1h)\n",
      "2025-05-12 19:16:35,949 - StockDownloader - WARNING - Empty data for WNDI.L (interval 1h)\n",
      "2025-05-12 19:16:35,984 - StockDownloader - WARNING - Empty data for V3SU.L (interval 1h)\n",
      "2025-05-12 19:16:36,018 - StockDownloader - WARNING - Empty data for GGLL (interval 1h)\n",
      "2025-05-12 19:16:36,054 - StockDownloader - WARNING - Empty data for MAGS (interval 1h)\n",
      "2025-05-12 19:16:36,089 - StockDownloader - WARNING - Empty data for RSHO (interval 1h)\n",
      "2025-05-12 19:16:36,126 - StockDownloader - WARNING - Empty data for CLOZ (interval 1h)\n",
      "2025-05-12 19:16:36,165 - StockDownloader - WARNING - Empty data for TBIL (interval 1h)\n",
      "2025-05-12 19:16:36,198 - StockDownloader - WARNING - Empty data for MSFU (interval 1h)\n",
      "2025-05-12 19:16:36,233 - StockDownloader - WARNING - Empty data for AAPU (interval 1h)\n",
      "2025-05-12 19:16:36,302 - StockDownloader - WARNING - Empty data for DFLV (interval 1h)\n",
      "2025-05-12 19:16:36,335 - StockDownloader - WARNING - No data found for  (interval 1h)\n",
      "2025-05-12 19:16:36,370 - StockDownloader - WARNING - Empty data for 0MPY.IL (interval 1h)\n",
      "2025-05-12 19:16:36,661 - PriorityDownloader - INFO - Added 53 new rows for MBB (1h)\n",
      "2025-05-12 19:16:36,728 - PriorityDownloader - INFO - Added 53 new rows for IEI (1h)\n",
      "2025-05-12 19:16:40,110 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:16:45,915 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:16:51,552 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:16:53,461 - PriorityDownloader - INFO - Added 53 new rows for IR (1h)\n",
      "2025-05-12 19:16:53,492 - PriorityDownloader - INFO - Added 3662 new rows for IRM (1h)\n",
      "2025-05-12 19:16:53,567 - PriorityDownloader - INFO - Added 53 new rows for ITW (1h)\n",
      "2025-05-12 19:16:53,601 - PriorityDownloader - INFO - Added 53 new rows for IVZ (1h)\n",
      "2025-05-12 19:16:53,638 - PriorityDownloader - INFO - Added 53 new rows for JBHT (1h)\n",
      "2025-05-12 19:16:53,709 - PriorityDownloader - INFO - Added 53 new rows for JCI (1h)\n",
      "2025-05-12 19:16:53,743 - PriorityDownloader - INFO - Added 53 new rows for J (1h)\n",
      "2025-05-12 19:16:53,781 - PriorityDownloader - INFO - Added 53 new rows for JKHY (1h)\n",
      "2025-05-12 19:16:53,818 - PriorityDownloader - INFO - Added 53 new rows for JNPR (1h)\n",
      "2025-05-12 19:16:53,851 - PriorityDownloader - INFO - Added 53 new rows for JWN (1h)\n",
      "2025-05-12 19:16:53,906 - PriorityDownloader - INFO - Added 53 new rows for K (1h)\n",
      "2025-05-12 19:16:53,940 - PriorityDownloader - INFO - Added 53 new rows for KEY (1h)\n",
      "2025-05-12 19:16:53,979 - PriorityDownloader - INFO - Added 53 new rows for KEYS (1h)\n",
      "2025-05-12 19:16:54,012 - PriorityDownloader - INFO - Added 53 new rows for KHC (1h)\n",
      "2025-05-12 19:16:54,045 - PriorityDownloader - INFO - Added 53 new rows for KIM (1h)\n",
      "2025-05-12 19:16:54,079 - PriorityDownloader - INFO - Added 53 new rows for KMB (1h)\n",
      "2025-05-12 19:16:54,110 - PriorityDownloader - INFO - Added 53 new rows for KMI (1h)\n",
      "2025-05-12 19:16:54,146 - PriorityDownloader - INFO - Added 53 new rows for KMX (1h)\n",
      "2025-05-12 19:16:54,231 - PriorityDownloader - INFO - Added 53 new rows for KR (1h)\n",
      "2025-05-12 19:16:54,263 - PriorityDownloader - INFO - Added 53 new rows for KSS (1h)\n",
      "2025-05-12 19:16:54,300 - PriorityDownloader - INFO - Added 53 new rows for L (1h)\n",
      "2025-05-12 19:16:57,324 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:17:00,042 - PriorityDownloader - INFO - Added 53 new rows for LB (1h)\n",
      "2025-05-12 19:17:00,065 - PriorityDownloader - INFO - Added 53 new rows for LDOS (1h)\n",
      "2025-05-12 19:17:00,099 - PriorityDownloader - INFO - Added 53 new rows for LEG (1h)\n",
      "2025-05-12 19:17:00,136 - PriorityDownloader - INFO - Added 53 new rows for LEN (1h)\n",
      "2025-05-12 19:17:00,206 - PriorityDownloader - INFO - Added 53 new rows for LH (1h)\n",
      "2025-05-12 19:17:00,238 - PriorityDownloader - INFO - Added 53 new rows for LHX (1h)\n",
      "2025-05-12 19:17:00,271 - PriorityDownloader - INFO - Added 53 new rows for LIN (1h)\n",
      "2025-05-12 19:17:00,306 - PriorityDownloader - INFO - Added 53 new rows for LKQ (1h)\n",
      "2025-05-12 19:17:00,340 - PriorityDownloader - INFO - Added 53 new rows for LMT (1h)\n",
      "2025-05-12 19:17:00,383 - PriorityDownloader - INFO - Added 53 new rows for LNC (1h)\n",
      "2025-05-12 19:17:00,440 - PriorityDownloader - INFO - Added 53 new rows for LNT (1h)\n",
      "2025-05-12 19:17:00,476 - PriorityDownloader - INFO - Added 53 new rows for LOW (1h)\n",
      "2025-05-12 19:17:00,512 - PriorityDownloader - INFO - Added 53 new rows for LUV (1h)\n",
      "2025-05-12 19:17:00,551 - PriorityDownloader - INFO - Added 53 new rows for LW (1h)\n",
      "2025-05-12 19:17:00,586 - PriorityDownloader - INFO - Added 53 new rows for LYB (1h)\n",
      "2025-05-12 19:17:00,622 - PriorityDownloader - INFO - Added 53 new rows for M (1h)\n",
      "2025-05-12 19:17:00,705 - PriorityDownloader - INFO - Added 53 new rows for MAA (1h)\n",
      "2025-05-12 19:17:00,740 - PriorityDownloader - INFO - Added 53 new rows for MAC (1h)\n",
      "2025-05-12 19:17:00,774 - PriorityDownloader - INFO - Added 53 new rows for MAR (1h)\n",
      "2025-05-12 19:17:00,809 - PriorityDownloader - INFO - Added 53 new rows for MAS (1h)\n",
      "2025-05-12 19:17:00,851 - PriorityDownloader - INFO - Added 53 new rows for MCD (1h)\n",
      "2025-05-12 19:17:00,904 - PriorityDownloader - INFO - Added 53 new rows for MCHP (1h)\n",
      "2025-05-12 19:17:00,939 - PriorityDownloader - INFO - Added 53 new rows for MCK (1h)\n",
      "2025-05-12 19:17:00,994 - PriorityDownloader - INFO - Added 53 new rows for MCO (1h)\n",
      "2025-05-12 19:17:01,053 - PriorityDownloader - INFO - Added 53 new rows for MET (1h)\n",
      "2025-05-12 19:17:01,086 - PriorityDownloader - INFO - Added 53 new rows for MGM (1h)\n",
      "2025-05-12 19:17:01,118 - PriorityDownloader - INFO - Added 53 new rows for MHK (1h)\n",
      "2025-05-12 19:17:01,155 - PriorityDownloader - INFO - Added 53 new rows for MKC (1h)\n",
      "2025-05-12 19:17:01,191 - PriorityDownloader - INFO - Added 53 new rows for MKTX (1h)\n",
      "2025-05-12 19:17:01,271 - PriorityDownloader - INFO - Added 53 new rows for MLM (1h)\n",
      "2025-05-12 19:17:04,296 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:17:05,857 - PriorityDownloader - INFO - Added 53 new rows for MMC (1h)\n",
      "2025-05-12 19:17:05,889 - PriorityDownloader - INFO - Added 53 new rows for MMM (1h)\n",
      "2025-05-12 19:17:05,924 - PriorityDownloader - INFO - Added 53 new rows for MNST (1h)\n",
      "2025-05-12 19:17:05,960 - PriorityDownloader - INFO - Added 53 new rows for MO (1h)\n",
      "2025-05-12 19:17:06,031 - PriorityDownloader - INFO - Added 53 new rows for MOS (1h)\n",
      "2025-05-12 19:17:06,087 - PriorityDownloader - INFO - Added 53 new rows for MU (1h)\n",
      "2025-05-12 19:17:06,121 - PriorityDownloader - INFO - Added 53 new rows for NAVI (1h)\n",
      "2025-05-12 19:17:06,155 - PriorityDownloader - INFO - Added 53 new rows for NCLH (1h)\n",
      "2025-05-12 19:17:06,190 - PriorityDownloader - INFO - Added 53 new rows for NDAQ (1h)\n",
      "2025-05-12 19:17:06,224 - PriorityDownloader - INFO - Added 53 new rows for NEE (1h)\n",
      "2025-05-12 19:17:06,259 - PriorityDownloader - INFO - Added 53 new rows for MPC (1h)\n",
      "2025-05-12 19:17:06,296 - PriorityDownloader - INFO - Added 53 new rows for MSCI (1h)\n",
      "2025-05-12 19:17:06,333 - PriorityDownloader - INFO - Added 53 new rows for MSI (1h)\n",
      "2025-05-12 19:17:06,369 - PriorityDownloader - INFO - Added 53 new rows for MTB (1h)\n",
      "2025-05-12 19:17:06,414 - PriorityDownloader - INFO - Added 53 new rows for MTD (1h)\n",
      "2025-05-12 19:17:06,450 - PriorityDownloader - INFO - Added 53 new rows for NEM (1h)\n",
      "2025-05-12 19:17:06,486 - PriorityDownloader - INFO - Added 53 new rows for NI (1h)\n",
      "2025-05-12 19:17:06,571 - PriorityDownloader - INFO - Added 53 new rows for NOC (1h)\n",
      "2025-05-12 19:17:06,606 - PriorityDownloader - INFO - Added 53 new rows for NOV (1h)\n",
      "2025-05-12 19:17:06,643 - PriorityDownloader - INFO - Added 53 new rows for NRG (1h)\n",
      "2025-05-12 19:17:06,682 - PriorityDownloader - INFO - Added 53 new rows for NSC (1h)\n",
      "2025-05-12 19:17:06,717 - PriorityDownloader - INFO - Added 53 new rows for NTAP (1h)\n",
      "2025-05-12 19:17:06,752 - PriorityDownloader - INFO - Added 53 new rows for NTRS (1h)\n",
      "2025-05-12 19:17:06,788 - PriorityDownloader - INFO - Added 53 new rows for NUE (1h)\n",
      "2025-05-12 19:17:06,824 - PriorityDownloader - INFO - Added 53 new rows for NVR (1h)\n",
      "2025-05-12 19:17:06,858 - PriorityDownloader - INFO - Added 53 new rows for NWL (1h)\n",
      "2025-05-12 19:17:06,892 - PriorityDownloader - INFO - Added 53 new rows for NWS (1h)\n",
      "2025-05-12 19:17:06,928 - PriorityDownloader - INFO - Added 53 new rows for NWSA (1h)\n",
      "2025-05-12 19:17:06,967 - PriorityDownloader - INFO - Added 53 new rows for O (1h)\n",
      "2025-05-12 19:17:07,003 - PriorityDownloader - INFO - Added 53 new rows for ODFL (1h)\n",
      "2025-05-12 19:17:10,034 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:17:11,557 - PriorityDownloader - INFO - Added 53 new rows for OKE (1h)\n",
      "2025-05-12 19:17:11,594 - PriorityDownloader - INFO - Added 53 new rows for OMC (1h)\n",
      "2025-05-12 19:17:11,629 - PriorityDownloader - INFO - Added 53 new rows for ORLY (1h)\n",
      "2025-05-12 19:17:11,666 - PriorityDownloader - INFO - Added 53 new rows for OXY (1h)\n",
      "2025-05-12 19:17:11,700 - PriorityDownloader - INFO - Added 53 new rows for PAYC (1h)\n",
      "2025-05-12 19:17:11,733 - PriorityDownloader - INFO - Added 53 new rows for PAYX (1h)\n",
      "2025-05-12 19:17:11,770 - PriorityDownloader - INFO - Added 53 new rows for PCAR (1h)\n",
      "2025-05-12 19:17:11,847 - PriorityDownloader - INFO - Added 53 new rows for PEG (1h)\n",
      "2025-05-12 19:17:11,883 - PriorityDownloader - INFO - Added 53 new rows for PFG (1h)\n",
      "2025-05-12 19:17:11,917 - PriorityDownloader - INFO - Added 53 new rows for PGR (1h)\n",
      "2025-05-12 19:17:11,962 - PriorityDownloader - INFO - Added 53 new rows for BXP (1h)\n",
      "2025-05-12 19:17:11,998 - PriorityDownloader - INFO - Added 53 new rows for C (1h)\n",
      "2025-05-12 19:17:12,035 - PriorityDownloader - INFO - Added 53 new rows for CAG (1h)\n",
      "2025-05-12 19:17:12,070 - PriorityDownloader - INFO - Added 53 new rows for CAH (1h)\n",
      "2025-05-12 19:17:12,106 - PriorityDownloader - INFO - Added 53 new rows for CAT (1h)\n",
      "2025-05-12 19:17:12,140 - PriorityDownloader - INFO - Added 53 new rows for CB (1h)\n",
      "2025-05-12 19:17:12,177 - PriorityDownloader - INFO - Added 53 new rows for CBOE (1h)\n",
      "2025-05-12 19:17:12,213 - PriorityDownloader - INFO - Added 53 new rows for CBRE (1h)\n",
      "2025-05-12 19:17:12,250 - PriorityDownloader - INFO - Added 53 new rows for CCI (1h)\n",
      "2025-05-12 19:17:12,329 - PriorityDownloader - INFO - Added 53 new rows for CCL (1h)\n",
      "2025-05-12 19:17:12,366 - PriorityDownloader - INFO - Added 53 new rows for CE (1h)\n",
      "2025-05-12 19:17:12,410 - PriorityDownloader - INFO - Added 53 new rows for CF (1h)\n",
      "2025-05-12 19:17:12,446 - PriorityDownloader - INFO - Added 53 new rows for CFG (1h)\n",
      "2025-05-12 19:17:12,483 - PriorityDownloader - INFO - Added 53 new rows for CHD (1h)\n",
      "2025-05-12 19:17:12,527 - PriorityDownloader - INFO - Added 53 new rows for CHRW (1h)\n",
      "2025-05-12 19:17:12,554 - PriorityDownloader - INFO - Added 2 new rows for JCPN.L (1h)\n",
      "2025-05-12 19:17:12,573 - PriorityDownloader - INFO - Added 53 new rows for CHTR (1h)\n",
      "2025-05-12 19:17:12,612 - PriorityDownloader - INFO - Added 53 new rows for CI (1h)\n",
      "2025-05-12 19:17:12,646 - PriorityDownloader - INFO - Added 53 new rows for CINF (1h)\n",
      "2025-05-12 19:17:12,685 - PriorityDownloader - INFO - Added 53 new rows for CL (1h)\n",
      "2025-05-12 19:17:15,706 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:17:17,288 - PriorityDownloader - INFO - Added 53 new rows for CLX (1h)\n",
      "2025-05-12 19:17:17,316 - PriorityDownloader - INFO - Added 31 new rows for COTY.PA (1h)\n",
      "2025-05-12 19:17:17,340 - PriorityDownloader - INFO - Added 63 new rows for AKE.PA (1h)\n",
      "2025-05-12 19:17:17,394 - PriorityDownloader - INFO - Added 63 new rows for AYV.PA (1h)\n",
      "2025-05-12 19:17:17,458 - PriorityDownloader - INFO - Added 63 new rows for RF.PA (1h)\n",
      "2025-05-12 19:17:17,495 - PriorityDownloader - INFO - Added 63 new rows for COV.PA (1h)\n",
      "2025-05-12 19:17:17,534 - PriorityDownloader - INFO - Added 63 new rows for GTT.PA (1h)\n",
      "2025-05-12 19:17:17,573 - PriorityDownloader - INFO - Added 63 new rows for SPIE.PA (1h)\n",
      "2025-05-12 19:17:17,615 - PriorityDownloader - INFO - Added 63 new rows for TEP.PA (1h)\n",
      "2025-05-12 19:17:17,657 - PriorityDownloader - INFO - Added 63 new rows for SK.PA (1h)\n",
      "2025-05-12 19:17:17,696 - PriorityDownloader - INFO - Added 63 new rows for TE.PA (1h)\n",
      "2025-05-12 19:17:17,737 - PriorityDownloader - INFO - Added 63 new rows for ELIS.PA (1h)\n",
      "2025-05-12 19:17:17,776 - PriorityDownloader - INFO - Added 63 new rows for SCR.PA (1h)\n",
      "2025-05-12 19:17:17,815 - PriorityDownloader - INFO - Added 63 new rows for VK.PA (1h)\n",
      "2025-05-12 19:17:17,889 - PriorityDownloader - INFO - Added 63 new rows for NEX.PA (1h)\n",
      "2025-05-12 19:17:17,927 - PriorityDownloader - INFO - Added 63 new rows for MF.PA (1h)\n",
      "2025-05-12 19:17:17,957 - PriorityDownloader - INFO - Added 19 new rows for MLHK.PA (1h)\n",
      "2025-05-12 19:17:17,977 - PriorityDownloader - INFO - Added 63 new rows for TKO.PA (1h)\n",
      "2025-05-12 19:17:18,031 - PriorityDownloader - INFO - Added 24 new rows for FLY.PA (1h)\n",
      "2025-05-12 19:17:18,057 - PriorityDownloader - INFO - Added 63 new rows for SOP.PA (1h)\n",
      "2025-05-12 19:17:18,098 - PriorityDownloader - INFO - Added 63 new rows for DEC.PA (1h)\n",
      "2025-05-12 19:17:18,135 - PriorityDownloader - INFO - Added 63 new rows for PLX.PA (1h)\n",
      "2025-05-12 19:17:18,162 - PriorityDownloader - INFO - Added 63 new rows for ITP.PA (1h)\n",
      "2025-05-12 19:17:18,202 - PriorityDownloader - INFO - Added 63 new rows for VRLA.PA (1h)\n",
      "2025-05-12 19:17:18,273 - PriorityDownloader - INFO - Added 63 new rows for SOI.PA (1h)\n",
      "2025-05-12 19:17:18,311 - PriorityDownloader - INFO - Added 63 new rows for RCO.PA (1h)\n",
      "2025-05-12 19:17:18,347 - PriorityDownloader - INFO - Added 37 new rows for COVH.PA (1h)\n",
      "2025-05-12 19:17:18,376 - PriorityDownloader - INFO - Added 61 new rows for MMB.PA (1h)\n",
      "2025-05-12 19:17:18,411 - PriorityDownloader - INFO - Added 63 new rows for ATE.PA (1h)\n",
      "2025-05-12 19:17:18,444 - PriorityDownloader - INFO - Added 63 new rows for VU.PA (1h)\n",
      "2025-05-12 19:17:21,460 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:17:22,839 - PriorityDownloader - INFO - Added 63 new rows for FR.PA (1h)\n",
      "2025-05-12 19:17:22,948 - PriorityDownloader - INFO - Added 63 new rows for IDL.PA (1h)\n",
      "2025-05-12 19:17:22,982 - PriorityDownloader - INFO - Added 63 new rows for BB.PA (1h)\n",
      "2025-05-12 19:17:23,070 - PriorityDownloader - INFO - Added 63 new rows for RUI.PA (1h)\n",
      "2025-05-12 19:17:23,109 - PriorityDownloader - INFO - Added 63 new rows for VIRP.PA (1h)\n",
      "2025-05-12 19:17:23,147 - PriorityDownloader - INFO - Added 63 new rows for TRI.PA (1h)\n",
      "2025-05-12 19:17:23,185 - PriorityDownloader - INFO - Added 37 new rows for BAIN.PA (1h)\n",
      "2025-05-12 19:17:23,213 - PriorityDownloader - INFO - Added 63 new rows for COFA.PA (1h)\n",
      "2025-05-12 19:17:23,255 - PriorityDownloader - INFO - Added 63 new rows for CARM.PA (1h)\n",
      "2025-05-12 19:17:23,300 - PriorityDownloader - INFO - Added 63 new rows for LOUP.PA (1h)\n",
      "2025-05-12 19:17:23,333 - PriorityDownloader - INFO - Added 63 new rows for VIV.PA (1h)\n",
      "2025-05-12 19:17:23,375 - PriorityDownloader - INFO - Added 63 new rows for NK.PA (1h)\n",
      "2025-05-12 19:17:23,414 - PriorityDownloader - INFO - Added 63 new rows for WLN.PA (1h)\n",
      "2025-05-12 19:17:23,503 - PriorityDownloader - INFO - Added 63 new rows for ALTA.PA (1h)\n",
      "2025-05-12 19:17:23,534 - PriorityDownloader - INFO - Added 5 new rows for UNBL.PA (1h)\n",
      "2025-05-12 19:17:23,555 - PriorityDownloader - INFO - Added 63 new rows for IPS.PA (1h)\n",
      "2025-05-12 19:17:23,593 - PriorityDownloader - INFO - Added 46 new rows for CAF.PA (1h)\n",
      "2025-05-12 19:17:23,627 - PriorityDownloader - INFO - Added 63 new rows for AF.PA (1h)\n",
      "2025-05-12 19:17:23,687 - PriorityDownloader - INFO - Added 63 new rows for PLNW.PA (1h)\n",
      "2025-05-12 19:17:23,706 - PriorityDownloader - INFO - Added 6 new rows for CBE.PA (1h)\n",
      "2025-05-12 19:17:23,728 - PriorityDownloader - INFO - Added 63 new rows for VCT.PA (1h)\n",
      "2025-05-12 19:17:23,767 - PriorityDownloader - INFO - Added 63 new rows for PEUG.PA (1h)\n",
      "2025-05-12 19:17:23,810 - PriorityDownloader - INFO - Added 55 new rows for RBT.PA (1h)\n",
      "2025-05-12 19:17:23,841 - PriorityDownloader - INFO - Added 63 new rows for STF.PA (1h)\n",
      "2025-05-12 19:17:23,880 - PriorityDownloader - INFO - Added 63 new rows for ICAD.PA (1h)\n",
      "2025-05-12 19:17:23,922 - PriorityDownloader - INFO - Added 63 new rows for SESG.PA (1h)\n",
      "2025-05-12 19:17:23,958 - PriorityDownloader - INFO - Added 63 new rows for OPM.PA (1h)\n",
      "2025-05-12 19:17:24,030 - PriorityDownloader - INFO - Added 63 new rows for ERA.PA (1h)\n",
      "2025-05-12 19:17:24,070 - PriorityDownloader - INFO - Added 63 new rows for ARG.PA (1h)\n",
      "2025-05-12 19:17:24,107 - PriorityDownloader - INFO - Added 63 new rows for TFI.PA (1h)\n",
      "2025-05-12 19:17:27,134 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:17:28,597 - PriorityDownloader - INFO - Added 63 new rows for UBI.PA (1h)\n",
      "2025-05-12 19:17:28,638 - PriorityDownloader - INFO - Added 63 new rows for OVH.PA (1h)\n",
      "2025-05-12 19:17:28,680 - PriorityDownloader - INFO - Added 63 new rows for MMT.PA (1h)\n",
      "2025-05-12 19:17:28,719 - PriorityDownloader - INFO - Added 63 new rows for ES.PA (1h)\n",
      "2025-05-12 19:17:28,755 - PriorityDownloader - INFO - Added 31 new rows for BLV.PA (1h)\n",
      "2025-05-12 19:17:28,791 - PriorityDownloader - INFO - Added 63 new rows for MAU.PA (1h)\n",
      "2025-05-12 19:17:28,826 - PriorityDownloader - INFO - Added 19 new rows for GDS.PA (1h)\n",
      "2025-05-12 19:17:28,852 - PriorityDownloader - INFO - Added 57 new rows for FII.PA (1h)\n",
      "2025-05-12 19:17:28,927 - PriorityDownloader - INFO - Added 61 new rows for WAVE.PA (1h)\n",
      "2025-05-12 19:17:28,963 - PriorityDownloader - INFO - Added 45 new rows for CRLA.PA (1h)\n",
      "2025-05-12 19:17:28,991 - PriorityDownloader - INFO - Added 62 new rows for NRO.PA (1h)\n",
      "2025-05-12 19:17:29,027 - PriorityDownloader - INFO - Added 62 new rows for LSS.PA (1h)\n",
      "2025-05-12 19:17:29,063 - PriorityDownloader - INFO - Added 63 new rows for MERY.PA (1h)\n",
      "2025-05-12 19:17:29,102 - PriorityDownloader - INFO - Added 63 new rows for ETL.PA (1h)\n",
      "2025-05-12 19:17:29,154 - PriorityDownloader - INFO - Added 61 new rows for ELEC.PA (1h)\n",
      "2025-05-12 19:17:29,173 - PriorityDownloader - INFO - Added 11 new rows for FREY.PA (1h)\n",
      "2025-05-12 19:17:29,195 - PriorityDownloader - INFO - Added 63 new rows for DBG.PA (1h)\n",
      "2025-05-12 19:17:29,233 - PriorityDownloader - INFO - Added 53 new rows for CNDF.PA (1h)\n",
      "2025-05-12 19:17:29,280 - PriorityDownloader - INFO - Added 50 new rows for LTA.PA (1h)\n",
      "2025-05-12 19:17:29,308 - PriorityDownloader - INFO - Added 63 new rows for CDA.PA (1h)\n",
      "2025-05-12 19:17:29,346 - PriorityDownloader - INFO - Added 63 new rows for FNAC.PA (1h)\n",
      "2025-05-12 19:17:29,386 - PriorityDownloader - INFO - Added 62 new rows for MTU.PA (1h)\n",
      "2025-05-12 19:17:29,458 - PriorityDownloader - INFO - Added 63 new rows for VETO.PA (1h)\n",
      "2025-05-12 19:17:29,499 - PriorityDownloader - INFO - Added 49 new rows for TKTT.PA (1h)\n",
      "2025-05-12 19:17:29,533 - PriorityDownloader - INFO - Added 63 new rows for VIL.PA (1h)\n",
      "2025-05-12 19:17:29,570 - PriorityDownloader - INFO - Added 63 new rows for BEN.PA (1h)\n",
      "2025-05-12 19:17:29,611 - PriorityDownloader - INFO - Added 59 new rows for EC.PA (1h)\n",
      "2025-05-12 19:17:29,645 - PriorityDownloader - INFO - Added 62 new rows for VAC.PA (1h)\n",
      "2025-05-12 19:17:29,690 - PriorityDownloader - INFO - Added 49 new rows for SAVE.PA (1h)\n",
      "2025-05-12 19:17:29,739 - PriorityDownloader - INFO - Added 36 new rows for BASS.PA (1h)\n",
      "2025-05-12 19:17:32,754 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:17:34,390 - PriorityDownloader - INFO - Added 53 new rows for SHOP (1h)\n",
      "2025-05-12 19:17:34,418 - PriorityDownloader - INFO - Added 8 new rows for EADSF (1h)\n",
      "2025-05-12 19:17:34,440 - PriorityDownloader - INFO - Added 53 new rows for EADSY (1h)\n",
      "2025-05-12 19:17:34,488 - PriorityDownloader - INFO - Added 4 new rows for CHDRY (1h)\n",
      "2025-05-12 19:17:34,508 - PriorityDownloader - INFO - Added 53 new rows for SONY (1h)\n",
      "2025-05-12 19:17:34,543 - PriorityDownloader - INFO - Added 53 new rows for WFC-PC (1h)\n",
      "2025-05-12 19:17:34,573 - PriorityDownloader - INFO - Added 4 new rows for ALIZF (1h)\n",
      "2025-05-12 19:17:34,594 - PriorityDownloader - INFO - Added 53 new rows for ALIZY (1h)\n",
      "2025-05-12 19:17:34,622 - PriorityDownloader - INFO - Added 2 new rows for HTHIF (1h)\n",
      "2025-05-12 19:17:34,642 - PriorityDownloader - INFO - Added 47 new rows for ESLOY (1h)\n",
      "2025-05-12 19:17:34,677 - PriorityDownloader - INFO - Added 53 new rows for HTHIY (1h)\n",
      "2025-05-12 19:17:34,708 - PriorityDownloader - INFO - Added 2 new rows for MPNGF (1h)\n",
      "2025-05-12 19:17:34,727 - PriorityDownloader - INFO - Added 53 new rows for XIACY (1h)\n",
      "2025-05-12 19:17:34,750 - PriorityDownloader - INFO - Added 53 new rows for MPNGY (1h)\n",
      "2025-05-12 19:17:34,781 - PriorityDownloader - INFO - Added 51 new rows for PNGAY (1h)\n",
      "2025-05-12 19:17:34,832 - PriorityDownloader - INFO - Added 38 new rows for XIACF (1h)\n",
      "2025-05-12 19:17:34,857 - PriorityDownloader - INFO - Added 53 new rows for GILD (1h)\n",
      "2025-05-12 19:17:34,893 - PriorityDownloader - INFO - Added 53 new rows for VRTX (1h)\n",
      "2025-05-12 19:17:34,966 - PriorityDownloader - INFO - Added 51 new rows for BYDDF (1h)\n",
      "2025-05-12 19:17:35,000 - PriorityDownloader - INFO - Added 53 new rows for BYDDY (1h)\n",
      "2025-05-12 19:17:35,035 - PriorityDownloader - INFO - Added 53 new rows for SBUX (1h)\n",
      "2025-05-12 19:17:35,064 - PriorityDownloader - INFO - Added 3 new rows for SAFRF (1h)\n",
      "2025-05-12 19:17:35,087 - PriorityDownloader - INFO - Added 53 new rows for SAFRY (1h)\n",
      "2025-05-12 19:17:35,123 - PriorityDownloader - INFO - Added 53 new rows for MRVL (1h)\n",
      "2025-05-12 19:17:35,157 - PriorityDownloader - INFO - Added 22 new rows for KYCCF (1h)\n",
      "2025-05-12 19:17:35,194 - PriorityDownloader - INFO - Added 52 new rows for RCRUY (1h)\n",
      "2025-05-12 19:17:35,230 - PriorityDownloader - INFO - Added 52 new rows for CFRUY (1h)\n",
      "2025-05-12 19:17:35,258 - PriorityDownloader - INFO - Added 2 new rows for CFRHF (1h)\n",
      "2025-05-12 19:17:35,276 - PriorityDownloader - INFO - Added 53 new rows for ABBNY (1h)\n",
      "2025-05-12 19:17:38,292 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:17:40,289 - PriorityDownloader - INFO - Added 3 new rows for ABLZF (1h)\n",
      "2025-05-12 19:17:40,314 - PriorityDownloader - INFO - Added 51 new rows for UNCRY (1h)\n",
      "2025-05-12 19:17:40,346 - PriorityDownloader - INFO - Added 20 new rows for CSUAY (1h)\n",
      "2025-05-12 19:17:40,386 - PriorityDownloader - INFO - Added 53 new rows for SPOT (1h)\n",
      "2025-05-12 19:17:40,421 - PriorityDownloader - INFO - Added 53 new rows for LRCX (1h)\n",
      "2025-05-12 19:17:40,456 - PriorityDownloader - INFO - Added 53 new rows for KLAC (1h)\n",
      "2025-05-12 19:17:40,485 - PriorityDownloader - INFO - Added 4 new rows for SFTBF (1h)\n",
      "2025-05-12 19:17:40,524 - PriorityDownloader - INFO - Added 36 new rows for FRCOY (1h)\n",
      "2025-05-12 19:17:40,558 - PriorityDownloader - INFO - Added 53 new rows for AIQUY (1h)\n",
      "2025-05-12 19:17:40,589 - PriorityDownloader - INFO - Added 5 new rows for AIQUF (1h)\n",
      "2025-05-12 19:17:40,617 - PriorityDownloader - INFO - Added 53 new rows for SFTBY (1h)\n",
      "2025-05-12 19:17:40,653 - PriorityDownloader - INFO - Added 53 new rows for SMFG (1h)\n",
      "2025-05-12 19:17:40,699 - PriorityDownloader - INFO - Added 53 new rows for USB-PH (1h)\n",
      "2025-05-12 19:17:40,732 - PriorityDownloader - INFO - Added 53 new rows for IBKR (1h)\n",
      "2025-05-12 19:17:40,801 - PriorityDownloader - INFO - Added 53 new rows for CRWD (1h)\n",
      "2025-05-12 19:17:40,837 - PriorityDownloader - INFO - Added 53 new rows for DBSDY (1h)\n",
      "2025-05-12 19:17:40,884 - PriorityDownloader - INFO - Added 6 new rows for RLXXF (1h)\n",
      "2025-05-12 19:17:40,910 - PriorityDownloader - INFO - Added 53 new rows for EQIX (1h)\n",
      "2025-05-12 19:17:40,945 - PriorityDownloader - INFO - Added 53 new rows for RELX (1h)\n",
      "2025-05-12 19:17:40,980 - PriorityDownloader - INFO - Added 53 new rows for INTC (1h)\n",
      "2025-05-12 19:17:41,013 - PriorityDownloader - INFO - Added 53 new rows for INFY (1h)\n",
      "2025-05-12 19:17:41,069 - PriorityDownloader - INFO - Added 53 new rows for PYPL (1h)\n",
      "2025-05-12 19:17:41,099 - PriorityDownloader - INFO - Added 15 new rows for EBBNF (1h)\n",
      "2025-05-12 19:17:41,118 - PriorityDownloader - INFO - Added 3 new rows for DBSDF (1h)\n",
      "2025-05-12 19:17:41,144 - PriorityDownloader - INFO - Added 53 new rows for PROSY (1h)\n",
      "2025-05-12 19:17:41,178 - PriorityDownloader - INFO - Added 52 new rows for GS-PA (1h)\n",
      "2025-05-12 19:17:41,214 - PriorityDownloader - INFO - Added 53 new rows for IBDRY (1h)\n",
      "2025-05-12 19:17:41,246 - PriorityDownloader - INFO - Added 3 new rows for IBDSF (1h)\n",
      "2025-05-12 19:17:41,275 - PriorityDownloader - INFO - Added 53 new rows for CDNS (1h)\n",
      "2025-05-12 19:17:44,307 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:17:46,465 - PriorityDownloader - INFO - Added 2 new rows for NPPXF (1h)\n",
      "2025-05-12 19:17:46,492 - PriorityDownloader - INFO - Added 53 new rows for NTES (1h)\n",
      "2025-05-12 19:17:46,558 - PriorityDownloader - INFO - Added 48 new rows for MKKGY (1h)\n",
      "2025-05-12 19:17:46,592 - PriorityDownloader - INFO - Added 53 new rows for EQNR (1h)\n",
      "2025-05-12 19:17:46,619 - PriorityDownloader - INFO - Added 2 new rows for IVSBF (1h)\n",
      "2025-05-12 19:17:46,631 - PriorityDownloader - INFO - Added 7 new rows for ZFSVF (1h)\n",
      "2025-05-12 19:17:46,672 - PriorityDownloader - INFO - Added 53 new rows for MS-PA (1h)\n",
      "2025-05-12 19:17:46,706 - PriorityDownloader - INFO - Added 51 new rows for ZURVY (1h)\n",
      "2025-05-12 19:17:46,737 - PriorityDownloader - INFO - Added 53 new rows for WELL (1h)\n",
      "2025-05-12 19:17:46,770 - PriorityDownloader - INFO - Added 51 new rows for SHECY (1h)\n",
      "2025-05-12 19:17:46,802 - PriorityDownloader - INFO - Added 49 new rows for ITOCY (1h)\n",
      "2025-05-12 19:17:46,835 - PriorityDownloader - INFO - Added 49 new rows for TKOMY (1h)\n",
      "2025-05-12 19:17:46,867 - PriorityDownloader - INFO - Added 53 new rows for ADSK (1h)\n",
      "2025-05-12 19:17:46,902 - PriorityDownloader - INFO - Added 53 new rows for BBVA (1h)\n",
      "2025-05-12 19:17:46,940 - PriorityDownloader - INFO - Added 31 new rows for RYCEF (1h)\n",
      "2025-05-12 19:17:46,970 - PriorityDownloader - INFO - Added 63 new rows for DBK.DE (1h)\n",
      "2025-05-12 19:17:47,053 - PriorityDownloader - INFO - Added 63 new rows for ENEL.MI (1h)\n",
      "2025-05-12 19:17:47,095 - PriorityDownloader - INFO - Added 63 new rows for FRE.DE (1h)\n",
      "2025-05-12 19:17:47,135 - PriorityDownloader - INFO - Added 63 new rows for IBE.MC (1h)\n",
      "2025-05-12 19:17:47,176 - PriorityDownloader - INFO - Added 63 new rows for INGA.AS (1h)\n",
      "2025-05-12 19:17:47,217 - PriorityDownloader - INFO - Added 63 new rows for ISP.MI (1h)\n",
      "2025-05-12 19:17:47,256 - PriorityDownloader - INFO - Added 63 new rows for EOAN.DE (1h)\n",
      "2025-05-12 19:17:47,297 - PriorityDownloader - INFO - Added 63 new rows for G.MI (1h)\n",
      "2025-05-12 19:17:47,339 - PriorityDownloader - INFO - Added 63 new rows for ALV.DE (1h)\n",
      "2025-05-12 19:17:47,428 - PriorityDownloader - INFO - Added 63 new rows for BBVA.MC (1h)\n",
      "2025-05-12 19:17:47,469 - PriorityDownloader - INFO - Added 63 new rows for BAYN.DE (1h)\n",
      "2025-05-12 19:17:47,509 - PriorityDownloader - INFO - Added 63 new rows for ABI.BR (1h)\n",
      "2025-05-12 19:17:47,559 - PriorityDownloader - INFO - Added 175 new rows for EURUSD=X (1h)\n",
      "2025-05-12 19:17:47,630 - PriorityDownloader - INFO - Added 63 new rows for ENI.MI (1h)\n",
      "2025-05-12 19:17:47,674 - PriorityDownloader - INFO - Added 63 new rows for BMW.DE (1h)\n",
      "2025-05-12 19:17:50,704 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:17:52,178 - PriorityDownloader - INFO - Added 63 new rows for ASML.AS (1h)\n",
      "2025-05-12 19:17:52,262 - PriorityDownloader - INFO - Added 63 new rows for DTE.DE (1h)\n",
      "2025-05-12 19:17:52,304 - PriorityDownloader - INFO - Added 63 new rows for BAS.DE (1h)\n",
      "2025-05-12 19:17:52,346 - PriorityDownloader - INFO - Added 63 new rows for MT.AS (1h)\n",
      "2025-05-12 19:17:52,387 - PriorityDownloader - INFO - Added 63 new rows for RMS.PA (1h)\n",
      "2025-05-12 19:17:52,424 - PriorityDownloader - INFO - Added 63 new rows for STLAP.PA (1h)\n",
      "2025-05-12 19:17:52,459 - PriorityDownloader - INFO - Added 63 new rows for STMPA.PA (1h)\n",
      "2025-05-12 19:17:52,494 - PriorityDownloader - INFO - Added 53 new rows for V (1h)\n",
      "2025-05-12 19:17:52,529 - PriorityDownloader - INFO - Added 53 new rows for JPM (1h)\n",
      "2025-05-12 19:17:52,565 - PriorityDownloader - INFO - Added 53 new rows for JNJ (1h)\n",
      "2025-05-12 19:17:52,604 - PriorityDownloader - INFO - Added 53 new rows for WMT (1h)\n",
      "2025-05-12 19:17:52,637 - PriorityDownloader - INFO - Added 53 new rows for PG (1h)\n",
      "2025-05-12 19:17:52,675 - PriorityDownloader - INFO - Added 53 new rows for MA (1h)\n",
      "2025-05-12 19:17:52,753 - PriorityDownloader - INFO - Added 53 new rows for DIS (1h)\n",
      "2025-05-12 19:17:52,791 - PriorityDownloader - INFO - Added 53 new rows for HD (1h)\n",
      "2025-05-12 19:17:52,827 - PriorityDownloader - INFO - Added 53 new rows for VZ (1h)\n",
      "2025-05-12 19:17:52,860 - PriorityDownloader - INFO - Added 53 new rows for UNH (1h)\n",
      "2025-05-12 19:17:52,896 - PriorityDownloader - INFO - Added 53 new rows for KO (1h)\n",
      "2025-05-12 19:17:52,932 - PriorityDownloader - INFO - Added 53 new rows for PFE (1h)\n",
      "2025-05-12 19:17:52,966 - PriorityDownloader - INFO - Added 53 new rows for XOM (1h)\n",
      "2025-05-12 19:17:53,000 - PriorityDownloader - INFO - Added 53 new rows for MRK (1h)\n",
      "2025-05-12 19:17:53,037 - PriorityDownloader - INFO - Added 53 new rows for NKE (1h)\n",
      "2025-05-12 19:17:53,071 - PriorityDownloader - INFO - Added 53 new rows for ABT (1h)\n",
      "2025-05-12 19:17:53,109 - PriorityDownloader - INFO - Added 53 new rows for PEP (1h)\n",
      "2025-05-12 19:17:53,147 - PriorityDownloader - INFO - Added 53 new rows for CRM (1h)\n",
      "2025-05-12 19:17:53,234 - PriorityDownloader - INFO - Added 53 new rows for TMO (1h)\n",
      "2025-05-12 19:17:53,271 - PriorityDownloader - INFO - Added 53 new rows for MDT (1h)\n",
      "2025-05-12 19:17:53,308 - PriorityDownloader - INFO - Added 53 new rows for LLY (1h)\n",
      "2025-05-12 19:17:53,346 - PriorityDownloader - INFO - Added 53 new rows for MS (1h)\n",
      "2025-05-12 19:17:53,382 - PriorityDownloader - INFO - Added 53 new rows for BA (1h)\n",
      "2025-05-12 19:17:56,408 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:17:57,864 - PriorityDownloader - INFO - Added 53 new rows for STLA (1h)\n",
      "2025-05-12 19:17:57,899 - PriorityDownloader - INFO - Added 63 new rows for NESN.SW (1h)\n",
      "2025-05-12 19:17:57,939 - PriorityDownloader - INFO - Added 53 new rows for A (1h)\n",
      "2025-05-12 19:17:57,972 - PriorityDownloader - INFO - Added 53 new rows for AAL (1h)\n",
      "2025-05-12 19:17:58,065 - PriorityDownloader - INFO - Added 53 new rows for AAP (1h)\n",
      "2025-05-12 19:17:58,103 - PriorityDownloader - INFO - Added 53 new rows for ACN (1h)\n",
      "2025-05-12 19:17:58,136 - PriorityDownloader - INFO - Added 53 new rows for ADI (1h)\n",
      "2025-05-12 19:17:58,174 - PriorityDownloader - INFO - Added 53 new rows for ADM (1h)\n",
      "2025-05-12 19:17:58,226 - PriorityDownloader - INFO - Added 53 new rows for ADP (1h)\n",
      "2025-05-12 19:17:58,263 - PriorityDownloader - INFO - Added 53 new rows for AEE (1h)\n",
      "2025-05-12 19:17:58,300 - PriorityDownloader - INFO - Added 53 new rows for AEP (1h)\n",
      "2025-05-12 19:17:58,333 - PriorityDownloader - INFO - Added 53 new rows for AES (1h)\n",
      "2025-05-12 19:17:58,368 - PriorityDownloader - INFO - Added 53 new rows for AFL (1h)\n",
      "2025-05-12 19:17:58,403 - PriorityDownloader - INFO - Added 53 new rows for AIG (1h)\n",
      "2025-05-12 19:17:58,430 - PriorityDownloader - INFO - Added 53 new rows for AIV (1h)\n",
      "2025-05-12 19:17:58,471 - PriorityDownloader - INFO - Added 53 new rows for AIZ (1h)\n",
      "2025-05-12 19:17:58,505 - PriorityDownloader - INFO - Added 53 new rows for AJG (1h)\n",
      "2025-05-12 19:17:58,537 - PriorityDownloader - INFO - Added 53 new rows for AKAM (1h)\n",
      "2025-05-12 19:17:58,622 - PriorityDownloader - INFO - Added 53 new rows for ALB (1h)\n",
      "2025-05-12 19:17:58,658 - PriorityDownloader - INFO - Added 53 new rows for ALGN (1h)\n",
      "2025-05-12 19:17:58,692 - PriorityDownloader - INFO - Added 53 new rows for ALK (1h)\n",
      "2025-05-12 19:17:58,725 - PriorityDownloader - INFO - Added 53 new rows for ALL (1h)\n",
      "2025-05-12 19:17:58,763 - PriorityDownloader - INFO - Added 53 new rows for ALLE (1h)\n",
      "2025-05-12 19:17:58,798 - PriorityDownloader - INFO - Added 53 new rows for AMD (1h)\n",
      "2025-05-12 19:17:58,835 - PriorityDownloader - INFO - Added 53 new rows for AME (1h)\n",
      "2025-05-12 19:17:58,871 - PriorityDownloader - INFO - Added 53 new rows for AMP (1h)\n",
      "2025-05-12 19:17:58,904 - PriorityDownloader - INFO - Added 53 new rows for AMT (1h)\n",
      "2025-05-12 19:17:58,944 - PriorityDownloader - INFO - Added 53 new rows for ANSS (1h)\n",
      "2025-05-12 19:17:59,000 - PriorityDownloader - INFO - Added 53 new rows for AON (1h)\n",
      "2025-05-12 19:17:59,037 - PriorityDownloader - INFO - Added 53 new rows for AOS (1h)\n",
      "2025-05-12 19:18:02,055 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:18:03,592 - PriorityDownloader - INFO - Added 53 new rows for APA (1h)\n",
      "2025-05-12 19:18:03,626 - PriorityDownloader - INFO - Added 53 new rows for APD (1h)\n",
      "2025-05-12 19:18:03,663 - PriorityDownloader - INFO - Added 53 new rows for APH (1h)\n",
      "2025-05-12 19:18:03,698 - PriorityDownloader - INFO - Added 53 new rows for APTV (1h)\n",
      "2025-05-12 19:18:03,788 - PriorityDownloader - INFO - Added 53 new rows for ARE (1h)\n",
      "2025-05-12 19:18:03,822 - PriorityDownloader - INFO - Added 53 new rows for ATO (1h)\n",
      "2025-05-12 19:18:03,863 - PriorityDownloader - INFO - Added 53 new rows for AVB (1h)\n",
      "2025-05-12 19:18:03,897 - PriorityDownloader - INFO - Added 53 new rows for AVY (1h)\n",
      "2025-05-12 19:18:03,932 - PriorityDownloader - INFO - Added 53 new rows for AWK (1h)\n",
      "2025-05-12 19:18:03,973 - PriorityDownloader - INFO - Added 53 new rows for AXP (1h)\n",
      "2025-05-12 19:18:04,012 - PriorityDownloader - INFO - Added 53 new rows for AZO (1h)\n",
      "2025-05-12 19:18:04,047 - PriorityDownloader - INFO - Added 53 new rows for BAC (1h)\n",
      "2025-05-12 19:18:04,093 - PriorityDownloader - INFO - Added 53 new rows for BAX (1h)\n",
      "2025-05-12 19:18:04,129 - PriorityDownloader - INFO - Added 53 new rows for BBY (1h)\n",
      "2025-05-12 19:18:04,167 - PriorityDownloader - INFO - Added 53 new rows for BDX (1h)\n",
      "2025-05-12 19:18:04,203 - PriorityDownloader - INFO - Added 53 new rows for BEN (1h)\n",
      "2025-05-12 19:18:04,238 - PriorityDownloader - INFO - Added 53 new rows for BIIB (1h)\n",
      "2025-05-12 19:18:04,313 - PriorityDownloader - INFO - Added 53 new rows for BK (1h)\n",
      "2025-05-12 19:18:04,347 - PriorityDownloader - INFO - Added 53 new rows for BKNG (1h)\n",
      "2025-05-12 19:18:04,380 - PriorityDownloader - INFO - Added 53 new rows for BKR (1h)\n",
      "2025-05-12 19:18:04,418 - PriorityDownloader - INFO - Added 53 new rows for BLK (1h)\n",
      "2025-05-12 19:18:04,454 - PriorityDownloader - INFO - Added 53 new rows for BMY (1h)\n",
      "2025-05-12 19:18:04,491 - PriorityDownloader - INFO - Added 53 new rows for BR (1h)\n",
      "2025-05-12 19:18:04,534 - PriorityDownloader - INFO - Added 53 new rows for BSX (1h)\n",
      "2025-05-12 19:18:04,575 - PriorityDownloader - INFO - Added 53 new rows for BWA (1h)\n",
      "2025-05-12 19:18:04,609 - PriorityDownloader - INFO - Added 7 new rows for ESLOF (1h)\n",
      "2025-05-12 19:18:04,631 - PriorityDownloader - INFO - Added 4 new rows for BACHF (1h)\n",
      "2025-05-12 19:18:04,642 - PriorityDownloader - INFO - Added 1 new rows for SNYNF (1h)\n",
      "2025-05-12 19:18:04,657 - PriorityDownloader - INFO - Added 1 new rows for PIAIF (1h)\n",
      "2025-05-12 19:18:04,679 - PriorityDownloader - INFO - Added 53 new rows for WDAY (1h)\n",
      "2025-05-12 19:18:07,698 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:18:09,174 - PriorityDownloader - INFO - Added 10 new rows for ITOCF (1h)\n",
      "2025-05-12 19:18:09,207 - PriorityDownloader - INFO - Added 31 new rows for RLLCF (1h)\n",
      "2025-05-12 19:18:09,233 - PriorityDownloader - INFO - Added 4 new rows for MKGAF (1h)\n",
      "2025-05-12 19:18:09,247 - PriorityDownloader - INFO - Added 2 new rows for CMXHF (1h)\n",
      "2025-05-12 19:18:09,268 - PriorityDownloader - INFO - Added 53 new rows for ATLKY (1h)\n",
      "2025-05-12 19:18:09,302 - PriorityDownloader - INFO - Added 53 new rows for MS-PK (1h)\n",
      "2025-05-12 19:18:09,337 - PriorityDownloader - INFO - Added 53 new rows for TOELY (1h)\n",
      "2025-05-12 19:18:09,372 - PriorityDownloader - INFO - Added 53 new rows for GS-PD (1h)\n",
      "2025-05-12 19:18:09,409 - PriorityDownloader - INFO - Added 53 new rows for MS-PI (1h)\n",
      "2025-05-12 19:18:09,444 - PriorityDownloader - INFO - Added 53 new rows for PBR-A (1h)\n",
      "2025-05-12 19:18:09,480 - PriorityDownloader - INFO - Added 52 new rows for NTTYY (1h)\n",
      "2025-05-12 19:18:09,515 - PriorityDownloader - INFO - Added 53 new rows for MS-PF (1h)\n",
      "2025-05-12 19:18:09,542 - PriorityDownloader - INFO - Added 3 new rows for BCDRF (1h)\n",
      "2025-05-12 19:18:09,566 - PriorityDownloader - INFO - Added 53 new rows for DELL (1h)\n",
      "2025-05-12 19:18:09,643 - PriorityDownloader - INFO - Added 53 new rows for CTAS (1h)\n",
      "2025-05-12 19:18:09,678 - PriorityDownloader - INFO - Added 53 new rows for ABNB (1h)\n",
      "2025-05-12 19:18:09,720 - PriorityDownloader - INFO - Added 53 new rows for MS-PE (1h)\n",
      "2025-05-12 19:18:09,753 - PriorityDownloader - INFO - Added 53 new rows for LNSTY (1h)\n",
      "2025-05-12 19:18:09,784 - PriorityDownloader - INFO - Added 7 new rows for LDNXF (1h)\n",
      "2025-05-12 19:18:09,806 - PriorityDownloader - INFO - Added 53 new rows for ISNPY (1h)\n",
      "2025-05-12 19:18:09,858 - PriorityDownloader - INFO - Added 53 new rows for RACE (1h)\n",
      "2025-05-12 19:18:09,894 - PriorityDownloader - INFO - Added 53 new rows for MDLZ (1h)\n",
      "2025-05-12 19:18:09,927 - PriorityDownloader - INFO - Added 33 new rows for HNHPF (1h)\n",
      "2025-05-12 19:18:09,962 - PriorityDownloader - INFO - Added 53 new rows for AAGIY (1h)\n",
      "2025-05-12 19:18:09,997 - PriorityDownloader - INFO - Added 53 new rows for SCCO (1h)\n",
      "2025-05-12 19:18:10,051 - PriorityDownloader - INFO - Added 53 new rows for DASH (1h)\n",
      "2025-05-12 19:18:10,089 - PriorityDownloader - INFO - Added 53 new rows for USB-PP (1h)\n",
      "2025-05-12 19:18:10,137 - PriorityDownloader - INFO - Added 53 new rows for COIN (1h)\n",
      "2025-05-12 19:18:10,168 - PriorityDownloader - INFO - Added 19 new rows for NTDOF (1h)\n",
      "2025-05-12 19:18:10,242 - PriorityDownloader - INFO - Added 53 new rows for FTNT (1h)\n",
      "2025-05-12 19:18:13,270 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:18:14,834 - yfinance - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-12 19:18:14,834 - yfinance - ERROR - ['JGRO']: YFPricesMissingError('possibly delisted; no price data found  (period=730d) (Yahoo error = \"1h data not available for startTime=1660051800 and endTime=1747070295. The requested range must be within the last 730 days.\")')\n",
      "2025-05-12 19:18:15,274 - StockDownloader - WARNING - Empty data for JGRO (interval 1h)\n",
      "2025-05-12 19:18:15,376 - PriorityDownloader - INFO - Added 53 new rows for REGN (1h)\n",
      "2025-05-12 19:18:15,412 - PriorityDownloader - INFO - Added 53 new rows for NTDOY (1h)\n",
      "2025-05-12 19:18:15,448 - PriorityDownloader - INFO - Added 53 new rows for MURGY (1h)\n",
      "2025-05-12 19:18:15,476 - PriorityDownloader - INFO - Added 5 new rows for MURGF (1h)\n",
      "2025-05-12 19:18:15,496 - PriorityDownloader - INFO - Added 47 new rows for PBCRY (1h)\n",
      "2025-05-12 19:18:15,523 - PriorityDownloader - INFO - Added 1 new rows for WEBNF (1h)\n",
      "2025-05-12 19:18:15,546 - PriorityDownloader - INFO - Added 48 new rows for ENLAY (1h)\n",
      "2025-05-12 19:18:15,578 - PriorityDownloader - INFO - Added 39 new rows for NABZY (1h)\n",
      "2025-05-12 19:18:15,606 - PriorityDownloader - INFO - Added 4 new rows for GLAXF (1h)\n",
      "2025-05-12 19:18:15,627 - PriorityDownloader - INFO - Added 53 new rows for TEAM (1h)\n",
      "2025-05-12 19:18:15,664 - PriorityDownloader - INFO - Added 42 new rows for CHGCY (1h)\n",
      "2025-05-12 19:18:15,689 - PriorityDownloader - INFO - Added 3 new rows for 0MMG.IL (1h)\n",
      "2025-05-12 19:18:15,701 - PriorityDownloader - INFO - Added 7 new rows for BUDFF (1h)\n",
      "2025-05-12 19:18:15,742 - PriorityDownloader - INFO - Added 53 new rows for BNPQY (1h)\n",
      "2025-05-12 19:18:15,795 - PriorityDownloader - INFO - Added 53 new rows for SNPS (1h)\n",
      "2025-05-12 19:18:15,829 - PriorityDownloader - INFO - Added 33 new rows for ATLCY (1h)\n",
      "2025-05-12 19:18:15,855 - PriorityDownloader - INFO - Added 6 new rows for BPAQF (1h)\n",
      "2025-05-12 19:18:15,879 - PriorityDownloader - INFO - Added 53 new rows for AXAHY (1h)\n",
      "2025-05-12 19:18:15,913 - PriorityDownloader - INFO - Added 48 new rows for CSLLY (1h)\n",
      "2025-05-12 19:18:15,987 - PriorityDownloader - INFO - Added 53 new rows for MSTR (1h)\n",
      "2025-05-12 19:18:16,016 - PriorityDownloader - INFO - Added 1 new rows for AZNCF (1h)\n",
      "2025-05-12 19:18:16,048 - PriorityDownloader - INFO - Added 1 new rows for CBAUF (1h)\n",
      "2025-05-12 19:18:19,143 - StockDownloader - INFO - Downloading 30 tickers for interval 1h\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:18:20,561 - yfinance - ERROR - \n",
      "2 Failed downloads:\n",
      "2025-05-12 19:18:20,561 - yfinance - ERROR - ['URW.PA']: YFPricesMissingError('possibly delisted; no price data found  (period=730d) (Yahoo error = \"1h data not available for startTime=1681455600 and endTime=1747070301. The requested range must be within the last 730 days.\")')\n",
      "2025-05-12 19:18:20,562 - yfinance - ERROR - ['FDJ.PA']: YFPricesMissingError('possibly delisted; no price data found  (period=730d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "2025-05-12 19:18:20,692 - StockDownloader - WARNING - Empty data for URW.PA (interval 1h)\n",
      "2025-05-12 19:18:20,804 - StockDownloader - WARNING - Empty data for FDJ.PA (interval 1h)\n",
      "2025-05-12 19:18:20,983 - PriorityDownloader - INFO - Added 2 new rows for RHHBF (1h)\n",
      "2025-05-12 19:18:21,057 - PriorityDownloader - INFO - Added 2 new rows for TOELF (1h)\n",
      "2025-05-12 19:18:21,238 - PriorityDownloader - INFO - Added 1 new rows for PROSF (1h)\n",
      "2025-05-12 19:18:24,497 - StockDownloader - INFO - Downloading 3 tickers for interval 1h\n",
      "[*********************100%***********************]  3 of 3 completed\n",
      "Downloading 1h: 100%|██████████| 573/573 [01:54<00:00,  5.02it/s]\n",
      "2025-05-12 19:18:34,572 - PriorityDownloader - INFO - Processing 1540 tickers for interval 1d (quota: 2286 batches)\n",
      "2025-05-12 19:18:34,573 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:18:36,323 - PriorityDownloader - INFO - Added 1 new rows for ^GSPC (1d)\n",
      "2025-05-12 19:18:41,213 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:18:47,234 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:18:48,584 - yfinance - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-12 19:18:48,586 - yfinance - ERROR - ['SSNLF']: Exception(\"SSNLF: auto_adjust failed with unsupported operand type(s) for /: 'str' and 'float'\")\n",
      "2025-05-12 19:18:48,929 - StockDownloader - WARNING - Empty data for SSNLF (interval 1d)\n",
      "2025-05-12 19:18:49,186 - PriorityDownloader - INFO - Added 1 new rows for SCHP.PA (1d)\n",
      "2025-05-12 19:18:49,273 - PriorityDownloader - INFO - Added 1 new rows for KOF.PA (1d)\n",
      "2025-05-12 19:18:49,323 - PriorityDownloader - INFO - Added 1 new rows for QDT.PA (1d)\n",
      "2025-05-12 19:18:49,380 - PriorityDownloader - INFO - Added 1 new rows for LPE.PA (1d)\n",
      "2025-05-12 19:18:49,432 - PriorityDownloader - INFO - Added 1 new rows for SBT.PA (1d)\n",
      "2025-05-12 19:18:49,480 - PriorityDownloader - INFO - Added 1 new rows for EQS.PA (1d)\n",
      "2025-05-12 19:18:49,573 - PriorityDownloader - INFO - Added 1 new rows for BUR.PA (1d)\n",
      "2025-05-12 19:18:49,625 - PriorityDownloader - INFO - Added 1 new rows for AUB.PA (1d)\n",
      "2025-05-12 19:18:49,678 - PriorityDownloader - INFO - Added 1 new rows for GLO.PA (1d)\n",
      "2025-05-12 19:18:49,850 - PriorityDownloader - INFO - Added 1 new rows for MSFT (1d)\n",
      "2025-05-12 19:18:50,147 - PriorityDownloader - INFO - Added 1 new rows for META (1d)\n",
      "2025-05-12 19:18:50,386 - PriorityDownloader - INFO - Added 1 new rows for NONOF (1d)\n",
      "2025-05-12 19:18:50,583 - PriorityDownloader - INFO - Added 1 new rows for UNCFF (1d)\n",
      "2025-05-12 19:18:50,615 - PriorityDownloader - INFO - Added 7 new rows for AXAHF (1d)\n",
      "2025-05-12 19:18:53,689 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:18:55,423 - yfinance - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-12 19:18:55,424 - yfinance - ERROR - ['PPWLM']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "2025-05-12 19:18:55,829 - StockDownloader - WARNING - Empty data for PPWLM (interval 1d)\n",
      "2025-05-12 19:18:56,071 - PriorityDownloader - INFO - Added 1 new rows for PHM (1d)\n",
      "2025-05-12 19:18:56,260 - PriorityDownloader - INFO - Added 1 new rows for PNC (1d)\n",
      "2025-05-12 19:18:56,678 - PriorityDownloader - INFO - Added 1 new rows for PRGO (1d)\n",
      "2025-05-12 19:19:00,911 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:19:03,175 - PriorityDownloader - INFO - Added 1 new rows for ROST (1d)\n",
      "2025-05-12 19:19:03,240 - PriorityDownloader - INFO - Added 1 new rows for RSG (1d)\n",
      "2025-05-12 19:19:03,305 - PriorityDownloader - INFO - Added 1 new rows for RTX (1d)\n",
      "2025-05-12 19:19:03,394 - PriorityDownloader - INFO - Added 1 new rows for SBAC (1d)\n",
      "2025-05-12 19:19:03,495 - PriorityDownloader - INFO - Added 1 new rows for SEE (1d)\n",
      "2025-05-12 19:19:03,947 - PriorityDownloader - INFO - Added 1 new rows for SO (1d)\n",
      "2025-05-12 19:19:04,075 - PriorityDownloader - INFO - Added 1 new rows for SRE (1d)\n",
      "2025-05-12 19:19:04,149 - PriorityDownloader - INFO - Added 1 new rows for STE (1d)\n",
      "2025-05-12 19:19:04,275 - PriorityDownloader - INFO - Added 1 new rows for STT (1d)\n",
      "2025-05-12 19:19:04,349 - PriorityDownloader - INFO - Added 1 new rows for STX (1d)\n",
      "2025-05-12 19:19:04,423 - PriorityDownloader - INFO - Added 1 new rows for STZ (1d)\n",
      "2025-05-12 19:19:04,708 - PriorityDownloader - INFO - Added 1 new rows for SYY (1d)\n",
      "2025-05-12 19:19:08,668 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:19:11,973 - PriorityDownloader - INFO - Added 1 new rows for UAL (1d)\n",
      "2025-05-12 19:19:16,408 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:19:23,697 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:19:25,108 - PriorityDownloader - INFO - Added 1 new rows for ENB.TO (1d)\n",
      "2025-05-12 19:19:25,254 - PriorityDownloader - INFO - Added 1 new rows for CNQ.TO (1d)\n",
      "2025-05-12 19:19:25,407 - PriorityDownloader - INFO - Added 1 new rows for SLF.TO (1d)\n",
      "2025-05-12 19:19:29,669 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:19:31,987 - PriorityDownloader - INFO - Added 1 new rows for EURHUF=X (1d)\n",
      "2025-05-12 19:19:32,032 - PriorityDownloader - INFO - Added 1 new rows for CNY=X (1d)\n",
      "2025-05-12 19:19:32,079 - PriorityDownloader - INFO - Added 1 new rows for HKD=X (1d)\n",
      "2025-05-12 19:19:32,126 - PriorityDownloader - INFO - Added 1 new rows for SGD=X (1d)\n",
      "2025-05-12 19:19:35,207 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:19:35,974 - yfinance - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-12 19:19:35,975 - yfinance - ERROR - ['DFND-EUR.PA']: YFInvalidPeriodError(\"DFND-EUR.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:36,202 - StockDownloader - WARNING - Empty data for DFND-EUR.PA (interval 1d)\n",
      "2025-05-12 19:19:36,341 - PriorityDownloader - INFO - Added 1 new rows for PHP=X (1d)\n",
      "2025-05-12 19:19:40,312 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:19:40,863 - yfinance - ERROR - \n",
      "17 Failed downloads:\n",
      "2025-05-12 19:19:40,864 - yfinance - ERROR - ['AARTL.PA']: YFInvalidPeriodError(\"AARTL.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,864 - yfinance - ERROR - ['ABSMI.PA']: YFInvalidPeriodError(\"ABSMI.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,865 - yfinance - ERROR - ['AATCX.PA']: YFInvalidPeriodError(\"AATCX.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,865 - yfinance - ERROR - ['ABDJE.PA']: YFInvalidPeriodError(\"ABDJE.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,866 - yfinance - ERROR - ['AAFIN.PA']: YFInvalidPeriodError(\"AAFIN.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,866 - yfinance - ERROR - ['ABNSP.PA']: YFInvalidPeriodError(\"ABNSP.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,866 - yfinance - ERROR - ['ABHSN.PA']: YFInvalidPeriodError(\"ABHSN.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,866 - yfinance - ERROR - ['NB28V.PA']: YFInvalidPeriodError(\"NB28V.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,867 - yfinance - ERROR - ['AABCH.PA']: YFInvalidPeriodError(\"AABCH.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,867 - yfinance - ERROR - ['8G19V.PA']: YFInvalidPeriodError(\"8G19V.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,867 - yfinance - ERROR - ['NB22V.PA']: YFInvalidPeriodError(\"NB22V.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,868 - yfinance - ERROR - ['AABEN.PA']: YFInvalidPeriodError(\"AABEN.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,868 - yfinance - ERROR - ['ABDJI.PA']: YFInvalidPeriodError(\"ABDJI.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,869 - yfinance - ERROR - ['AAHLT.PA']: YFInvalidPeriodError(\"AAHLT.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,869 - yfinance - ERROR - ['AAUTL.PA']: YFInvalidPeriodError(\"AAUTL.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,869 - yfinance - ERROR - ['AABFB.PA']: YFInvalidPeriodError(\"AABFB.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,869 - yfinance - ERROR - ['AAINS.PA']: YFInvalidPeriodError(\"AAINS.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:40,906 - StockDownloader - WARNING - Empty data for ABDJI.PA (interval 1d)\n",
      "2025-05-12 19:19:40,943 - StockDownloader - WARNING - Empty data for ABNSP.PA (interval 1d)\n",
      "2025-05-12 19:19:40,978 - StockDownloader - WARNING - Empty data for AABCH.PA (interval 1d)\n",
      "2025-05-12 19:19:41,013 - StockDownloader - WARNING - Empty data for AATCX.PA (interval 1d)\n",
      "2025-05-12 19:19:41,048 - StockDownloader - WARNING - Empty data for AAHLT.PA (interval 1d)\n",
      "2025-05-12 19:19:41,083 - StockDownloader - WARNING - Empty data for ABSMI.PA (interval 1d)\n",
      "2025-05-12 19:19:41,156 - StockDownloader - WARNING - Empty data for AAFIN.PA (interval 1d)\n",
      "2025-05-12 19:19:41,191 - StockDownloader - WARNING - Empty data for AABFB.PA (interval 1d)\n",
      "2025-05-12 19:19:41,227 - StockDownloader - WARNING - Empty data for AARTL.PA (interval 1d)\n",
      "2025-05-12 19:19:41,263 - StockDownloader - WARNING - Empty data for 8G19V.PA (interval 1d)\n",
      "2025-05-12 19:19:41,299 - StockDownloader - WARNING - Empty data for NB22V.PA (interval 1d)\n",
      "2025-05-12 19:19:41,334 - StockDownloader - WARNING - Empty data for NB28V.PA (interval 1d)\n",
      "2025-05-12 19:19:41,371 - StockDownloader - WARNING - Empty data for AABEN.PA (interval 1d)\n",
      "2025-05-12 19:19:41,407 - StockDownloader - WARNING - Empty data for ABDJE.PA (interval 1d)\n",
      "2025-05-12 19:19:41,443 - StockDownloader - WARNING - Empty data for ABHSN.PA (interval 1d)\n",
      "2025-05-12 19:19:41,479 - StockDownloader - WARNING - Empty data for AAUTL.PA (interval 1d)\n",
      "2025-05-12 19:19:41,515 - StockDownloader - WARNING - Empty data for AAINS.PA (interval 1d)\n",
      "2025-05-12 19:19:41,709 - PriorityDownloader - INFO - Added 7 new rows for CACC.PA (1d)\n",
      "2025-05-12 19:19:41,761 - PriorityDownloader - INFO - Added 7 new rows for GEMU.PA (1d)\n",
      "2025-05-12 19:19:41,774 - PriorityDownloader - INFO - Added 7 new rows for OBLI.PA (1d)\n",
      "2025-05-12 19:19:41,791 - PriorityDownloader - INFO - Added 7 new rows for SPEEU.PA (1d)\n",
      "2025-05-12 19:19:41,804 - PriorityDownloader - INFO - Added 7 new rows for ERTH.PA (1d)\n",
      "2025-05-12 19:19:44,915 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:19:45,631 - yfinance - ERROR - \n",
      "6 Failed downloads:\n",
      "2025-05-12 19:19:45,631 - yfinance - ERROR - ['AABKX.PA']: YFInvalidPeriodError(\"AABKX.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:45,632 - yfinance - ERROR - ['AATLC.PA']: YFInvalidPeriodError(\"AATLC.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:45,632 - yfinance - ERROR - ['ABNSQ.PA']: YFInvalidPeriodError(\"ABNSQ.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:45,633 - yfinance - ERROR - ['XQ48V.PA']: YFInvalidPeriodError(\"XQ48V.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:45,634 - yfinance - ERROR - ['AASTX.PA']: YFInvalidPeriodError(\"AASTX.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:45,634 - yfinance - ERROR - ['ETHC-EUR.PA']: YFInvalidPeriodError(\"ETHC-EUR.PA: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:45,733 - StockDownloader - WARNING - Empty data for AASTX.PA (interval 1d)\n",
      "2025-05-12 19:19:45,770 - StockDownloader - WARNING - Empty data for ABNSQ.PA (interval 1d)\n",
      "2025-05-12 19:19:45,808 - StockDownloader - WARNING - Empty data for AABKX.PA (interval 1d)\n",
      "2025-05-12 19:19:45,880 - StockDownloader - WARNING - Empty data for AATLC.PA (interval 1d)\n",
      "2025-05-12 19:19:45,916 - StockDownloader - WARNING - Empty data for XQ48V.PA (interval 1d)\n",
      "2025-05-12 19:19:45,954 - StockDownloader - WARNING - Empty data for ETHC-EUR.PA (interval 1d)\n",
      "2025-05-12 19:19:46,524 - PriorityDownloader - INFO - Added 4 new rows for TS3S.L (1d)\n",
      "2025-05-12 19:19:46,572 - PriorityDownloader - INFO - Added 4 new rows for XT2D.L (1d)\n",
      "2025-05-12 19:19:46,659 - PriorityDownloader - INFO - Added 5 new rows for FRXD.L (1d)\n",
      "2025-05-12 19:19:46,682 - PriorityDownloader - INFO - Added 4 new rows for XSD2.L (1d)\n",
      "2025-05-12 19:19:49,769 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:19:50,387 - yfinance - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-12 19:19:50,388 - yfinance - ERROR - ['FBTC.L']: YFInvalidPeriodError(\"FBTC.L: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:50,530 - StockDownloader - WARNING - Empty data for FBTC.L (interval 1d)\n",
      "2025-05-12 19:19:51,057 - PriorityDownloader - INFO - Added 2 new rows for SPEH.L (1d)\n",
      "2025-05-12 19:19:51,089 - PriorityDownloader - INFO - Added 1 new rows for 0XC5.IL (1d)\n",
      "2025-05-12 19:19:51,168 - PriorityDownloader - INFO - Added 7 new rows for UC76.L (1d)\n",
      "2025-05-12 19:19:51,190 - PriorityDownloader - INFO - Added 4 new rows for AGBP.L (1d)\n",
      "2025-05-12 19:19:51,215 - PriorityDownloader - INFO - Added 6 new rows for MIDD.L (1d)\n",
      "2025-05-12 19:19:51,240 - PriorityDownloader - INFO - Added 6 new rows for FUSR.L (1d)\n",
      "2025-05-12 19:19:51,255 - PriorityDownloader - INFO - Added 2 new rows for 0DZB.L (1d)\n",
      "2025-05-12 19:19:51,268 - PriorityDownloader - INFO - Added 4 new rows for DTLE.L (1d)\n",
      "2025-05-12 19:19:51,291 - PriorityDownloader - INFO - Added 6 new rows for IGLT.L (1d)\n",
      "2025-05-12 19:19:51,457 - PriorityDownloader - INFO - Added 6 new rows for SDIA.L (1d)\n",
      "2025-05-12 19:19:51,478 - PriorityDownloader - INFO - Added 6 new rows for IEBB.IL (1d)\n",
      "2025-05-12 19:19:54,689 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:19:55,359 - yfinance - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-12 19:19:55,359 - yfinance - ERROR - ['I50D.L']: YFInvalidPeriodError(\"I50D.L: Period 'max' is invalid, must be of the format 1d, 5d, etc.\")\n",
      "2025-05-12 19:19:55,565 - StockDownloader - WARNING - Empty data for I50D.L (interval 1d)\n",
      "2025-05-12 19:19:55,806 - PriorityDownloader - INFO - Added 1 new rows for 0MP3.IL (1d)\n",
      "2025-05-12 19:19:56,080 - PriorityDownloader - INFO - Added 1 new rows for IGTM.L (1d)\n",
      "2025-05-12 19:19:59,477 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:20:01,144 - PriorityDownloader - INFO - Added 1 new rows for LQD (1d)\n",
      "2025-05-12 19:20:01,183 - PriorityDownloader - INFO - Added 1 new rows for MSTZ (1d)\n",
      "2025-05-12 19:20:01,274 - PriorityDownloader - INFO - Added 1 new rows for SCHD (1d)\n",
      "2025-05-12 19:20:01,315 - PriorityDownloader - INFO - Added 1 new rows for VEA (1d)\n",
      "2025-05-12 19:20:01,423 - PriorityDownloader - INFO - Added 1 new rows for XBI (1d)\n",
      "2025-05-12 19:20:01,458 - PriorityDownloader - INFO - Added 1 new rows for KRE (1d)\n",
      "2025-05-12 19:20:01,501 - PriorityDownloader - INFO - Added 1 new rows for XLE (1d)\n",
      "2025-05-12 19:20:05,078 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:20:06,464 - PriorityDownloader - INFO - Added 1 new rows for XLP (1d)\n",
      "2025-05-12 19:20:06,517 - PriorityDownloader - INFO - Added 1 new rows for JAAA (1d)\n",
      "2025-05-12 19:20:06,582 - PriorityDownloader - INFO - Added 1 new rows for EWJ (1d)\n",
      "2025-05-12 19:20:06,804 - PriorityDownloader - INFO - Added 8 new rows for SGOL (1d)\n",
      "2025-05-12 19:20:10,470 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:20:12,006 - PriorityDownloader - INFO - Added 1 new rows for EMB (1d)\n",
      "2025-05-12 19:20:12,061 - PriorityDownloader - INFO - Added 1 new rows for JEPQ (1d)\n",
      "2025-05-12 19:20:12,121 - PriorityDownloader - INFO - Added 1 new rows for VTEB (1d)\n",
      "2025-05-12 19:20:12,147 - PriorityDownloader - INFO - Added 1 new rows for SPIB (1d)\n",
      "2025-05-12 19:20:12,178 - PriorityDownloader - INFO - Added 1 new rows for IEF (1d)\n",
      "2025-05-12 19:20:12,325 - PriorityDownloader - INFO - Added 1 new rows for SPDW (1d)\n",
      "2025-05-12 19:20:12,403 - PriorityDownloader - INFO - Added 1 new rows for JEPI (1d)\n",
      "2025-05-12 19:20:12,427 - PriorityDownloader - INFO - Added 1 new rows for ILF (1d)\n",
      "2025-05-12 19:20:12,465 - PriorityDownloader - INFO - Added 1 new rows for PGX (1d)\n",
      "2025-05-12 19:20:12,499 - PriorityDownloader - INFO - Added 1 new rows for IJR (1d)\n",
      "2025-05-12 19:20:15,526 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:20:16,861 - PriorityDownloader - INFO - Added 1 new rows for CGGR (1d)\n",
      "2025-05-12 19:20:16,884 - PriorityDownloader - INFO - Added 1 new rows for EWY (1d)\n",
      "2025-05-12 19:20:17,720 - PriorityDownloader - INFO - Added 1 new rows for ARKG (1d)\n",
      "2025-05-12 19:20:20,847 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:20:22,519 - PriorityDownloader - INFO - Added 1 new rows for PFF (1d)\n",
      "2025-05-12 19:20:22,606 - PriorityDownloader - INFO - Added 1 new rows for EFV (1d)\n",
      "2025-05-12 19:20:22,688 - PriorityDownloader - INFO - Added 1 new rows for DOG (1d)\n",
      "2025-05-12 19:20:22,765 - PriorityDownloader - INFO - Added 1 new rows for IUSB (1d)\n",
      "2025-05-12 19:20:26,326 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:20:28,412 - PriorityDownloader - INFO - Added 1 new rows for IXUS (1d)\n",
      "2025-05-12 19:20:28,438 - PriorityDownloader - INFO - Added 1 new rows for SVIX (1d)\n",
      "2025-05-12 19:20:28,461 - PriorityDownloader - INFO - Added 1 new rows for VIXY (1d)\n",
      "2025-05-12 19:20:28,489 - PriorityDownloader - INFO - Added 1 new rows for DFAC (1d)\n",
      "2025-05-12 19:20:28,519 - PriorityDownloader - INFO - Added 1 new rows for SDVY (1d)\n",
      "2025-05-12 19:20:28,548 - PriorityDownloader - INFO - Added 1 new rows for TFLO (1d)\n",
      "2025-05-12 19:20:28,623 - PriorityDownloader - INFO - Added 1 new rows for SCHZ (1d)\n",
      "2025-05-12 19:20:28,654 - PriorityDownloader - INFO - Added 1 new rows for MLPX (1d)\n",
      "2025-05-12 19:20:28,681 - PriorityDownloader - INFO - Added 2 new rows for SPEM (1d)\n",
      "2025-05-12 19:20:31,719 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:20:32,776 - PriorityDownloader - INFO - Added 2 new rows for SPSB (1d)\n",
      "2025-05-12 19:20:32,806 - PriorityDownloader - INFO - Added 1 new rows for LABU (1d)\n",
      "2025-05-12 19:20:32,827 - PriorityDownloader - INFO - Added 1 new rows for DYNF (1d)\n",
      "2025-05-12 19:20:32,851 - PriorityDownloader - INFO - Added 1 new rows for IGSB (1d)\n",
      "2025-05-12 19:20:32,886 - PriorityDownloader - INFO - Added 1 new rows for CGUS (1d)\n",
      "2025-05-12 19:20:32,913 - PriorityDownloader - INFO - Added 1 new rows for ETHT (1d)\n",
      "2025-05-12 19:20:32,933 - PriorityDownloader - INFO - Added 1 new rows for BLV (1d)\n",
      "2025-05-12 19:20:32,968 - PriorityDownloader - INFO - Added 1 new rows for BBJP (1d)\n",
      "2025-05-12 19:20:33,003 - PriorityDownloader - INFO - Added 1 new rows for UCO (1d)\n",
      "2025-05-12 19:20:33,032 - PriorityDownloader - INFO - Added 1 new rows for YMAX (1d)\n",
      "2025-05-12 19:20:33,049 - PriorityDownloader - INFO - Added 1 new rows for IAUM (1d)\n",
      "2025-05-12 19:20:33,067 - PriorityDownloader - INFO - Added 1 new rows for VCSH (1d)\n",
      "2025-05-12 19:20:33,094 - PriorityDownloader - INFO - Added 1 new rows for AAAU (1d)\n",
      "2025-05-12 19:20:33,117 - PriorityDownloader - INFO - Added 1 new rows for VGLT (1d)\n",
      "2025-05-12 19:20:33,158 - PriorityDownloader - INFO - Added 1 new rows for VTWO (1d)\n",
      "2025-05-12 19:20:33,189 - PriorityDownloader - INFO - Added 1 new rows for SPMO (1d)\n",
      "2025-05-12 19:20:33,217 - PriorityDownloader - INFO - Added 1 new rows for TSLR (1d)\n",
      "2025-05-12 19:20:33,237 - PriorityDownloader - INFO - Added 1 new rows for DGRO (1d)\n",
      "2025-05-12 19:20:33,264 - PriorityDownloader - INFO - Added 1 new rows for SPAB (1d)\n",
      "2025-05-12 19:20:33,293 - PriorityDownloader - INFO - Added 1 new rows for KBE (1d)\n",
      "2025-05-12 19:20:33,351 - PriorityDownloader - INFO - Added 1 new rows for AUSF (1d)\n",
      "2025-05-12 19:20:33,416 - PriorityDownloader - INFO - Added 1 new rows for VCLT (1d)\n",
      "2025-05-12 19:20:33,474 - PriorityDownloader - INFO - Added 1 new rows for NVDU (1d)\n",
      "2025-05-12 19:20:33,526 - PriorityDownloader - INFO - Added 1 new rows for JETS (1d)\n",
      "2025-05-12 19:20:33,561 - PriorityDownloader - INFO - Added 1 new rows for IWD (1d)\n",
      "2025-05-12 19:20:33,609 - PriorityDownloader - INFO - Added 1 new rows for CWEB (1d)\n",
      "2025-05-12 19:20:33,634 - PriorityDownloader - INFO - Added 1 new rows for FNDF (1d)\n",
      "2025-05-12 19:20:33,753 - PriorityDownloader - INFO - Added 1 new rows for SCHR (1d)\n",
      "2025-05-12 19:20:33,786 - PriorityDownloader - INFO - Added 1 new rows for FLOT (1d)\n",
      "2025-05-12 19:20:36,809 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:20:37,842 - PriorityDownloader - INFO - Added 1 new rows for IGIB (1d)\n",
      "2025-05-12 19:20:37,877 - PriorityDownloader - INFO - Added 1 new rows for BIV (1d)\n",
      "2025-05-12 19:20:37,926 - PriorityDownloader - INFO - Added 1 new rows for MOAT (1d)\n",
      "2025-05-12 19:20:37,953 - PriorityDownloader - INFO - Added 1 new rows for DFIC (1d)\n",
      "2025-05-12 19:20:38,025 - PriorityDownloader - INFO - Added 1 new rows for URNM (1d)\n",
      "2025-05-12 19:20:38,119 - PriorityDownloader - INFO - Added 1 new rows for QEFA (1d)\n",
      "2025-05-12 19:20:38,159 - PriorityDownloader - INFO - Added 1 new rows for SCHE (1d)\n",
      "2025-05-12 19:20:38,191 - PriorityDownloader - INFO - Added 1 new rows for PVAL (1d)\n",
      "2025-05-12 19:20:38,226 - PriorityDownloader - INFO - Added 1 new rows for FGD (1d)\n",
      "2025-05-12 19:20:38,288 - PriorityDownloader - INFO - Added 1 new rows for XLG (1d)\n",
      "2025-05-12 19:20:38,329 - PriorityDownloader - INFO - Added 1 new rows for IVW (1d)\n",
      "2025-05-12 19:20:38,369 - PriorityDownloader - INFO - Added 1 new rows for BUFR (1d)\n",
      "2025-05-12 19:20:38,396 - PriorityDownloader - INFO - Added 1 new rows for DFSV (1d)\n",
      "2025-05-12 19:20:38,422 - PriorityDownloader - INFO - Added 1 new rows for OUNZ (1d)\n",
      "2025-05-12 19:20:38,446 - PriorityDownloader - INFO - Added 1 new rows for SCHI (1d)\n",
      "2025-05-12 19:20:38,468 - PriorityDownloader - INFO - Added 1 new rows for VFLO (1d)\n",
      "2025-05-12 19:20:38,500 - PriorityDownloader - INFO - Added 1 new rows for DFAI (1d)\n",
      "2025-05-12 19:20:38,558 - PriorityDownloader - INFO - Added 1 new rows for SPLV (1d)\n",
      "2025-05-12 19:20:38,595 - PriorityDownloader - INFO - Added 1 new rows for GRNY (1d)\n",
      "2025-05-12 19:20:38,666 - PriorityDownloader - INFO - Added 1 new rows for EEMA (1d)\n",
      "2025-05-12 19:20:38,706 - PriorityDownloader - INFO - Added 1 new rows for CIBR (1d)\n",
      "2025-05-12 19:20:38,730 - PriorityDownloader - INFO - Added 1 new rows for CGCP (1d)\n",
      "2025-05-12 19:20:38,759 - PriorityDownloader - INFO - Added 1 new rows for ITOT (1d)\n",
      "2025-05-12 19:20:38,797 - PriorityDownloader - INFO - Added 1 new rows for SHYG (1d)\n",
      "2025-05-12 19:20:38,822 - PriorityDownloader - INFO - Added 1 new rows for BSCR (1d)\n",
      "2025-05-12 19:20:41,839 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:20:42,966 - PriorityDownloader - INFO - Added 1 new rows for IWF (1d)\n",
      "2025-05-12 19:20:43,047 - PriorityDownloader - INFO - Added 1 new rows for RDVY (1d)\n",
      "2025-05-12 19:20:43,081 - PriorityDownloader - INFO - Added 1 new rows for FPE (1d)\n",
      "2025-05-12 19:20:43,121 - PriorityDownloader - INFO - Added 1 new rows for PXH (1d)\n",
      "2025-05-12 19:20:43,153 - PriorityDownloader - INFO - Added 1 new rows for BAR (1d)\n",
      "2025-05-12 19:20:43,187 - PriorityDownloader - INFO - Added 1 new rows for TFI (1d)\n",
      "2025-05-12 19:20:43,220 - PriorityDownloader - INFO - Added 8 new rows for IWP (1d)\n",
      "2025-05-12 19:20:43,249 - PriorityDownloader - INFO - Added 8 new rows for BINC (1d)\n",
      "2025-05-12 19:20:43,267 - PriorityDownloader - INFO - Added 8 new rows for MTUM (1d)\n",
      "2025-05-12 19:20:43,301 - PriorityDownloader - INFO - Added 8 new rows for UUP (1d)\n",
      "2025-05-12 19:20:43,333 - PriorityDownloader - INFO - Added 8 new rows for ACWX (1d)\n",
      "2025-05-12 19:20:43,372 - PriorityDownloader - INFO - Added 8 new rows for PZA (1d)\n",
      "2025-05-12 19:20:43,405 - PriorityDownloader - INFO - Added 8 new rows for MINT (1d)\n",
      "2025-05-12 19:20:43,427 - PriorityDownloader - INFO - Added 8 new rows for YMAG (1d)\n",
      "2025-05-12 19:20:43,444 - PriorityDownloader - INFO - Added 8 new rows for SPLB (1d)\n",
      "2025-05-12 19:20:43,476 - PriorityDownloader - INFO - Added 8 new rows for IWR (1d)\n",
      "2025-05-12 19:20:43,513 - PriorityDownloader - INFO - Added 8 new rows for USMV (1d)\n",
      "2025-05-12 19:20:43,542 - PriorityDownloader - INFO - Added 8 new rows for VUG (1d)\n",
      "2025-05-12 19:20:43,569 - PriorityDownloader - INFO - Added 8 new rows for ACES (1d)\n",
      "2025-05-12 19:20:43,597 - PriorityDownloader - INFO - Added 8 new rows for QUAL (1d)\n",
      "2025-05-12 19:20:43,621 - PriorityDownloader - INFO - Added 8 new rows for IGLB (1d)\n",
      "2025-05-12 19:20:43,649 - PriorityDownloader - INFO - Added 8 new rows for SVXY (1d)\n",
      "2025-05-12 19:20:43,675 - PriorityDownloader - INFO - Added 8 new rows for SCHV (1d)\n",
      "2025-05-12 19:20:43,711 - PriorityDownloader - INFO - Added 8 new rows for BTC (1d)\n",
      "2025-05-12 19:20:43,780 - PriorityDownloader - INFO - Added 8 new rows for IYT (1d)\n",
      "2025-05-12 19:20:43,806 - PriorityDownloader - INFO - Added 8 new rows for AMDY (1d)\n",
      "2025-05-12 19:20:43,816 - PriorityDownloader - INFO - Added 8 new rows for AVGX (1d)\n",
      "2025-05-12 19:20:43,830 - PriorityDownloader - INFO - Added 8 new rows for SPYD (1d)\n",
      "2025-05-12 19:20:43,845 - PriorityDownloader - INFO - Added 7 new rows for MRNY (1d)\n",
      "2025-05-12 19:20:43,854 - PriorityDownloader - INFO - Added 7 new rows for ARKB (1d)\n",
      "2025-05-12 19:20:46,867 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:20:47,955 - PriorityDownloader - INFO - Added 8 new rows for VIG (1d)\n",
      "2025-05-12 19:20:47,979 - PriorityDownloader - INFO - Added 8 new rows for TCAF (1d)\n",
      "2025-05-12 19:20:47,998 - PriorityDownloader - INFO - Added 8 new rows for ITA (1d)\n",
      "2025-05-12 19:20:48,089 - PriorityDownloader - INFO - Added 8 new rows for KIE (1d)\n",
      "2025-05-12 19:20:48,123 - PriorityDownloader - INFO - Added 8 new rows for HYD (1d)\n",
      "2025-05-12 19:20:48,146 - PriorityDownloader - INFO - Added 8 new rows for TSDD (1d)\n",
      "2025-05-12 19:20:48,157 - PriorityDownloader - INFO - Added 8 new rows for VUSB (1d)\n",
      "2025-05-12 19:20:48,175 - PriorityDownloader - INFO - Added 8 new rows for VTIP (1d)\n",
      "2025-05-12 19:20:48,219 - PriorityDownloader - INFO - Added 8 new rows for FDVV (1d)\n",
      "2025-05-12 19:20:48,246 - PriorityDownloader - INFO - Added 8 new rows for HTRB (1d)\n",
      "2025-05-12 19:20:48,268 - PriorityDownloader - INFO - Added 8 new rows for FTSM (1d)\n",
      "2025-05-12 19:20:48,288 - PriorityDownloader - INFO - Added 8 new rows for AMZZ (1d)\n",
      "2025-05-12 19:20:48,306 - PriorityDownloader - INFO - Added 8 new rows for FLTR (1d)\n",
      "2025-05-12 19:20:48,333 - PriorityDownloader - INFO - Added 8 new rows for BIZD (1d)\n",
      "2025-05-12 19:20:48,354 - PriorityDownloader - INFO - Added 8 new rows for PTIR (1d)\n",
      "2025-05-12 19:20:48,369 - PriorityDownloader - INFO - Added 8 new rows for DIVO (1d)\n",
      "2025-05-12 19:20:48,390 - PriorityDownloader - INFO - Added 8 new rows for VSS (1d)\n",
      "2025-05-12 19:20:48,414 - PriorityDownloader - INFO - Added 8 new rows for DFEM (1d)\n",
      "2025-05-12 19:20:48,426 - PriorityDownloader - INFO - Added 8 new rows for EPI (1d)\n",
      "2025-05-12 19:20:48,464 - PriorityDownloader - INFO - Added 8 new rows for IOO (1d)\n",
      "2025-05-12 19:20:48,495 - PriorityDownloader - INFO - Added 8 new rows for AVUV (1d)\n",
      "2025-05-12 19:20:48,515 - PriorityDownloader - INFO - Added 8 new rows for VONG (1d)\n",
      "2025-05-12 19:20:48,543 - PriorityDownloader - INFO - Added 8 new rows for VYM (1d)\n",
      "2025-05-12 19:20:48,572 - PriorityDownloader - INFO - Added 8 new rows for FNDE (1d)\n",
      "2025-05-12 19:20:48,597 - PriorityDownloader - INFO - Added 8 new rows for SPHQ (1d)\n",
      "2025-05-12 19:20:48,628 - PriorityDownloader - INFO - Added 8 new rows for FLRN (1d)\n",
      "2025-05-12 19:20:48,652 - PriorityDownloader - INFO - Added 8 new rows for HYEM (1d)\n",
      "2025-05-12 19:20:48,682 - PriorityDownloader - INFO - Added 8 new rows for MDY (1d)\n",
      "2025-05-12 19:20:48,721 - PriorityDownloader - INFO - Added 8 new rows for SIVR (1d)\n",
      "2025-05-12 19:20:48,748 - PriorityDownloader - INFO - Added 8 new rows for USIG (1d)\n",
      "2025-05-12 19:20:51,771 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  29 of 29 completed\n",
      "2025-05-12 19:20:52,668 - StockDownloader - WARNING - No data found for  (interval 1d)\n",
      "2025-05-12 19:20:52,801 - PriorityDownloader - INFO - Added 8 new rows for DIVI (1d)\n",
      "2025-05-12 19:20:52,819 - PriorityDownloader - INFO - Added 8 new rows for BUG (1d)\n",
      "2025-05-12 19:20:52,844 - PriorityDownloader - INFO - Added 8 new rows for IWB (1d)\n",
      "2025-05-12 19:20:52,875 - PriorityDownloader - INFO - Added 8 new rows for GSLC (1d)\n",
      "2025-05-12 19:20:52,896 - PriorityDownloader - INFO - Added 8 new rows for UCON (1d)\n",
      "2025-05-12 19:20:52,916 - PriorityDownloader - INFO - Added 8 new rows for CHAU (1d)\n",
      "2025-05-12 19:20:52,938 - PriorityDownloader - INFO - Added 8 new rows for AVDV (1d)\n",
      "2025-05-12 19:20:52,956 - PriorityDownloader - INFO - Added 8 new rows for BOTZ (1d)\n",
      "2025-05-12 19:20:52,977 - PriorityDownloader - INFO - Added 8 new rows for FNDA (1d)\n",
      "2025-05-12 19:20:52,999 - PriorityDownloader - INFO - Added 8 new rows for IBDQ (1d)\n",
      "2025-05-12 19:20:53,022 - PriorityDownloader - INFO - Added 8 new rows for GUNR (1d)\n",
      "2025-05-12 19:20:53,042 - PriorityDownloader - INFO - Added 8 new rows for PAAA (1d)\n",
      "2025-05-12 19:20:53,075 - PriorityDownloader - INFO - Added 8 new rows for AIQ (1d)\n",
      "2025-05-12 19:20:53,097 - PriorityDownloader - INFO - Added 8 new rows for VWOB (1d)\n",
      "2025-05-12 19:20:53,123 - PriorityDownloader - INFO - Added 8 new rows for SIL (1d)\n",
      "2025-05-12 19:20:53,153 - PriorityDownloader - INFO - Added 8 new rows for DBA (1d)\n",
      "2025-05-12 19:20:53,186 - PriorityDownloader - INFO - Added 8 new rows for SCZ (1d)\n",
      "2025-05-12 19:20:53,210 - PriorityDownloader - INFO - Added 8 new rows for DUHP (1d)\n",
      "2025-05-12 19:20:53,223 - PriorityDownloader - INFO - Added 8 new rows for SVOL (1d)\n",
      "2025-05-12 19:20:53,239 - PriorityDownloader - INFO - Added 8 new rows for AVEM (1d)\n",
      "2025-05-12 19:20:53,254 - PriorityDownloader - INFO - Added 8 new rows for DFSD (1d)\n",
      "2025-05-12 19:20:53,270 - PriorityDownloader - INFO - Added 8 new rows for HYLB (1d)\n",
      "2025-05-12 19:20:53,294 - PriorityDownloader - INFO - Added 8 new rows for FENY (1d)\n",
      "2025-05-12 19:20:53,315 - PriorityDownloader - INFO - Added 8 new rows for DFCF (1d)\n",
      "2025-05-12 19:20:53,335 - PriorityDownloader - INFO - Added 8 new rows for XSMO (1d)\n",
      "2025-05-12 19:20:53,361 - PriorityDownloader - INFO - Added 8 new rows for AMZY (1d)\n",
      "2025-05-12 19:20:53,427 - PriorityDownloader - INFO - Added 8 new rows for REM (1d)\n",
      "2025-05-12 19:20:53,458 - PriorityDownloader - INFO - Added 8 new rows for SLYV (1d)\n",
      "2025-05-12 19:20:53,496 - PriorityDownloader - INFO - Added 8 new rows for IYW (1d)\n",
      "2025-05-12 19:20:56,525 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:20:57,541 - PriorityDownloader - INFO - Added 8 new rows for BSCP (1d)\n",
      "2025-05-12 19:20:57,580 - PriorityDownloader - INFO - Added 8 new rows for BSCQ (1d)\n",
      "2025-05-12 19:20:57,596 - PriorityDownloader - INFO - Added 8 new rows for AIYY (1d)\n",
      "2025-05-12 19:20:57,606 - PriorityDownloader - INFO - Added 8 new rows for CGBL (1d)\n",
      "2025-05-12 19:20:57,623 - PriorityDownloader - INFO - Added 8 new rows for DBEF (1d)\n",
      "2025-05-12 19:20:57,643 - PriorityDownloader - INFO - Added 8 new rows for FELC (1d)\n",
      "2025-05-12 19:20:57,663 - PriorityDownloader - INFO - Added 8 new rows for EWU (1d)\n",
      "2025-05-12 19:20:57,702 - PriorityDownloader - INFO - Added 8 new rows for WEAT (1d)\n",
      "2025-05-12 19:20:57,723 - PriorityDownloader - INFO - Added 8 new rows for DFAE (1d)\n",
      "2025-05-12 19:20:57,750 - PriorityDownloader - INFO - Added 8 new rows for USD (1d)\n",
      "2025-05-12 19:20:57,774 - PriorityDownloader - INFO - Added 8 new rows for CGGO (1d)\n",
      "2025-05-12 19:20:57,788 - PriorityDownloader - INFO - Added 8 new rows for GBIL (1d)\n",
      "2025-05-12 19:20:57,813 - PriorityDownloader - INFO - Added 8 new rows for IUSV (1d)\n",
      "2025-05-12 19:20:57,851 - PriorityDownloader - INFO - Added 8 new rows for EFG (1d)\n",
      "2025-05-12 19:20:57,877 - PriorityDownloader - INFO - Added 8 new rows for BTCZ (1d)\n",
      "2025-05-12 19:20:57,889 - PriorityDownloader - INFO - Added 8 new rows for IBDV (1d)\n",
      "2025-05-12 19:20:57,912 - PriorityDownloader - INFO - Added 8 new rows for SPTM (1d)\n",
      "2025-05-12 19:20:57,942 - PriorityDownloader - INFO - Added 8 new rows for SPYU (1d)\n",
      "2025-05-12 19:20:57,957 - PriorityDownloader - INFO - Added 8 new rows for DPST (1d)\n",
      "2025-05-12 19:20:57,981 - PriorityDownloader - INFO - Added 8 new rows for OIH (1d)\n",
      "2025-05-12 19:20:58,010 - PriorityDownloader - INFO - Added 8 new rows for DJAN (1d)\n",
      "2025-05-12 19:20:58,026 - PriorityDownloader - INFO - Added 8 new rows for FALN (1d)\n",
      "2025-05-12 19:20:58,048 - PriorityDownloader - INFO - Added 8 new rows for EUFN (1d)\n",
      "2025-05-12 19:20:58,115 - PriorityDownloader - INFO - Added 8 new rows for PFFD (1d)\n",
      "2025-05-12 19:20:58,129 - PriorityDownloader - INFO - Added 8 new rows for METU (1d)\n",
      "2025-05-12 19:20:58,146 - PriorityDownloader - INFO - Added 8 new rows for AIRR (1d)\n",
      "2025-05-12 19:20:58,164 - PriorityDownloader - INFO - Added 8 new rows for ETHD (1d)\n",
      "2025-05-12 19:20:58,176 - PriorityDownloader - INFO - Added 8 new rows for DFAU (1d)\n",
      "2025-05-12 19:20:58,188 - PriorityDownloader - INFO - Added 8 new rows for CETH (1d)\n",
      "2025-05-12 19:20:58,206 - PriorityDownloader - INFO - Added 8 new rows for VFH (1d)\n",
      "2025-05-12 19:21:01,231 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:21:02,245 - PriorityDownloader - INFO - Added 8 new rows for FBCG (1d)\n",
      "2025-05-12 19:21:02,267 - PriorityDownloader - INFO - Added 8 new rows for IDV (1d)\n",
      "2025-05-12 19:21:02,293 - PriorityDownloader - INFO - Added 8 new rows for BSCS (1d)\n",
      "2025-05-12 19:21:02,314 - PriorityDownloader - INFO - Added 8 new rows for GSY (1d)\n",
      "2025-05-12 19:21:02,341 - PriorityDownloader - INFO - Added 8 new rows for ICSH (1d)\n",
      "2025-05-12 19:21:02,365 - PriorityDownloader - INFO - Added 8 new rows for ESGE (1d)\n",
      "2025-05-12 19:21:02,442 - PriorityDownloader - INFO - Added 8 new rows for DBC (1d)\n",
      "2025-05-12 19:21:02,467 - PriorityDownloader - INFO - Added 8 new rows for CTA (1d)\n",
      "2025-05-12 19:21:02,478 - PriorityDownloader - INFO - Added 8 new rows for FIAT (1d)\n",
      "2025-05-12 19:21:02,492 - PriorityDownloader - INFO - Added 8 new rows for SDIV (1d)\n",
      "2025-05-12 19:21:02,512 - PriorityDownloader - INFO - Added 8 new rows for AVL (1d)\n",
      "2025-05-12 19:21:02,527 - PriorityDownloader - INFO - Added 8 new rows for FHLC (1d)\n",
      "2025-05-12 19:21:02,545 - PriorityDownloader - INFO - Added 8 new rows for CGXU (1d)\n",
      "2025-05-12 19:21:02,557 - PriorityDownloader - INFO - Added 7 new rows for IBDU (1d)\n",
      "2025-05-12 19:21:02,575 - PriorityDownloader - INFO - Added 8 new rows for LVHI (1d)\n",
      "2025-05-12 19:21:02,592 - PriorityDownloader - INFO - Added 7 new rows for IBDS (1d)\n",
      "2025-05-12 19:21:02,610 - PriorityDownloader - INFO - Added 8 new rows for SCHK (1d)\n",
      "2025-05-12 19:21:02,628 - PriorityDownloader - INFO - Added 8 new rows for BUFD (1d)\n",
      "2025-05-12 19:21:02,641 - PriorityDownloader - INFO - Added 8 new rows for DFAX (1d)\n",
      "2025-05-12 19:21:02,660 - PriorityDownloader - INFO - Added 8 new rows for TLH (1d)\n",
      "2025-05-12 19:21:02,687 - PriorityDownloader - INFO - Added 8 new rows for JMST (1d)\n",
      "2025-05-12 19:21:02,707 - PriorityDownloader - INFO - Added 8 new rows for FJP (1d)\n",
      "2025-05-12 19:21:02,730 - PriorityDownloader - INFO - Added 7 new rows for IBDR (1d)\n",
      "2025-05-12 19:21:02,747 - PriorityDownloader - INFO - Added 8 new rows for DFIV (1d)\n",
      "2025-05-12 19:21:02,765 - PriorityDownloader - INFO - Added 8 new rows for DGRW (1d)\n",
      "2025-05-12 19:21:02,787 - PriorityDownloader - INFO - Added 8 new rows for FIXD (1d)\n",
      "2025-05-12 19:21:02,807 - PriorityDownloader - INFO - Added 8 new rows for RYLD (1d)\n",
      "2025-05-12 19:21:02,822 - PriorityDownloader - INFO - Added 8 new rows for QDTE (1d)\n",
      "2025-05-12 19:21:02,833 - PriorityDownloader - INFO - Added 8 new rows for EVTR (1d)\n",
      "2025-05-12 19:21:02,845 - PriorityDownloader - INFO - Added 8 new rows for FLCB (1d)\n",
      "2025-05-12 19:21:05,855 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:21:07,133 - PriorityDownloader - INFO - Added 8 new rows for BBIN (1d)\n",
      "2025-05-12 19:21:07,147 - PriorityDownloader - INFO - Added 8 new rows for JMEE (1d)\n",
      "2025-05-12 19:21:07,160 - PriorityDownloader - INFO - Added 8 new rows for WGMI (1d)\n",
      "2025-05-12 19:21:07,179 - PriorityDownloader - INFO - Added 8 new rows for SPGP (1d)\n",
      "2025-05-12 19:21:07,205 - PriorityDownloader - INFO - Added 8 new rows for HYMB (1d)\n",
      "2025-05-12 19:21:07,227 - PriorityDownloader - INFO - Added 8 new rows for JPIE (1d)\n",
      "2025-05-12 19:21:07,247 - PriorityDownloader - INFO - Added 8 new rows for IWN (1d)\n",
      "2025-05-12 19:21:07,288 - PriorityDownloader - INFO - Added 6 new rows for RR.L (1d)\n",
      "2025-05-12 19:21:07,333 - PriorityDownloader - INFO - Added 1 new rows for AVGO (1d)\n",
      "2025-05-12 19:21:07,376 - PriorityDownloader - INFO - Added 1 new rows for BRK-B (1d)\n",
      "2025-05-12 19:21:07,433 - PriorityDownloader - INFO - Added 1 new rows for TCEHY (1d)\n",
      "2025-05-12 19:21:07,486 - PriorityDownloader - INFO - Added 1 new rows for TCTZF (1d)\n",
      "2025-05-12 19:21:07,580 - PriorityDownloader - INFO - Added 1 new rows for COST (1d)\n",
      "2025-05-12 19:21:07,634 - PriorityDownloader - INFO - Added 1 new rows for LVMHF (1d)\n",
      "2025-05-12 19:21:07,690 - PriorityDownloader - INFO - Added 1 new rows for LVMUY (1d)\n",
      "2025-05-12 19:21:07,725 - PriorityDownloader - INFO - Added 1 new rows for JPM-PD (1d)\n",
      "2025-05-12 19:21:07,771 - PriorityDownloader - INFO - Added 1 new rows for JPM-PC (1d)\n",
      "2025-05-12 19:21:07,805 - PriorityDownloader - INFO - Added 1 new rows for BML-PG (1d)\n",
      "2025-05-12 19:21:07,841 - PriorityDownloader - INFO - Added 1 new rows for SAPGF (1d)\n",
      "2025-05-12 19:21:07,885 - PriorityDownloader - INFO - Added 1 new rows for BML-PH (1d)\n",
      "2025-05-12 19:21:07,917 - PriorityDownloader - INFO - Added 1 new rows for BML-PL (1d)\n",
      "2025-05-12 19:21:07,951 - PriorityDownloader - INFO - Added 1 new rows for BAC-PE (1d)\n",
      "2025-05-12 19:21:07,987 - PriorityDownloader - INFO - Added 1 new rows for IDCBY (1d)\n",
      "2025-05-12 19:21:08,020 - PriorityDownloader - INFO - Added 1 new rows for BAC-PK (1d)\n",
      "2025-05-12 19:21:08,090 - PriorityDownloader - INFO - Added 1 new rows for HESAY (1d)\n",
      "2025-05-12 19:21:08,120 - PriorityDownloader - INFO - Added 2 new rows for ASMLF (1d)\n",
      "2025-05-12 19:21:08,153 - PriorityDownloader - INFO - Added 1 new rows for ASML (1d)\n",
      "2025-05-12 19:21:08,200 - PriorityDownloader - INFO - Added 1 new rows for TMUS (1d)\n",
      "2025-05-12 19:21:08,299 - PriorityDownloader - INFO - Added 1 new rows for BML-PJ (1d)\n",
      "2025-05-12 19:21:11,356 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:21:12,891 - PriorityDownloader - INFO - Added 1 new rows for BAC-PB (1d)\n",
      "2025-05-12 19:21:12,974 - PriorityDownloader - INFO - Added 1 new rows for CSCO (1d)\n",
      "2025-05-12 19:21:13,023 - PriorityDownloader - INFO - Added 1 new rows for RHHVF (1d)\n",
      "2025-05-12 19:21:13,054 - PriorityDownloader - INFO - Added 1 new rows for ACGBY (1d)\n",
      "2025-05-12 19:21:13,091 - PriorityDownloader - INFO - Added 1 new rows for RHHBY (1d)\n",
      "2025-05-12 19:21:13,128 - PriorityDownloader - INFO - Added 1 new rows for TOYOF (1d)\n",
      "2025-05-12 19:21:13,190 - PriorityDownloader - INFO - Added 1 new rows for BABA (1d)\n",
      "2025-05-12 19:21:13,225 - PriorityDownloader - INFO - Added 1 new rows for NSRGY (1d)\n",
      "2025-05-12 19:21:13,271 - PriorityDownloader - INFO - Added 1 new rows for NSRGF (1d)\n",
      "2025-05-12 19:21:13,346 - PriorityDownloader - INFO - Added 2 new rows for ISRG (1d)\n",
      "2025-05-12 19:21:13,385 - PriorityDownloader - INFO - Added 1 new rows for CICHY (1d)\n",
      "2025-05-12 19:21:13,415 - PriorityDownloader - INFO - Added 1 new rows for RYDAF (1d)\n",
      "2025-05-12 19:21:13,447 - PriorityDownloader - INFO - Added 1 new rows for BACHY (1d)\n",
      "2025-05-12 19:21:13,484 - PriorityDownloader - INFO - Added 2 new rows for LRLCY (1d)\n",
      "2025-05-12 19:21:13,517 - PriorityDownloader - INFO - Added 1 new rows for WFC-PY (1d)\n",
      "2025-05-12 19:21:13,550 - PriorityDownloader - INFO - Added 1 new rows for PH (1d)\n",
      "2025-05-12 19:21:13,608 - PriorityDownloader - INFO - Added 1 new rows for NVSEF (1d)\n",
      "2025-05-12 19:21:13,663 - PriorityDownloader - INFO - Added 1 new rows for SHEL (1d)\n",
      "2025-05-12 19:21:13,734 - PriorityDownloader - INFO - Added 1 new rows for LRLCF (1d)\n",
      "2025-05-12 19:21:13,925 - PriorityDownloader - INFO - Added 1 new rows for QCOM (1d)\n",
      "2025-05-12 19:21:13,977 - PriorityDownloader - INFO - Added 1 new rows for HBCYF (1d)\n",
      "2025-05-12 19:21:14,026 - PriorityDownloader - INFO - Added 1 new rows for HSBC (1d)\n",
      "2025-05-12 19:21:14,070 - PriorityDownloader - INFO - Added 1 new rows for CMWAY (1d)\n",
      "2025-05-12 19:21:14,122 - PriorityDownloader - INFO - Added 1 new rows for SIEGY (1d)\n",
      "2025-05-12 19:21:14,165 - PriorityDownloader - INFO - Added 1 new rows for SMAWF (1d)\n",
      "2025-05-12 19:21:14,205 - PriorityDownloader - INFO - Added 1 new rows for INTU (1d)\n",
      "2025-05-12 19:21:17,244 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:21:19,337 - PriorityDownloader - INFO - Added 1 new rows for SBGSF (1d)\n",
      "2025-05-12 19:21:19,378 - PriorityDownloader - INFO - Added 1 new rows for SPGI (1d)\n",
      "2025-05-12 19:21:19,443 - PriorityDownloader - INFO - Added 1 new rows for IDEXY (1d)\n",
      "2025-05-12 19:21:19,545 - PriorityDownloader - INFO - Added 2 new rows for SBGSY (1d)\n",
      "2025-05-12 19:21:19,579 - PriorityDownloader - INFO - Added 1 new rows for MBFJF (1d)\n",
      "2025-05-12 19:21:19,700 - PriorityDownloader - INFO - Added 1 new rows for AMAT (1d)\n",
      "2025-05-12 19:21:19,771 - PriorityDownloader - INFO - Added 1 new rows for DTEGY (1d)\n",
      "2025-05-12 19:21:19,884 - PriorityDownloader - INFO - Added 1 new rows for CIHKY (1d)\n",
      "2025-05-12 19:21:19,986 - PriorityDownloader - INFO - Added 1 new rows for MUFG (1d)\n",
      "2025-05-12 19:21:20,095 - PriorityDownloader - INFO - Added 2 new rows for CME (1d)\n",
      "2025-05-12 19:21:20,181 - PriorityDownloader - INFO - Added 1 new rows for CMI (1d)\n",
      "2025-05-12 19:21:20,259 - PriorityDownloader - INFO - Added 1 new rows for CMS (1d)\n",
      "2025-05-12 19:21:20,342 - PriorityDownloader - INFO - Added 1 new rows for AMGN (1d)\n",
      "2025-05-12 19:21:20,731 - PriorityDownloader - INFO - Added 1 new rows for CNP (1d)\n",
      "2025-05-12 19:21:20,822 - PriorityDownloader - INFO - Added 1 new rows for COF (1d)\n",
      "2025-05-12 19:21:20,962 - PriorityDownloader - INFO - Added 1 new rows for COO (1d)\n",
      "2025-05-12 19:21:21,111 - PriorityDownloader - INFO - Added 1 new rows for CPB (1d)\n",
      "2025-05-12 19:21:21,366 - PriorityDownloader - INFO - Added 1 new rows for CVS (1d)\n",
      "2025-05-12 19:21:24,408 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:21:26,785 - PriorityDownloader - INFO - Added 1 new rows for CVX (1d)\n",
      "2025-05-12 19:21:26,868 - PriorityDownloader - INFO - Added 1 new rows for D (1d)\n",
      "2025-05-12 19:21:26,927 - PriorityDownloader - INFO - Added 1 new rows for DAL (1d)\n",
      "2025-05-12 19:21:26,969 - PriorityDownloader - INFO - Added 1 new rows for DD (1d)\n",
      "2025-05-12 19:21:27,046 - PriorityDownloader - INFO - Added 1 new rows for DE (1d)\n",
      "2025-05-12 19:21:27,114 - PriorityDownloader - INFO - Added 1 new rows for DFS (1d)\n",
      "2025-05-12 19:21:27,150 - PriorityDownloader - INFO - Added 1 new rows for DG (1d)\n",
      "2025-05-12 19:21:27,248 - PriorityDownloader - INFO - Added 1 new rows for DGX (1d)\n",
      "2025-05-12 19:21:27,307 - PriorityDownloader - INFO - Added 1 new rows for DHI (1d)\n",
      "2025-05-12 19:21:27,377 - PriorityDownloader - INFO - Added 1 new rows for DHR (1d)\n",
      "2025-05-12 19:21:27,450 - PriorityDownloader - INFO - Added 1 new rows for DLR (1d)\n",
      "2025-05-12 19:21:27,527 - PriorityDownloader - INFO - Added 1 new rows for DLTR (1d)\n",
      "2025-05-12 19:21:27,650 - PriorityDownloader - INFO - Added 1 new rows for DOV (1d)\n",
      "2025-05-12 19:21:27,726 - PriorityDownloader - INFO - Added 1 new rows for DOW (1d)\n",
      "2025-05-12 19:21:27,824 - PriorityDownloader - INFO - Added 1 new rows for DRI (1d)\n",
      "2025-05-12 19:21:27,915 - PriorityDownloader - INFO - Added 1 new rows for DTE (1d)\n",
      "2025-05-12 19:21:28,072 - PriorityDownloader - INFO - Added 1 new rows for DVA (1d)\n",
      "2025-05-12 19:21:28,188 - PriorityDownloader - INFO - Added 1 new rows for DVN (1d)\n",
      "2025-05-12 19:21:28,252 - PriorityDownloader - INFO - Added 1 new rows for DXC (1d)\n",
      "2025-05-12 19:21:28,323 - PriorityDownloader - INFO - Added 1 new rows for EA (1d)\n",
      "2025-05-12 19:21:28,441 - PriorityDownloader - INFO - Added 1 new rows for ECL (1d)\n",
      "2025-05-12 19:21:28,573 - PriorityDownloader - INFO - Added 1 new rows for ED (1d)\n",
      "2025-05-12 19:21:28,660 - PriorityDownloader - INFO - Added 1 new rows for EFX (1d)\n",
      "2025-05-12 19:21:28,733 - PriorityDownloader - INFO - Added 1 new rows for EIX (1d)\n",
      "2025-05-12 19:21:28,808 - PriorityDownloader - INFO - Added 1 new rows for EL (1d)\n",
      "2025-05-12 19:21:28,878 - PriorityDownloader - INFO - Added 1 new rows for EMN (1d)\n",
      "2025-05-12 19:21:29,003 - PriorityDownloader - INFO - Added 1 new rows for EMR (1d)\n",
      "2025-05-12 19:21:29,096 - PriorityDownloader - INFO - Added 1 new rows for EOG (1d)\n",
      "2025-05-12 19:21:32,135 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:21:34,414 - PriorityDownloader - INFO - Added 1 new rows for EQR (1d)\n",
      "2025-05-12 19:21:34,533 - PriorityDownloader - INFO - Added 1 new rows for ES (1d)\n",
      "2025-05-12 19:21:34,616 - PriorityDownloader - INFO - Added 1 new rows for ESS (1d)\n",
      "2025-05-12 19:21:34,724 - PriorityDownloader - INFO - Added 1 new rows for ETN (1d)\n",
      "2025-05-12 19:21:34,823 - PriorityDownloader - INFO - Added 1 new rows for ETR (1d)\n",
      "2025-05-12 19:21:34,901 - PriorityDownloader - INFO - Added 1 new rows for EVRG (1d)\n",
      "2025-05-12 19:21:35,029 - PriorityDownloader - INFO - Added 1 new rows for EW (1d)\n",
      "2025-05-12 19:21:35,086 - PriorityDownloader - INFO - Added 1 new rows for EXC (1d)\n",
      "2025-05-12 19:21:35,169 - PriorityDownloader - INFO - Added 1 new rows for EXPD (1d)\n",
      "2025-05-12 19:21:35,233 - PriorityDownloader - INFO - Added 1 new rows for EXPE (1d)\n",
      "2025-05-12 19:21:35,291 - PriorityDownloader - INFO - Added 1 new rows for EXR (1d)\n",
      "2025-05-12 19:21:35,365 - PriorityDownloader - INFO - Added 1 new rows for F (1d)\n",
      "2025-05-12 19:21:35,564 - PriorityDownloader - INFO - Added 1 new rows for FAST (1d)\n",
      "2025-05-12 19:21:35,634 - PriorityDownloader - INFO - Added 1 new rows for FCX (1d)\n",
      "2025-05-12 19:21:35,694 - PriorityDownloader - INFO - Added 1 new rows for FDX (1d)\n",
      "2025-05-12 19:21:35,762 - PriorityDownloader - INFO - Added 1 new rows for FE (1d)\n",
      "2025-05-12 19:21:35,815 - PriorityDownloader - INFO - Added 1 new rows for FFIV (1d)\n",
      "2025-05-12 19:21:35,932 - PriorityDownloader - INFO - Added 1 new rows for FIS (1d)\n",
      "2025-05-12 19:21:35,998 - PriorityDownloader - INFO - Added 1 new rows for FITB (1d)\n",
      "2025-05-12 19:21:36,059 - PriorityDownloader - INFO - Added 1 new rows for FLR (1d)\n",
      "2025-05-12 19:21:36,108 - PriorityDownloader - INFO - Added 1 new rows for FLS (1d)\n",
      "2025-05-12 19:21:36,176 - PriorityDownloader - INFO - Added 1 new rows for FMC (1d)\n",
      "2025-05-12 19:21:36,393 - PriorityDownloader - INFO - Added 1 new rows for FTV (1d)\n",
      "2025-05-12 19:21:36,444 - PriorityDownloader - INFO - Added 1 new rows for GD (1d)\n",
      "2025-05-12 19:21:36,532 - PriorityDownloader - INFO - Added 1 new rows for GE (1d)\n",
      "2025-05-12 19:21:36,616 - PriorityDownloader - INFO - Added 1 new rows for GIS (1d)\n",
      "2025-05-12 19:21:36,687 - PriorityDownloader - INFO - Added 1 new rows for GL (1d)\n",
      "2025-05-12 19:21:39,730 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:21:42,043 - PriorityDownloader - INFO - Added 1 new rows for GLW (1d)\n",
      "2025-05-12 19:21:42,100 - PriorityDownloader - INFO - Added 1 new rows for GM (1d)\n",
      "2025-05-12 19:21:42,139 - PriorityDownloader - INFO - Added 1 new rows for GPC (1d)\n",
      "2025-05-12 19:21:42,201 - PriorityDownloader - INFO - Added 1 new rows for GPN (1d)\n",
      "2025-05-12 19:21:42,245 - PriorityDownloader - INFO - Added 1 new rows for GS (1d)\n",
      "2025-05-12 19:21:42,354 - PriorityDownloader - INFO - Added 1 new rows for GWW (1d)\n",
      "2025-05-12 19:21:42,428 - PriorityDownloader - INFO - Added 1 new rows for HAL (1d)\n",
      "2025-05-12 19:21:42,523 - PriorityDownloader - INFO - Added 1 new rows for HAS (1d)\n",
      "2025-05-12 19:21:42,799 - PriorityDownloader - INFO - Added 1 new rows for HCA (1d)\n",
      "2025-05-12 19:21:42,884 - PriorityDownloader - INFO - Added 1 new rows for HES (1d)\n",
      "2025-05-12 19:21:42,957 - PriorityDownloader - INFO - Added 1 new rows for HIG (1d)\n",
      "2025-05-12 19:21:43,008 - PriorityDownloader - INFO - Added 1 new rows for HII (1d)\n",
      "2025-05-12 19:21:43,066 - PriorityDownloader - INFO - Added 1 new rows for HLT (1d)\n",
      "2025-05-12 19:21:43,105 - PriorityDownloader - INFO - Added 1 new rows for HOG (1d)\n",
      "2025-05-12 19:21:43,209 - PriorityDownloader - INFO - Added 1 new rows for HOLX (1d)\n",
      "2025-05-12 19:21:43,281 - PriorityDownloader - INFO - Added 1 new rows for HON (1d)\n",
      "2025-05-12 19:21:43,367 - PriorityDownloader - INFO - Added 1 new rows for HP (1d)\n",
      "2025-05-12 19:21:43,472 - PriorityDownloader - INFO - Added 1 new rows for HPQ (1d)\n",
      "2025-05-12 19:21:43,558 - PriorityDownloader - INFO - Added 1 new rows for HRB (1d)\n",
      "2025-05-12 19:21:43,680 - PriorityDownloader - INFO - Added 1 new rows for HRL (1d)\n",
      "2025-05-12 19:21:43,755 - PriorityDownloader - INFO - Added 1 new rows for HSIC (1d)\n",
      "2025-05-12 19:21:43,895 - PriorityDownloader - INFO - Added 1 new rows for HSY (1d)\n",
      "2025-05-12 19:21:43,971 - PriorityDownloader - INFO - Added 1 new rows for HUM (1d)\n",
      "2025-05-12 19:21:44,098 - PriorityDownloader - INFO - Added 1 new rows for IBM (1d)\n",
      "2025-05-12 19:21:44,179 - PriorityDownloader - INFO - Added 1 new rows for ICE (1d)\n",
      "2025-05-12 19:21:44,242 - PriorityDownloader - INFO - Added 1 new rows for IDXX (1d)\n",
      "2025-05-12 19:21:47,279 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:21:49,403 - PriorityDownloader - INFO - Added 1 new rows for IEX (1d)\n",
      "2025-05-12 19:21:49,472 - PriorityDownloader - INFO - Added 1 new rows for IFF (1d)\n",
      "2025-05-12 19:21:49,539 - PriorityDownloader - INFO - Added 1 new rows for ILMN (1d)\n",
      "2025-05-12 19:21:49,646 - PriorityDownloader - INFO - Added 1 new rows for INCY (1d)\n",
      "2025-05-12 19:21:49,701 - PriorityDownloader - INFO - Added 1 new rows for INFO (1d)\n",
      "2025-05-12 19:21:49,789 - PriorityDownloader - INFO - Added 1 new rows for IP (1d)\n",
      "2025-05-12 19:21:49,885 - PriorityDownloader - INFO - Added 1 new rows for IPG (1d)\n",
      "2025-05-12 19:21:49,952 - PriorityDownloader - INFO - Added 1 new rows for IPGP (1d)\n",
      "2025-05-12 19:21:50,016 - PriorityDownloader - INFO - Added 1 new rows for IQV (1d)\n",
      "2025-05-12 19:21:50,133 - PriorityDownloader - INFO - Added 1 new rows for IR (1d)\n",
      "2025-05-12 19:21:50,210 - PriorityDownloader - INFO - Added 1 new rows for IRM (1d)\n",
      "2025-05-12 19:21:50,279 - PriorityDownloader - INFO - Added 1 new rows for IT (1d)\n",
      "2025-05-12 19:21:50,346 - PriorityDownloader - INFO - Added 1 new rows for ITW (1d)\n",
      "2025-05-12 19:21:50,433 - PriorityDownloader - INFO - Added 1 new rows for IVZ (1d)\n",
      "2025-05-12 19:21:50,497 - PriorityDownloader - INFO - Added 1 new rows for J (1d)\n",
      "2025-05-12 19:21:50,764 - PriorityDownloader - INFO - Added 1 new rows for JKHY (1d)\n",
      "2025-05-12 19:21:50,837 - PriorityDownloader - INFO - Added 1 new rows for JNPR (1d)\n",
      "2025-05-12 19:21:50,915 - PriorityDownloader - INFO - Added 1 new rows for JWN (1d)\n",
      "2025-05-12 19:21:51,055 - PriorityDownloader - INFO - Added 1 new rows for K (1d)\n",
      "2025-05-12 19:21:51,177 - PriorityDownloader - INFO - Added 1 new rows for KEYS (1d)\n",
      "2025-05-12 19:21:51,219 - PriorityDownloader - INFO - Added 1 new rows for KHC (1d)\n",
      "2025-05-12 19:21:51,268 - PriorityDownloader - INFO - Added 1 new rows for KIM (1d)\n",
      "2025-05-12 19:21:51,352 - PriorityDownloader - INFO - Added 1 new rows for KMB (1d)\n",
      "2025-05-12 19:21:51,429 - PriorityDownloader - INFO - Added 1 new rows for KMI (1d)\n",
      "2025-05-12 19:21:51,576 - PriorityDownloader - INFO - Added 1 new rows for KMX (1d)\n",
      "2025-05-12 19:21:51,631 - PriorityDownloader - INFO - Added 1 new rows for KR (1d)\n",
      "2025-05-12 19:21:51,717 - PriorityDownloader - INFO - Added 1 new rows for KSS (1d)\n",
      "2025-05-12 19:21:54,752 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:21:56,914 - PriorityDownloader - INFO - Added 1 new rows for L (1d)\n",
      "2025-05-12 19:21:56,963 - PriorityDownloader - INFO - Added 1 new rows for LB (1d)\n",
      "2025-05-12 19:21:57,046 - PriorityDownloader - INFO - Added 1 new rows for LDOS (1d)\n",
      "2025-05-12 19:21:57,090 - PriorityDownloader - INFO - Added 1 new rows for LEG (1d)\n",
      "2025-05-12 19:21:57,158 - PriorityDownloader - INFO - Added 1 new rows for LEN (1d)\n",
      "2025-05-12 19:21:57,224 - PriorityDownloader - INFO - Added 1 new rows for LH (1d)\n",
      "2025-05-12 19:21:57,290 - PriorityDownloader - INFO - Added 1 new rows for LHX (1d)\n",
      "2025-05-12 19:21:57,399 - PriorityDownloader - INFO - Added 1 new rows for LIN (1d)\n",
      "2025-05-12 19:21:57,464 - PriorityDownloader - INFO - Added 1 new rows for LKQ (1d)\n",
      "2025-05-12 19:21:57,531 - PriorityDownloader - INFO - Added 1 new rows for LMT (1d)\n",
      "2025-05-12 19:21:57,601 - PriorityDownloader - INFO - Added 1 new rows for LNC (1d)\n",
      "2025-05-12 19:21:57,668 - PriorityDownloader - INFO - Added 1 new rows for LNT (1d)\n",
      "2025-05-12 19:21:57,802 - PriorityDownloader - INFO - Added 1 new rows for LOW (1d)\n",
      "2025-05-12 19:21:57,873 - PriorityDownloader - INFO - Added 1 new rows for LUV (1d)\n",
      "2025-05-12 19:21:57,949 - PriorityDownloader - INFO - Added 1 new rows for LW (1d)\n",
      "2025-05-12 19:21:58,009 - PriorityDownloader - INFO - Added 1 new rows for LYB (1d)\n",
      "2025-05-12 19:21:58,081 - PriorityDownloader - INFO - Added 1 new rows for M (1d)\n",
      "2025-05-12 19:21:58,164 - PriorityDownloader - INFO - Added 1 new rows for MAA (1d)\n",
      "2025-05-12 19:21:58,281 - PriorityDownloader - INFO - Added 1 new rows for MAC (1d)\n",
      "2025-05-12 19:21:58,338 - PriorityDownloader - INFO - Added 1 new rows for MAR (1d)\n",
      "2025-05-12 19:21:58,463 - PriorityDownloader - INFO - Added 1 new rows for MCD (1d)\n",
      "2025-05-12 19:21:58,540 - PriorityDownloader - INFO - Added 1 new rows for MCHP (1d)\n",
      "2025-05-12 19:21:58,596 - PriorityDownloader - INFO - Added 1 new rows for MCK (1d)\n",
      "2025-05-12 19:21:58,719 - PriorityDownloader - INFO - Added 8 new rows for MCO (1d)\n",
      "2025-05-12 19:21:58,761 - PriorityDownloader - INFO - Added 1 new rows for MET (1d)\n",
      "2025-05-12 19:21:58,816 - PriorityDownloader - INFO - Added 1 new rows for MGM (1d)\n",
      "2025-05-12 19:21:58,877 - PriorityDownloader - INFO - Added 1 new rows for MHK (1d)\n",
      "2025-05-12 19:21:58,942 - PriorityDownloader - INFO - Added 1 new rows for MKC (1d)\n",
      "2025-05-12 19:21:59,014 - PriorityDownloader - INFO - Added 1 new rows for MKTX (1d)\n",
      "2025-05-12 19:22:02,048 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:22:04,170 - PriorityDownloader - INFO - Added 1 new rows for MLM (1d)\n",
      "2025-05-12 19:22:04,224 - PriorityDownloader - INFO - Added 1 new rows for MMC (1d)\n",
      "2025-05-12 19:22:04,299 - PriorityDownloader - INFO - Added 1 new rows for MMM (1d)\n",
      "2025-05-12 19:22:04,422 - PriorityDownloader - INFO - Added 1 new rows for MNST (1d)\n",
      "2025-05-12 19:22:04,485 - PriorityDownloader - INFO - Added 1 new rows for MO (1d)\n",
      "2025-05-12 19:22:04,583 - PriorityDownloader - INFO - Added 1 new rows for MOS (1d)\n",
      "2025-05-12 19:22:04,679 - PriorityDownloader - INFO - Added 1 new rows for MPC (1d)\n",
      "2025-05-12 19:22:04,772 - PriorityDownloader - INFO - Added 1 new rows for MSCI (1d)\n",
      "2025-05-12 19:22:04,825 - PriorityDownloader - INFO - Added 1 new rows for MSI (1d)\n",
      "2025-05-12 19:22:04,944 - PriorityDownloader - INFO - Added 1 new rows for MTB (1d)\n",
      "2025-05-12 19:22:05,002 - PriorityDownloader - INFO - Added 1 new rows for MTD (1d)\n",
      "2025-05-12 19:22:05,067 - PriorityDownloader - INFO - Added 1 new rows for MU (1d)\n",
      "2025-05-12 19:22:05,120 - PriorityDownloader - INFO - Added 1 new rows for NAVI (1d)\n",
      "2025-05-12 19:22:05,162 - PriorityDownloader - INFO - Added 1 new rows for NCLH (1d)\n",
      "2025-05-12 19:22:05,202 - PriorityDownloader - INFO - Added 1 new rows for NDAQ (1d)\n",
      "2025-05-12 19:22:05,253 - PriorityDownloader - INFO - Added 1 new rows for NEE (1d)\n",
      "2025-05-12 19:22:05,427 - PriorityDownloader - INFO - Added 1 new rows for NI (1d)\n",
      "2025-05-12 19:22:05,500 - PriorityDownloader - INFO - Added 1 new rows for NOC (1d)\n",
      "2025-05-12 19:22:05,590 - PriorityDownloader - INFO - Added 1 new rows for NOV (1d)\n",
      "2025-05-12 19:22:05,691 - PriorityDownloader - INFO - Added 1 new rows for NRG (1d)\n",
      "2025-05-12 19:22:05,754 - PriorityDownloader - INFO - Added 1 new rows for NSC (1d)\n",
      "2025-05-12 19:22:05,857 - PriorityDownloader - INFO - Added 1 new rows for NTAP (1d)\n",
      "2025-05-12 19:22:05,983 - PriorityDownloader - INFO - Added 1 new rows for NUE (1d)\n",
      "2025-05-12 19:22:06,066 - PriorityDownloader - INFO - Added 1 new rows for NVR (1d)\n",
      "2025-05-12 19:22:06,136 - PriorityDownloader - INFO - Added 1 new rows for NWL (1d)\n",
      "2025-05-12 19:22:06,257 - PriorityDownloader - INFO - Added 1 new rows for NWS (1d)\n",
      "2025-05-12 19:22:06,286 - PriorityDownloader - INFO - Added 1 new rows for NWSA (1d)\n",
      "2025-05-12 19:22:06,326 - PriorityDownloader - INFO - Added 1 new rows for O (1d)\n",
      "2025-05-12 19:22:09,355 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:22:11,568 - PriorityDownloader - INFO - Added 1 new rows for OKE (1d)\n",
      "2025-05-12 19:22:11,633 - PriorityDownloader - INFO - Added 1 new rows for OMC (1d)\n",
      "2025-05-12 19:22:11,700 - PriorityDownloader - INFO - Added 1 new rows for ORLY (1d)\n",
      "2025-05-12 19:22:11,809 - PriorityDownloader - INFO - Added 1 new rows for OXY (1d)\n",
      "2025-05-12 19:22:11,867 - PriorityDownloader - INFO - Added 1 new rows for PAYC (1d)\n",
      "2025-05-12 19:22:11,920 - PriorityDownloader - INFO - Added 1 new rows for PAYX (1d)\n",
      "2025-05-12 19:22:11,982 - PriorityDownloader - INFO - Added 1 new rows for PCAR (1d)\n",
      "2025-05-12 19:22:12,048 - PriorityDownloader - INFO - Added 1 new rows for PEG (1d)\n",
      "2025-05-12 19:22:12,167 - PriorityDownloader - INFO - Added 1 new rows for PFG (1d)\n",
      "2025-05-12 19:22:12,215 - PriorityDownloader - INFO - Added 1 new rows for PGR (1d)\n",
      "2025-05-12 19:22:12,284 - PriorityDownloader - INFO - Added 1 new rows for BXP (1d)\n",
      "2025-05-12 19:22:12,602 - PriorityDownloader - INFO - Added 1 new rows for CAT (1d)\n",
      "2025-05-12 19:22:12,681 - PriorityDownloader - INFO - Added 1 new rows for CB (1d)\n",
      "2025-05-12 19:22:12,741 - PriorityDownloader - INFO - Added 1 new rows for CBOE (1d)\n",
      "2025-05-12 19:22:12,772 - PriorityDownloader - INFO - Added 1 new rows for CBRE (1d)\n",
      "2025-05-12 19:22:12,811 - PriorityDownloader - INFO - Added 1 new rows for CCI (1d)\n",
      "2025-05-12 19:22:12,932 - PriorityDownloader - INFO - Added 1 new rows for CE (1d)\n",
      "2025-05-12 19:22:13,023 - PriorityDownloader - INFO - Added 1 new rows for CF (1d)\n",
      "2025-05-12 19:22:13,058 - PriorityDownloader - INFO - Added 1 new rows for CFG (1d)\n",
      "2025-05-12 19:22:13,099 - PriorityDownloader - INFO - Added 1 new rows for CHD (1d)\n",
      "2025-05-12 19:22:13,167 - PriorityDownloader - INFO - Added 1 new rows for CHRW (1d)\n",
      "2025-05-12 19:22:13,216 - PriorityDownloader - INFO - Added 1 new rows for CHTR (1d)\n",
      "2025-05-12 19:22:13,276 - PriorityDownloader - INFO - Added 1 new rows for CI (1d)\n",
      "2025-05-12 19:22:13,343 - PriorityDownloader - INFO - Added 1 new rows for CINF (1d)\n",
      "2025-05-12 19:22:13,463 - PriorityDownloader - INFO - Added 1 new rows for CL (1d)\n",
      "2025-05-12 19:22:16,526 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:22:17,952 - PriorityDownloader - INFO - Added 1 new rows for CLX (1d)\n",
      "2025-05-12 19:22:18,018 - PriorityDownloader - INFO - Added 1 new rows for JCPN.L (1d)\n",
      "2025-05-12 19:22:18,073 - PriorityDownloader - INFO - Added 1 new rows for EADSF (1d)\n",
      "2025-05-12 19:22:18,106 - PriorityDownloader - INFO - Added 1 new rows for EADSY (1d)\n",
      "2025-05-12 19:22:18,267 - PriorityDownloader - INFO - Added 1 new rows for SONY (1d)\n",
      "2025-05-12 19:22:18,328 - PriorityDownloader - INFO - Added 1 new rows for WFC-PC (1d)\n",
      "2025-05-12 19:22:18,381 - PriorityDownloader - INFO - Added 1 new rows for ALIZY (1d)\n",
      "2025-05-12 19:22:18,452 - PriorityDownloader - INFO - Added 2 new rows for ESLOY (1d)\n",
      "2025-05-12 19:22:18,495 - PriorityDownloader - INFO - Added 2 new rows for HTHIY (1d)\n",
      "2025-05-12 19:22:18,587 - PriorityDownloader - INFO - Added 2 new rows for XIACY (1d)\n",
      "2025-05-12 19:22:18,617 - PriorityDownloader - INFO - Added 1 new rows for MPNGY (1d)\n",
      "2025-05-12 19:22:18,650 - PriorityDownloader - INFO - Added 2 new rows for PNGAY (1d)\n",
      "2025-05-12 19:22:18,683 - PriorityDownloader - INFO - Added 1 new rows for XIACF (1d)\n",
      "2025-05-12 19:22:18,721 - PriorityDownloader - INFO - Added 1 new rows for GILD (1d)\n",
      "2025-05-12 19:22:18,776 - PriorityDownloader - INFO - Added 1 new rows for VRTX (1d)\n",
      "2025-05-12 19:22:18,824 - PriorityDownloader - INFO - Added 2 new rows for BYDDF (1d)\n",
      "2025-05-12 19:22:18,864 - PriorityDownloader - INFO - Added 2 new rows for BYDDY (1d)\n",
      "2025-05-12 19:22:18,958 - PriorityDownloader - INFO - Added 2 new rows for SBUX (1d)\n",
      "2025-05-12 19:22:19,041 - PriorityDownloader - INFO - Added 2 new rows for SAFRY (1d)\n",
      "2025-05-12 19:22:19,074 - PriorityDownloader - INFO - Added 1 new rows for CFRUY (1d)\n",
      "2025-05-12 19:22:19,107 - PriorityDownloader - INFO - Added 1 new rows for CFRHF (1d)\n",
      "2025-05-12 19:22:19,141 - PriorityDownloader - INFO - Added 1 new rows for ABBNY (1d)\n",
      "2025-05-12 19:22:19,181 - PriorityDownloader - INFO - Added 1 new rows for ABLZF (1d)\n",
      "2025-05-12 19:22:22,214 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:22:23,661 - PriorityDownloader - INFO - Added 1 new rows for MRVL (1d)\n",
      "2025-05-12 19:22:23,705 - PriorityDownloader - INFO - Added 2 new rows for KYCCF (1d)\n",
      "2025-05-12 19:22:23,740 - PriorityDownloader - INFO - Added 1 new rows for RCRUY (1d)\n",
      "2025-05-12 19:22:23,765 - PriorityDownloader - INFO - Added 2 new rows for UNCRY (1d)\n",
      "2025-05-12 19:22:23,835 - PriorityDownloader - INFO - Added 1 new rows for SPOT (1d)\n",
      "2025-05-12 19:22:23,992 - PriorityDownloader - INFO - Added 1 new rows for KLAC (1d)\n",
      "2025-05-12 19:22:24,058 - PriorityDownloader - INFO - Added 1 new rows for SFTBF (1d)\n",
      "2025-05-12 19:22:24,098 - PriorityDownloader - INFO - Added 2 new rows for FRCOY (1d)\n",
      "2025-05-12 19:22:24,141 - PriorityDownloader - INFO - Added 2 new rows for AIQUY (1d)\n",
      "2025-05-12 19:22:24,233 - PriorityDownloader - INFO - Added 1 new rows for SFTBY (1d)\n",
      "2025-05-12 19:22:24,272 - PriorityDownloader - INFO - Added 1 new rows for SMFG (1d)\n",
      "2025-05-12 19:22:24,352 - PriorityDownloader - INFO - Added 1 new rows for USB-PH (1d)\n",
      "2025-05-12 19:22:24,436 - PriorityDownloader - INFO - Added 1 new rows for IBKR (1d)\n",
      "2025-05-12 19:22:24,481 - PriorityDownloader - INFO - Added 1 new rows for CRWD (1d)\n",
      "2025-05-12 19:22:24,506 - PriorityDownloader - INFO - Added 1 new rows for DBSDY (1d)\n",
      "2025-05-12 19:22:24,583 - PriorityDownloader - INFO - Added 1 new rows for EQIX (1d)\n",
      "2025-05-12 19:22:24,627 - PriorityDownloader - INFO - Added 1 new rows for RELX (1d)\n",
      "2025-05-12 19:22:24,753 - PriorityDownloader - INFO - Added 1 new rows for INFY (1d)\n",
      "2025-05-12 19:22:24,812 - PriorityDownloader - INFO - Added 1 new rows for PYPL (1d)\n",
      "2025-05-12 19:22:24,850 - PriorityDownloader - INFO - Added 1 new rows for EBBNF (1d)\n",
      "2025-05-12 19:22:24,932 - PriorityDownloader - INFO - Added 1 new rows for PROSY (1d)\n",
      "2025-05-12 19:22:25,018 - PriorityDownloader - INFO - Added 1 new rows for GS-PA (1d)\n",
      "2025-05-12 19:22:25,062 - PriorityDownloader - INFO - Added 1 new rows for IBDRY (1d)\n",
      "2025-05-12 19:22:28,103 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:22:29,837 - PriorityDownloader - INFO - Added 2 new rows for IBDSF (1d)\n",
      "2025-05-12 19:22:29,879 - PriorityDownloader - INFO - Added 1 new rows for CDNS (1d)\n",
      "2025-05-12 19:22:30,044 - PriorityDownloader - INFO - Added 1 new rows for MS-PA (1d)\n",
      "2025-05-12 19:22:30,083 - PriorityDownloader - INFO - Added 1 new rows for ZURVY (1d)\n",
      "2025-05-12 19:22:30,129 - PriorityDownloader - INFO - Added 1 new rows for WELL (1d)\n",
      "2025-05-12 19:22:30,190 - PriorityDownloader - INFO - Added 2 new rows for NTES (1d)\n",
      "2025-05-12 19:22:30,284 - PriorityDownloader - INFO - Added 1 new rows for MKKGY (1d)\n",
      "2025-05-12 19:22:30,321 - PriorityDownloader - INFO - Added 1 new rows for SHECY (1d)\n",
      "2025-05-12 19:22:30,362 - PriorityDownloader - INFO - Added 1 new rows for ITOCY (1d)\n",
      "2025-05-12 19:22:30,409 - PriorityDownloader - INFO - Added 1 new rows for TKOMY (1d)\n",
      "2025-05-12 19:22:30,468 - PriorityDownloader - INFO - Added 1 new rows for EQNR (1d)\n",
      "2025-05-12 19:22:30,513 - PriorityDownloader - INFO - Added 8 new rows for ADSK (1d)\n",
      "2025-05-12 19:22:30,566 - PriorityDownloader - INFO - Added 8 new rows for BBVA (1d)\n",
      "2025-05-12 19:22:30,611 - PriorityDownloader - INFO - Added 8 new rows for RYCEF (1d)\n",
      "2025-05-12 19:22:30,710 - PriorityDownloader - INFO - Added 7 new rows for DBK.DE (1d)\n",
      "2025-05-12 19:22:30,752 - PriorityDownloader - INFO - Added 7 new rows for ENEL.MI (1d)\n",
      "2025-05-12 19:22:30,792 - PriorityDownloader - INFO - Added 7 new rows for FRE.DE (1d)\n",
      "2025-05-12 19:22:30,833 - PriorityDownloader - INFO - Added 7 new rows for IBE.MC (1d)\n",
      "2025-05-12 19:22:30,875 - PriorityDownloader - INFO - Added 7 new rows for INGA.AS (1d)\n",
      "2025-05-12 19:22:30,922 - PriorityDownloader - INFO - Added 7 new rows for ISP.MI (1d)\n",
      "2025-05-12 19:22:30,965 - PriorityDownloader - INFO - Added 7 new rows for EOAN.DE (1d)\n",
      "2025-05-12 19:22:31,068 - PriorityDownloader - INFO - Added 7 new rows for G.MI (1d)\n",
      "2025-05-12 19:22:31,117 - PriorityDownloader - INFO - Added 7 new rows for ALV.DE (1d)\n",
      "2025-05-12 19:22:31,159 - PriorityDownloader - INFO - Added 7 new rows for BBVA.MC (1d)\n",
      "2025-05-12 19:22:31,203 - PriorityDownloader - INFO - Added 7 new rows for BAYN.DE (1d)\n",
      "2025-05-12 19:22:31,254 - PriorityDownloader - INFO - Added 7 new rows for ABI.BR (1d)\n",
      "2025-05-12 19:22:31,297 - PriorityDownloader - INFO - Added 7 new rows for ENI.MI (1d)\n",
      "2025-05-12 19:22:34,325 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:22:37,108 - PriorityDownloader - INFO - Added 7 new rows for BMW.DE (1d)\n",
      "2025-05-12 19:22:37,151 - PriorityDownloader - INFO - Added 7 new rows for EURUSD=X (1d)\n",
      "2025-05-12 19:22:37,196 - PriorityDownloader - INFO - Added 7 new rows for ASML.AS (1d)\n",
      "2025-05-12 19:22:37,239 - PriorityDownloader - INFO - Added 7 new rows for DTE.DE (1d)\n",
      "2025-05-12 19:22:37,281 - PriorityDownloader - INFO - Added 7 new rows for BAS.DE (1d)\n",
      "2025-05-12 19:22:37,324 - PriorityDownloader - INFO - Added 7 new rows for MT.AS (1d)\n",
      "2025-05-12 19:22:37,360 - PriorityDownloader - INFO - Added 7 new rows for RMS.PA (1d)\n",
      "2025-05-12 19:22:37,396 - PriorityDownloader - INFO - Added 7 new rows for STLAP.PA (1d)\n",
      "2025-05-12 19:22:37,437 - PriorityDownloader - INFO - Added 7 new rows for STMPA.PA (1d)\n",
      "2025-05-12 19:22:37,475 - PriorityDownloader - INFO - Added 8 new rows for V (1d)\n",
      "2025-05-12 19:22:37,515 - PriorityDownloader - INFO - Added 8 new rows for JPM (1d)\n",
      "2025-05-12 19:22:37,650 - PriorityDownloader - INFO - Added 8 new rows for JNJ (1d)\n",
      "2025-05-12 19:22:37,728 - PriorityDownloader - INFO - Added 8 new rows for WMT (1d)\n",
      "2025-05-12 19:22:37,798 - PriorityDownloader - INFO - Added 7 new rows for PG (1d)\n",
      "2025-05-12 19:22:37,867 - PriorityDownloader - INFO - Added 8 new rows for MA (1d)\n",
      "2025-05-12 19:22:37,909 - PriorityDownloader - INFO - Added 8 new rows for DIS (1d)\n",
      "2025-05-12 19:22:38,046 - PriorityDownloader - INFO - Added 8 new rows for HD (1d)\n",
      "2025-05-12 19:22:38,118 - PriorityDownloader - INFO - Added 8 new rows for VZ (1d)\n",
      "2025-05-12 19:22:38,176 - PriorityDownloader - INFO - Added 7 new rows for UNH (1d)\n",
      "2025-05-12 19:22:38,238 - PriorityDownloader - INFO - Added 8 new rows for KO (1d)\n",
      "2025-05-12 19:22:38,313 - PriorityDownloader - INFO - Added 8 new rows for PFE (1d)\n",
      "2025-05-12 19:22:38,447 - PriorityDownloader - INFO - Added 7 new rows for XOM (1d)\n",
      "2025-05-12 19:22:38,527 - PriorityDownloader - INFO - Added 8 new rows for MRK (1d)\n",
      "2025-05-12 19:22:38,603 - PriorityDownloader - INFO - Added 7 new rows for NKE (1d)\n",
      "2025-05-12 19:22:38,667 - PriorityDownloader - INFO - Added 8 new rows for ABT (1d)\n",
      "2025-05-12 19:22:38,780 - PriorityDownloader - INFO - Added 8 new rows for PEP (1d)\n",
      "2025-05-12 19:22:38,851 - PriorityDownloader - INFO - Added 8 new rows for CRM (1d)\n",
      "2025-05-12 19:22:38,897 - PriorityDownloader - INFO - Added 8 new rows for TMO (1d)\n",
      "2025-05-12 19:22:38,960 - PriorityDownloader - INFO - Added 8 new rows for MDT (1d)\n",
      "2025-05-12 19:22:39,041 - PriorityDownloader - INFO - Added 8 new rows for LLY (1d)\n",
      "2025-05-12 19:22:42,098 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:22:44,427 - PriorityDownloader - INFO - Added 8 new rows for MS (1d)\n",
      "2025-05-12 19:22:44,493 - PriorityDownloader - INFO - Added 8 new rows for BA (1d)\n",
      "2025-05-12 19:22:44,561 - PriorityDownloader - INFO - Added 8 new rows for STLA (1d)\n",
      "2025-05-12 19:22:44,665 - PriorityDownloader - INFO - Added 7 new rows for NESN.SW (1d)\n",
      "2025-05-12 19:22:44,716 - PriorityDownloader - INFO - Added 8 new rows for A (1d)\n",
      "2025-05-12 19:22:44,758 - PriorityDownloader - INFO - Added 8 new rows for AAL (1d)\n",
      "2025-05-12 19:22:44,796 - PriorityDownloader - INFO - Added 8 new rows for AAP (1d)\n",
      "2025-05-12 19:22:44,837 - PriorityDownloader - INFO - Added 8 new rows for ACN (1d)\n",
      "2025-05-12 19:22:44,884 - PriorityDownloader - INFO - Added 8 new rows for ADI (1d)\n",
      "2025-05-12 19:22:44,944 - PriorityDownloader - INFO - Added 8 new rows for ADM (1d)\n",
      "2025-05-12 19:22:45,086 - PriorityDownloader - INFO - Added 8 new rows for ADP (1d)\n",
      "2025-05-12 19:22:45,143 - PriorityDownloader - INFO - Added 8 new rows for AEE (1d)\n",
      "2025-05-12 19:22:45,193 - PriorityDownloader - INFO - Added 8 new rows for AEP (1d)\n",
      "2025-05-12 19:22:45,259 - PriorityDownloader - INFO - Added 7 new rows for AES (1d)\n",
      "2025-05-12 19:22:45,311 - PriorityDownloader - INFO - Added 8 new rows for AFL (1d)\n",
      "2025-05-12 19:22:45,436 - PriorityDownloader - INFO - Added 8 new rows for AIG (1d)\n",
      "2025-05-12 19:22:45,500 - PriorityDownloader - INFO - Added 8 new rows for AIV (1d)\n",
      "2025-05-12 19:22:45,542 - PriorityDownloader - INFO - Added 8 new rows for AIZ (1d)\n",
      "2025-05-12 19:22:45,587 - PriorityDownloader - INFO - Added 8 new rows for AJG (1d)\n",
      "2025-05-12 19:22:45,640 - PriorityDownloader - INFO - Added 8 new rows for AKAM (1d)\n",
      "2025-05-12 19:22:45,682 - PriorityDownloader - INFO - Added 8 new rows for ALB (1d)\n",
      "2025-05-12 19:22:45,727 - PriorityDownloader - INFO - Added 8 new rows for ALGN (1d)\n",
      "2025-05-12 19:22:45,773 - PriorityDownloader - INFO - Added 8 new rows for ALK (1d)\n",
      "2025-05-12 19:22:45,880 - PriorityDownloader - INFO - Added 8 new rows for ALL (1d)\n",
      "2025-05-12 19:22:45,924 - PriorityDownloader - INFO - Added 8 new rows for ALLE (1d)\n",
      "2025-05-12 19:22:45,967 - PriorityDownloader - INFO - Added 8 new rows for AMD (1d)\n",
      "2025-05-12 19:22:46,022 - PriorityDownloader - INFO - Added 8 new rows for AME (1d)\n",
      "2025-05-12 19:22:46,073 - PriorityDownloader - INFO - Added 8 new rows for AMP (1d)\n",
      "2025-05-12 19:22:46,108 - PriorityDownloader - INFO - Added 8 new rows for AMT (1d)\n",
      "2025-05-12 19:22:46,148 - PriorityDownloader - INFO - Added 8 new rows for ANSS (1d)\n",
      "2025-05-12 19:22:49,175 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:22:51,605 - PriorityDownloader - INFO - Added 8 new rows for AON (1d)\n",
      "2025-05-12 19:22:51,663 - PriorityDownloader - INFO - Added 8 new rows for AOS (1d)\n",
      "2025-05-12 19:22:51,719 - PriorityDownloader - INFO - Added 8 new rows for APA (1d)\n",
      "2025-05-12 19:22:51,773 - PriorityDownloader - INFO - Added 8 new rows for APTV (1d)\n",
      "2025-05-12 19:22:51,809 - PriorityDownloader - INFO - Added 8 new rows for APD (1d)\n",
      "2025-05-12 19:22:51,926 - PriorityDownloader - INFO - Added 8 new rows for APH (1d)\n",
      "2025-05-12 19:22:51,972 - PriorityDownloader - INFO - Added 8 new rows for ARE (1d)\n",
      "2025-05-12 19:22:52,026 - PriorityDownloader - INFO - Added 8 new rows for ATO (1d)\n",
      "2025-05-12 19:22:52,082 - PriorityDownloader - INFO - Added 8 new rows for AVB (1d)\n",
      "2025-05-12 19:22:52,134 - PriorityDownloader - INFO - Added 8 new rows for AVY (1d)\n",
      "2025-05-12 19:22:52,194 - PriorityDownloader - INFO - Added 8 new rows for AWK (1d)\n",
      "2025-05-12 19:22:52,237 - PriorityDownloader - INFO - Added 7 new rows for AXP (1d)\n",
      "2025-05-12 19:22:52,364 - PriorityDownloader - INFO - Added 8 new rows for AZO (1d)\n",
      "2025-05-12 19:22:52,417 - PriorityDownloader - INFO - Added 7 new rows for BAC (1d)\n",
      "2025-05-12 19:22:52,483 - PriorityDownloader - INFO - Added 8 new rows for BAX (1d)\n",
      "2025-05-12 19:22:52,550 - PriorityDownloader - INFO - Added 7 new rows for BBY (1d)\n",
      "2025-05-12 19:22:52,609 - PriorityDownloader - INFO - Added 8 new rows for BDX (1d)\n",
      "2025-05-12 19:22:52,739 - PriorityDownloader - INFO - Added 8 new rows for BEN (1d)\n",
      "2025-05-12 19:22:52,792 - PriorityDownloader - INFO - Added 8 new rows for BIIB (1d)\n",
      "2025-05-12 19:22:52,847 - PriorityDownloader - INFO - Added 7 new rows for BK (1d)\n",
      "2025-05-12 19:22:52,908 - PriorityDownloader - INFO - Added 8 new rows for BKNG (1d)\n",
      "2025-05-12 19:22:52,954 - PriorityDownloader - INFO - Added 8 new rows for BKR (1d)\n",
      "2025-05-12 19:22:53,081 - PriorityDownloader - INFO - Added 8 new rows for BLK (1d)\n",
      "2025-05-12 19:22:53,125 - PriorityDownloader - INFO - Added 8 new rows for BMY (1d)\n",
      "2025-05-12 19:22:53,192 - PriorityDownloader - INFO - Added 8 new rows for BR (1d)\n",
      "2025-05-12 19:22:53,228 - PriorityDownloader - INFO - Added 8 new rows for BSX (1d)\n",
      "2025-05-12 19:22:53,273 - PriorityDownloader - INFO - Added 7 new rows for BWA (1d)\n",
      "2025-05-12 19:22:53,318 - PriorityDownloader - INFO - Added 8 new rows for BACHF (1d)\n",
      "2025-05-12 19:22:53,350 - PriorityDownloader - INFO - Added 7 new rows for ESLOF (1d)\n",
      "2025-05-12 19:22:53,379 - PriorityDownloader - INFO - Added 8 new rows for SNYNF (1d)\n",
      "2025-05-12 19:22:56,394 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:22:57,735 - PriorityDownloader - INFO - Added 8 new rows for PIAIF (1d)\n",
      "2025-05-12 19:22:57,761 - PriorityDownloader - INFO - Added 7 new rows for WDAY (1d)\n",
      "2025-05-12 19:22:57,784 - PriorityDownloader - INFO - Added 7 new rows for ITOCF (1d)\n",
      "2025-05-12 19:22:57,806 - PriorityDownloader - INFO - Added 8 new rows for RLLCF (1d)\n",
      "2025-05-12 19:22:57,829 - PriorityDownloader - INFO - Added 7 new rows for MKGAF (1d)\n",
      "2025-05-12 19:22:57,856 - PriorityDownloader - INFO - Added 8 new rows for CMXHF (1d)\n",
      "2025-05-12 19:22:57,889 - PriorityDownloader - INFO - Added 8 new rows for ATLKY (1d)\n",
      "2025-05-12 19:22:57,922 - PriorityDownloader - INFO - Added 8 new rows for MS-PK (1d)\n",
      "2025-05-12 19:22:57,948 - PriorityDownloader - INFO - Added 8 new rows for TOELY (1d)\n",
      "2025-05-12 19:22:57,986 - PriorityDownloader - INFO - Added 8 new rows for GS-PD (1d)\n",
      "2025-05-12 19:22:58,015 - PriorityDownloader - INFO - Added 8 new rows for MS-PI (1d)\n",
      "2025-05-12 19:22:58,041 - PriorityDownloader - INFO - Added 8 new rows for PBR-A (1d)\n",
      "2025-05-12 19:22:58,077 - PriorityDownloader - INFO - Added 8 new rows for NTTYY (1d)\n",
      "2025-05-12 19:22:58,116 - PriorityDownloader - INFO - Added 8 new rows for MS-PF (1d)\n",
      "2025-05-12 19:22:58,148 - PriorityDownloader - INFO - Added 7 new rows for BCDRF (1d)\n",
      "2025-05-12 19:22:58,175 - PriorityDownloader - INFO - Added 8 new rows for DELL (1d)\n",
      "2025-05-12 19:22:58,263 - PriorityDownloader - INFO - Added 8 new rows for CTAS (1d)\n",
      "2025-05-12 19:22:58,307 - PriorityDownloader - INFO - Added 8 new rows for ABNB (1d)\n",
      "2025-05-12 19:22:58,324 - PriorityDownloader - INFO - Added 8 new rows for MS-PE (1d)\n",
      "2025-05-12 19:22:58,347 - PriorityDownloader - INFO - Added 8 new rows for LNSTY (1d)\n",
      "2025-05-12 19:22:58,367 - PriorityDownloader - INFO - Added 7 new rows for LDNXF (1d)\n",
      "2025-05-12 19:22:58,397 - PriorityDownloader - INFO - Added 8 new rows for ISNPY (1d)\n",
      "2025-05-12 19:22:58,425 - PriorityDownloader - INFO - Added 8 new rows for RACE (1d)\n",
      "2025-05-12 19:22:58,449 - PriorityDownloader - INFO - Added 8 new rows for MDLZ (1d)\n",
      "2025-05-12 19:22:58,486 - PriorityDownloader - INFO - Added 8 new rows for HNHPF (1d)\n",
      "2025-05-12 19:22:58,517 - PriorityDownloader - INFO - Added 8 new rows for AAGIY (1d)\n",
      "2025-05-12 19:22:58,548 - PriorityDownloader - INFO - Added 8 new rows for SCCO (1d)\n",
      "2025-05-12 19:22:58,584 - PriorityDownloader - INFO - Added 8 new rows for DASH (1d)\n",
      "2025-05-12 19:22:58,599 - PriorityDownloader - INFO - Added 8 new rows for USB-PP (1d)\n",
      "2025-05-12 19:22:58,615 - PriorityDownloader - INFO - Added 8 new rows for COIN (1d)\n",
      "2025-05-12 19:23:01,631 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:23:02,848 - PriorityDownloader - INFO - Added 7 new rows for NTDOF (1d)\n",
      "2025-05-12 19:23:02,878 - PriorityDownloader - INFO - Added 8 new rows for FTNT (1d)\n",
      "2025-05-12 19:23:02,908 - PriorityDownloader - INFO - Added 8 new rows for REGN (1d)\n",
      "2025-05-12 19:23:02,955 - PriorityDownloader - INFO - Added 8 new rows for NTDOY (1d)\n",
      "2025-05-12 19:23:02,994 - PriorityDownloader - INFO - Added 8 new rows for MURGY (1d)\n",
      "2025-05-12 19:23:03,025 - PriorityDownloader - INFO - Added 7 new rows for MURGF (1d)\n",
      "2025-05-12 19:23:03,051 - PriorityDownloader - INFO - Added 8 new rows for PBCRY (1d)\n",
      "2025-05-12 19:23:03,084 - PriorityDownloader - INFO - Added 7 new rows for WEBNF (1d)\n",
      "2025-05-12 19:23:03,117 - PriorityDownloader - INFO - Added 8 new rows for ENLAY (1d)\n",
      "2025-05-12 19:23:03,220 - PriorityDownloader - INFO - Added 8 new rows for NABZY (1d)\n",
      "2025-05-12 19:23:03,264 - PriorityDownloader - INFO - Added 7 new rows for GLAXF (1d)\n",
      "2025-05-12 19:23:03,291 - PriorityDownloader - INFO - Added 8 new rows for TEAM (1d)\n",
      "2025-05-12 19:23:03,315 - PriorityDownloader - INFO - Added 8 new rows for CHGCY (1d)\n",
      "2025-05-12 19:23:03,336 - PriorityDownloader - INFO - Added 5 new rows for 0MMG.IL (1d)\n",
      "2025-05-12 19:23:03,362 - PriorityDownloader - INFO - Added 8 new rows for BUDFF (1d)\n",
      "2025-05-12 19:23:03,390 - PriorityDownloader - INFO - Added 7 new rows for BNPQF (1d)\n",
      "2025-05-12 19:23:03,419 - PriorityDownloader - INFO - Added 8 new rows for BNPQY (1d)\n",
      "2025-05-12 19:23:03,455 - PriorityDownloader - INFO - Added 8 new rows for SNPS (1d)\n",
      "2025-05-12 19:23:03,495 - PriorityDownloader - INFO - Added 8 new rows for ATLCY (1d)\n",
      "2025-05-12 19:23:03,523 - PriorityDownloader - INFO - Added 8 new rows for BPAQF (1d)\n",
      "2025-05-12 19:23:03,554 - PriorityDownloader - INFO - Added 8 new rows for AXAHY (1d)\n",
      "2025-05-12 19:23:03,590 - PriorityDownloader - INFO - Added 8 new rows for CSLLY (1d)\n",
      "2025-05-12 19:23:03,622 - PriorityDownloader - INFO - Added 7 new rows for MSTR (1d)\n",
      "2025-05-12 19:23:03,652 - PriorityDownloader - INFO - Added 1 new rows for 0MPY.IL (1d)\n",
      "2025-05-12 19:23:03,667 - PriorityDownloader - INFO - Added 8 new rows for AZNCF (1d)\n",
      "2025-05-12 19:23:03,699 - PriorityDownloader - INFO - Added 7 new rows for IDEXF (1d)\n",
      "2025-05-12 19:23:03,720 - PriorityDownloader - INFO - Added 7 new rows for HEMA.PA (1d)\n",
      "2025-05-12 19:23:03,733 - PriorityDownloader - INFO - Added 6 new rows for WDTE.L (1d)\n",
      "2025-05-12 19:23:03,743 - PriorityDownloader - INFO - Added 7 new rows for WHCE.L (1d)\n",
      "2025-05-12 19:23:03,755 - PriorityDownloader - INFO - Added 8 new rows for CONL (1d)\n",
      "2025-05-12 19:23:06,769 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:23:08,568 - PriorityDownloader - INFO - Added 8 new rows for AMZU (1d)\n",
      "2025-05-12 19:23:08,588 - PriorityDownloader - INFO - Added 7 new rows for CBAUF (1d)\n",
      "2025-05-12 19:23:08,611 - PriorityDownloader - INFO - Added 6 new rows for EWSP.L (1d)\n",
      "2025-05-12 19:23:08,622 - PriorityDownloader - INFO - Added 8 new rows for GGLL (1d)\n",
      "2025-05-12 19:23:08,635 - PriorityDownloader - INFO - Added 8 new rows for MAGS (1d)\n",
      "2025-05-12 19:23:08,665 - PriorityDownloader - INFO - Added 1 new rows for XEL (1d)\n",
      "2025-05-12 19:23:08,741 - PriorityDownloader - INFO - Added 1 new rows for XRAY (1d)\n",
      "2025-05-12 19:23:08,804 - PriorityDownloader - INFO - Added 1 new rows for XRX (1d)\n",
      "2025-05-12 19:23:08,880 - PriorityDownloader - INFO - Added 1 new rows for XYL (1d)\n",
      "2025-05-12 19:23:08,970 - PriorityDownloader - INFO - Added 1 new rows for YUM (1d)\n",
      "2025-05-12 19:23:09,015 - PriorityDownloader - INFO - Added 1 new rows for ZBH (1d)\n",
      "2025-05-12 19:23:09,060 - PriorityDownloader - INFO - Added 1 new rows for ZBRA (1d)\n",
      "2025-05-12 19:23:09,116 - PriorityDownloader - INFO - Added 1 new rows for ZION (1d)\n",
      "2025-05-12 19:23:09,173 - PriorityDownloader - INFO - Added 1 new rows for ZTS (1d)\n",
      "2025-05-12 19:23:09,205 - PriorityDownloader - INFO - Added 1 new rows for ADS.DE (1d)\n",
      "2025-05-12 19:23:09,253 - PriorityDownloader - INFO - Added 1 new rows for CON.DE (1d)\n",
      "2025-05-12 19:23:09,294 - PriorityDownloader - INFO - Added 1 new rows for DB1.DE (1d)\n",
      "2025-05-12 19:23:09,404 - PriorityDownloader - INFO - Added 1 new rows for LHA.DE (1d)\n",
      "2025-05-12 19:23:09,455 - PriorityDownloader - INFO - Added 1 new rows for LIN.DE (1d)\n",
      "2025-05-12 19:23:09,497 - PriorityDownloader - INFO - Added 1 new rows for MUV2.DE (1d)\n",
      "2025-05-12 19:23:09,545 - PriorityDownloader - INFO - Added 1 new rows for RWE.DE (1d)\n",
      "2025-05-12 19:23:09,593 - PriorityDownloader - INFO - Added 1 new rows for SAP.DE (1d)\n",
      "2025-05-12 19:23:09,642 - PriorityDownloader - INFO - Added 1 new rows for SIE.DE (1d)\n",
      "2025-05-12 19:23:09,697 - PriorityDownloader - INFO - Added 1 new rows for VOW3.DE (1d)\n",
      "2025-05-12 19:23:09,740 - PriorityDownloader - INFO - Added 1 new rows for ZAL.DE (1d)\n",
      "2025-05-12 19:23:09,769 - PriorityDownloader - INFO - Added 1 new rows for AAL.L (1d)\n",
      "2025-05-12 19:23:09,876 - PriorityDownloader - INFO - Added 1 new rows for ABF.L (1d)\n",
      "2025-05-12 19:23:09,931 - PriorityDownloader - INFO - Added 1 new rows for ADM.L (1d)\n",
      "2025-05-12 19:23:09,973 - PriorityDownloader - INFO - Added 1 new rows for AHT.L (1d)\n",
      "2025-05-12 19:23:10,031 - PriorityDownloader - INFO - Added 1 new rows for AV.L (1d)\n",
      "2025-05-12 19:23:13,074 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:23:14,832 - PriorityDownloader - INFO - Added 1 new rows for BA.L (1d)\n",
      "2025-05-12 19:23:14,890 - PriorityDownloader - INFO - Added 1 new rows for BARC.L (1d)\n",
      "2025-05-12 19:23:14,947 - PriorityDownloader - INFO - Added 1 new rows for BATS.L (1d)\n",
      "2025-05-12 19:23:15,055 - PriorityDownloader - INFO - Added 1 new rows for BP.L (1d)\n",
      "2025-05-12 19:23:15,116 - PriorityDownloader - INFO - Added 1 new rows for BTI (1d)\n",
      "2025-05-12 19:23:15,177 - PriorityDownloader - INFO - Added 1 new rows for CNA.L (1d)\n",
      "2025-05-12 19:23:15,229 - PriorityDownloader - INFO - Added 1 new rows for DGE.L (1d)\n",
      "2025-05-12 19:23:15,288 - PriorityDownloader - INFO - Added 1 new rows for GSK.L (1d)\n",
      "2025-05-12 19:23:15,346 - PriorityDownloader - INFO - Added 1 new rows for HSBA.L (1d)\n",
      "2025-05-12 19:23:15,401 - PriorityDownloader - INFO - Added 1 new rows for IMB.L (1d)\n",
      "2025-05-12 19:23:15,503 - PriorityDownloader - INFO - Added 1 new rows for ITV.L (1d)\n",
      "2025-05-12 19:23:15,551 - PriorityDownloader - INFO - Added 1 new rows for LGEN.L (1d)\n",
      "2025-05-12 19:23:15,609 - PriorityDownloader - INFO - Added 1 new rows for LLOY.L (1d)\n",
      "2025-05-12 19:23:15,656 - PriorityDownloader - INFO - Added 1 new rows for PUM.DE (1d)\n",
      "2025-05-12 19:23:15,706 - PriorityDownloader - INFO - Added 1 new rows for NOKIA.HE (1d)\n",
      "2025-05-12 19:23:15,748 - PriorityDownloader - INFO - Added 1 new rows for 2388.HK (1d)\n",
      "2025-05-12 19:23:15,784 - PriorityDownloader - INFO - Added 1 new rows for 1398.HK (1d)\n",
      "2025-05-12 19:23:15,820 - PriorityDownloader - INFO - Added 1 new rows for 600519.SS (1d)\n",
      "2025-05-12 19:23:15,853 - PriorityDownloader - INFO - Added 1 new rows for V3SU.L (1d)\n",
      "2025-05-12 19:23:15,871 - PriorityDownloader - INFO - Added 1 new rows for CILJF (1d)\n",
      "2025-05-12 19:23:15,961 - PriorityDownloader - INFO - Added 1 new rows for JGRO (1d)\n",
      "2025-05-12 19:23:16,040 - PriorityDownloader - INFO - Added 1 new rows for STOHF (1d)\n",
      "2025-05-12 19:23:16,080 - PriorityDownloader - INFO - Added 1 new rows for DGEAF (1d)\n",
      "2025-05-12 19:23:16,116 - PriorityDownloader - INFO - Added 1 new rows for PSTVY (1d)\n",
      "2025-05-12 19:23:16,149 - PriorityDownloader - INFO - Added 2 new rows for RHHBF (1d)\n",
      "2025-05-12 19:23:16,187 - PriorityDownloader - INFO - Added 1 new rows for IDCBF (1d)\n",
      "2025-05-12 19:23:16,221 - PriorityDownloader - INFO - Added 1 new rows for 0DZF.IL (1d)\n",
      "2025-05-12 19:23:16,247 - PriorityDownloader - INFO - Added 1 new rows for IITSF (1d)\n",
      "2025-05-12 19:23:19,296 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:23:20,230 - yfinance - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-12 19:23:20,230 - yfinance - ERROR - ['FDJ.PA']: YFPricesMissingError('possibly delisted; no price data found  (1d 1926-06-06 -> 2025-05-12) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "2025-05-12 19:23:20,466 - StockDownloader - WARNING - Empty data for FDJ.PA (interval 1d)\n",
      "2025-05-12 19:23:20,564 - PriorityDownloader - INFO - Added 1 new rows for CUAEF (1d)\n",
      "2025-05-12 19:23:20,601 - PriorityDownloader - INFO - Added 1 new rows for CHDRF (1d)\n",
      "2025-05-12 19:23:20,635 - PriorityDownloader - INFO - Added 1 new rows for CICHF (1d)\n",
      "2025-05-12 19:23:20,666 - PriorityDownloader - INFO - Added 1 new rows for URW.PA (1d)\n",
      "2025-05-12 19:23:20,691 - PriorityDownloader - INFO - Added 1 new rows for TOELF (1d)\n",
      "2025-05-12 19:23:20,723 - PriorityDownloader - INFO - Added 1 new rows for FMXUF (1d)\n",
      "2025-05-12 19:23:20,824 - PriorityDownloader - INFO - Added 1 new rows for FRCOF (1d)\n",
      "2025-05-12 19:23:20,859 - PriorityDownloader - INFO - Added 1 new rows for SMFNF (1d)\n",
      "2025-05-12 19:23:20,888 - PriorityDownloader - INFO - Added 1 new rows for RCRRF (1d)\n",
      "2025-05-12 19:23:20,916 - PriorityDownloader - INFO - Added 1 new rows for IVSXF (1d)\n",
      "2025-05-12 19:23:20,972 - PriorityDownloader - INFO - Added 1 new rows for PROSF (1d)\n",
      "2025-05-12 19:23:20,999 - PriorityDownloader - INFO - Added 2 new rows for ACGBF (1d)\n",
      "2025-05-12 19:23:21,034 - PriorityDownloader - INFO - Added 1 new rows for CIIHF (1d)\n",
      "2025-05-12 19:23:21,064 - PriorityDownloader - INFO - Added 1 new rows for SNPMF (1d)\n",
      "2025-05-12 19:23:21,100 - PriorityDownloader - INFO - Added 1 new rows for AAIGF (1d)\n",
      "2025-05-12 19:23:21,132 - PriorityDownloader - INFO - Added 1 new rows for BBVXF (1d)\n",
      "2025-05-12 19:23:21,164 - PriorityDownloader - INFO - Added 1 new rows for CGXYY (1d)\n",
      "2025-05-12 19:23:21,196 - PriorityDownloader - INFO - Added 1 new rows for BTAFF (1d)\n",
      "2025-05-12 19:23:21,237 - PriorityDownloader - INFO - Added 1 new rows for PBCRF (1d)\n",
      "2025-05-12 19:23:21,280 - PriorityDownloader - INFO - Added 1 new rows for SBKFF (1d)\n",
      "2025-05-12 19:23:21,319 - PriorityDownloader - INFO - Added 1 new rows for ESOCF (1d)\n",
      "2025-05-12 19:23:21,347 - PriorityDownloader - INFO - Added 1 new rows for COTY.PA (1d)\n",
      "2025-05-12 19:23:21,368 - PriorityDownloader - INFO - Added 1 new rows for AKE.PA (1d)\n",
      "2025-05-12 19:23:21,405 - PriorityDownloader - INFO - Added 1 new rows for AYV.PA (1d)\n",
      "2025-05-12 19:23:21,425 - PriorityDownloader - INFO - Added 1 new rows for NVDS (1d)\n",
      "2025-05-12 19:23:21,448 - PriorityDownloader - INFO - Added 1 new rows for RF.PA (1d)\n",
      "2025-05-12 19:23:24,483 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:23:25,779 - PriorityDownloader - INFO - Added 1 new rows for QGRW (1d)\n",
      "2025-05-12 19:23:25,792 - PriorityDownloader - INFO - Added 1 new rows for AAPD (1d)\n",
      "2025-05-12 19:23:25,806 - PriorityDownloader - INFO - Added 1 new rows for URNJ (1d)\n",
      "2025-05-12 19:23:25,830 - PriorityDownloader - INFO - Added 1 new rows for COV.PA (1d)\n",
      "2025-05-12 19:23:25,868 - PriorityDownloader - INFO - Added 1 new rows for FBL (1d)\n",
      "2025-05-12 19:23:25,882 - PriorityDownloader - INFO - Added 1 new rows for COWG (1d)\n",
      "2025-05-12 19:23:25,893 - PriorityDownloader - INFO - Added 1 new rows for CGMS (1d)\n",
      "2025-05-12 19:23:25,906 - PriorityDownloader - INFO - Added 1 new rows for SPYI (1d)\n",
      "2025-05-12 19:23:25,917 - PriorityDownloader - INFO - Added 1 new rows for AMZD (1d)\n",
      "2025-05-12 19:23:25,936 - PriorityDownloader - INFO - Added 1 new rows for GTT.PA (1d)\n",
      "2025-05-12 19:23:25,963 - PriorityDownloader - INFO - Added 1 new rows for SPIE.PA (1d)\n",
      "2025-05-12 19:23:25,996 - PriorityDownloader - INFO - Added 1 new rows for TEP.PA (1d)\n",
      "2025-05-12 19:23:26,053 - PriorityDownloader - INFO - Added 1 new rows for SK.PA (1d)\n",
      "2025-05-12 19:23:26,099 - PriorityDownloader - INFO - Added 1 new rows for TE.PA (1d)\n",
      "2025-05-12 19:23:26,131 - PriorityDownloader - INFO - Added 1 new rows for ELIS.PA (1d)\n",
      "2025-05-12 19:23:26,165 - PriorityDownloader - INFO - Added 1 new rows for SCR.PA (1d)\n",
      "2025-05-12 19:23:26,226 - PriorityDownloader - INFO - Added 1 new rows for VK.PA (1d)\n",
      "2025-05-12 19:23:26,334 - PriorityDownloader - INFO - Added 1 new rows for NEX.PA (1d)\n",
      "2025-05-12 19:23:26,391 - PriorityDownloader - INFO - Added 1 new rows for MF.PA (1d)\n",
      "2025-05-12 19:23:26,458 - PriorityDownloader - INFO - Added 1 new rows for MLHK.PA (1d)\n",
      "2025-05-12 19:23:26,506 - PriorityDownloader - INFO - Added 1 new rows for TKO.PA (1d)\n",
      "2025-05-12 19:23:26,537 - PriorityDownloader - INFO - Added 1 new rows for FLY.PA (1d)\n",
      "2025-05-12 19:23:26,594 - PriorityDownloader - INFO - Added 1 new rows for SOP.PA (1d)\n",
      "2025-05-12 19:23:26,647 - PriorityDownloader - INFO - Added 1 new rows for DEC.PA (1d)\n",
      "2025-05-12 19:23:26,705 - PriorityDownloader - INFO - Added 1 new rows for PLX.PA (1d)\n",
      "2025-05-12 19:23:26,760 - PriorityDownloader - INFO - Added 1 new rows for ITP.PA (1d)\n",
      "2025-05-12 19:23:26,825 - PriorityDownloader - INFO - Added 1 new rows for VRLA.PA (1d)\n",
      "2025-05-12 19:23:26,898 - PriorityDownloader - INFO - Added 1 new rows for SOI.PA (1d)\n",
      "2025-05-12 19:23:26,955 - PriorityDownloader - INFO - Added 1 new rows for RCO.PA (1d)\n",
      "2025-05-12 19:23:27,009 - PriorityDownloader - INFO - Added 1 new rows for COVH.PA (1d)\n",
      "2025-05-12 19:23:30,055 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:23:31,768 - PriorityDownloader - INFO - Added 1 new rows for MMB.PA (1d)\n",
      "2025-05-12 19:23:31,822 - PriorityDownloader - INFO - Added 1 new rows for ATE.PA (1d)\n",
      "2025-05-12 19:23:31,873 - PriorityDownloader - INFO - Added 1 new rows for VU.PA (1d)\n",
      "2025-05-12 19:23:31,926 - PriorityDownloader - INFO - Added 1 new rows for FR.PA (1d)\n",
      "2025-05-12 19:23:31,981 - PriorityDownloader - INFO - Added 1 new rows for IDL.PA (1d)\n",
      "2025-05-12 19:23:32,032 - PriorityDownloader - INFO - Added 1 new rows for BB.PA (1d)\n",
      "2025-05-12 19:23:32,087 - PriorityDownloader - INFO - Added 1 new rows for RUI.PA (1d)\n",
      "2025-05-12 19:23:32,207 - PriorityDownloader - INFO - Added 1 new rows for VIRP.PA (1d)\n",
      "2025-05-12 19:23:32,269 - PriorityDownloader - INFO - Added 1 new rows for TRI.PA (1d)\n",
      "2025-05-12 19:23:32,323 - PriorityDownloader - INFO - Added 1 new rows for BAIN.PA (1d)\n",
      "2025-05-12 19:23:32,382 - PriorityDownloader - INFO - Added 1 new rows for VIV.PA (1d)\n",
      "2025-05-12 19:23:32,440 - PriorityDownloader - INFO - Added 1 new rows for COFA.PA (1d)\n",
      "2025-05-12 19:23:32,530 - PriorityDownloader - INFO - Added 1 new rows for CARM.PA (1d)\n",
      "2025-05-12 19:23:32,573 - PriorityDownloader - INFO - Added 1 new rows for LOUP.PA (1d)\n",
      "2025-05-12 19:23:32,634 - PriorityDownloader - INFO - Added 1 new rows for NK.PA (1d)\n",
      "2025-05-12 19:23:32,686 - PriorityDownloader - INFO - Added 1 new rows for WLN.PA (1d)\n",
      "2025-05-12 19:23:32,748 - PriorityDownloader - INFO - Added 1 new rows for ALTA.PA (1d)\n",
      "2025-05-12 19:23:32,892 - PriorityDownloader - INFO - Added 1 new rows for IPS.PA (1d)\n",
      "2025-05-12 19:23:33,006 - PriorityDownloader - INFO - Added 1 new rows for CAF.PA (1d)\n",
      "2025-05-12 19:23:33,069 - PriorityDownloader - INFO - Added 1 new rows for AF.PA (1d)\n",
      "2025-05-12 19:23:33,118 - PriorityDownloader - INFO - Added 1 new rows for PLNW.PA (1d)\n",
      "2025-05-12 19:23:33,229 - PriorityDownloader - INFO - Added 1 new rows for VCT.PA (1d)\n",
      "2025-05-12 19:23:33,282 - PriorityDownloader - INFO - Added 1 new rows for PEUG.PA (1d)\n",
      "2025-05-12 19:23:33,334 - PriorityDownloader - INFO - Added 1 new rows for RBT.PA (1d)\n",
      "2025-05-12 19:23:33,385 - PriorityDownloader - INFO - Added 1 new rows for STF.PA (1d)\n",
      "2025-05-12 19:23:33,496 - PriorityDownloader - INFO - Added 1 new rows for ICAD.PA (1d)\n",
      "2025-05-12 19:23:33,548 - PriorityDownloader - INFO - Added 1 new rows for SESG.PA (1d)\n",
      "2025-05-12 19:23:33,595 - PriorityDownloader - INFO - Added 1 new rows for OPM.PA (1d)\n",
      "2025-05-12 19:23:36,628 - StockDownloader - INFO - Downloading 30 tickers for interval 1d\n",
      "[*********************100%***********************]  30 of 30 completed\n",
      "2025-05-12 19:23:38,020 - PriorityDownloader - INFO - Added 1 new rows for ERA.PA (1d)\n",
      "2025-05-12 19:23:38,069 - PriorityDownloader - INFO - Added 1 new rows for ARG.PA (1d)\n",
      "2025-05-12 19:23:38,108 - PriorityDownloader - INFO - Added 1 new rows for TBIL (1d)\n",
      "2025-05-12 19:23:38,123 - PriorityDownloader - INFO - Added 1 new rows for CLOZ (1d)\n",
      "2025-05-12 19:23:38,148 - PriorityDownloader - INFO - Added 1 new rows for TFI.PA (1d)\n",
      "2025-05-12 19:23:38,213 - PriorityDownloader - INFO - Added 1 new rows for AAPU (1d)\n",
      "2025-05-12 19:23:38,296 - PriorityDownloader - INFO - Added 1 new rows for UBI.PA (1d)\n",
      "2025-05-12 19:23:38,339 - PriorityDownloader - INFO - Added 1 new rows for DFLV (1d)\n",
      "2025-05-12 19:23:38,360 - PriorityDownloader - INFO - Added 1 new rows for OVH.PA (1d)\n",
      "2025-05-12 19:23:38,411 - PriorityDownloader - INFO - Added 1 new rows for MMT.PA (1d)\n",
      "2025-05-12 19:23:38,461 - PriorityDownloader - INFO - Added 1 new rows for ES.PA (1d)\n",
      "2025-05-12 19:23:38,513 - PriorityDownloader - INFO - Added 1 new rows for BLV.PA (1d)\n",
      "2025-05-12 19:23:38,566 - PriorityDownloader - INFO - Added 1 new rows for MAU.PA (1d)\n",
      "2025-05-12 19:23:38,616 - PriorityDownloader - INFO - Added 1 new rows for GDS.PA (1d)\n",
      "2025-05-12 19:23:38,671 - PriorityDownloader - INFO - Added 1 new rows for FII.PA (1d)\n",
      "2025-05-12 19:23:38,723 - PriorityDownloader - INFO - Added 1 new rows for WAVE.PA (1d)\n",
      "2025-05-12 19:23:38,774 - PriorityDownloader - INFO - Added 1 new rows for CRLA.PA (1d)\n",
      "2025-05-12 19:23:38,818 - PriorityDownloader - INFO - Added 1 new rows for BKFCF (1d)\n",
      "2025-05-12 19:23:38,852 - PriorityDownloader - INFO - Added 1 new rows for NRO.PA (1d)\n",
      "2025-05-12 19:23:38,955 - PriorityDownloader - INFO - Added 1 new rows for LSS.PA (1d)\n",
      "2025-05-12 19:23:39,004 - PriorityDownloader - INFO - Added 1 new rows for MERY.PA (1d)\n",
      "2025-05-12 19:23:39,054 - PriorityDownloader - INFO - Added 1 new rows for ETL.PA (1d)\n",
      "2025-05-12 19:23:39,106 - PriorityDownloader - INFO - Added 1 new rows for ELEC.PA (1d)\n",
      "2025-05-12 19:23:39,164 - PriorityDownloader - INFO - Added 1 new rows for FREY.PA (1d)\n",
      "2025-05-12 19:23:39,215 - PriorityDownloader - INFO - Added 1 new rows for DBG.PA (1d)\n",
      "2025-05-12 19:23:39,264 - PriorityDownloader - INFO - Added 1 new rows for CNDF.PA (1d)\n",
      "2025-05-12 19:23:39,314 - PriorityDownloader - INFO - Added 1 new rows for LTA.PA (1d)\n",
      "2025-05-12 19:23:39,364 - PriorityDownloader - INFO - Added 1 new rows for CDA.PA (1d)\n",
      "2025-05-12 19:23:39,414 - PriorityDownloader - INFO - Added 1 new rows for FNAC.PA (1d)\n",
      "2025-05-12 19:23:42,465 - StockDownloader - INFO - Downloading 10 tickers for interval 1d\n",
      "[*********************100%***********************]  10 of 10 completed\n",
      "2025-05-12 19:23:43,489 - PriorityDownloader - INFO - Added 1 new rows for MTU.PA (1d)\n",
      "2025-05-12 19:23:43,590 - PriorityDownloader - INFO - Added 1 new rows for VETO.PA (1d)\n",
      "2025-05-12 19:23:43,640 - PriorityDownloader - INFO - Added 1 new rows for TKTT.PA (1d)\n",
      "2025-05-12 19:23:43,708 - PriorityDownloader - INFO - Added 1 new rows for VIL.PA (1d)\n",
      "2025-05-12 19:23:43,771 - PriorityDownloader - INFO - Added 1 new rows for BEN.PA (1d)\n",
      "2025-05-12 19:23:43,834 - PriorityDownloader - INFO - Added 1 new rows for EC.PA (1d)\n",
      "2025-05-12 19:23:43,898 - PriorityDownloader - INFO - Added 1 new rows for VAC.PA (1d)\n",
      "2025-05-12 19:23:44,026 - PriorityDownloader - INFO - Added 1 new rows for SAVE.PA (1d)\n",
      "2025-05-12 19:23:44,083 - PriorityDownloader - INFO - Added 1 new rows for BASS.PA (1d)\n",
      "2025-05-12 19:23:44,130 - PriorityDownloader - INFO - Added 1 new rows for WNDI.L (1d)\n",
      "Downloading 1d: 100%|██████████| 1540/1540 [05:12<00:00,  4.93it/s]\n",
      "2025-05-12 19:23:53,158 - PriorityDownloader - INFO - Processing 1540 tickers for interval 1m (quota: 2286 batches)\n",
      "2025-05-12 19:23:53,159 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:23:54,198 - PriorityDownloader - INFO - Added 2545 new rows for ^GSPC (1m)\n",
      "2025-05-12 19:23:54,259 - PriorityDownloader - INFO - Added 3533 new rows for ^FCHI (1m)\n",
      "2025-05-12 19:23:54,331 - PriorityDownloader - INFO - Added 3534 new rows for MC.PA (1m)\n",
      "2025-05-12 19:23:54,417 - PriorityDownloader - INFO - Added 3420 new rows for OR.PA (1m)\n",
      "2025-05-12 19:23:54,545 - PriorityDownloader - INFO - Added 3499 new rows for SU.PA (1m)\n",
      "2025-05-12 19:23:54,632 - PriorityDownloader - INFO - Added 3510 new rows for AIR.PA (1m)\n",
      "2025-05-12 19:23:54,727 - PriorityDownloader - INFO - Added 3535 new rows for TTE.PA (1m)\n",
      "2025-05-12 19:23:54,818 - PriorityDownloader - INFO - Added 3521 new rows for SAN.PA (1m)\n",
      "2025-05-12 19:23:54,899 - PriorityDownloader - INFO - Added 1106 new rows for CDI.PA (1m)\n",
      "2025-05-12 19:23:54,941 - PriorityDownloader - INFO - Added 3033 new rows for EL.PA (1m)\n",
      "2025-05-12 19:23:55,023 - PriorityDownloader - INFO - Added 3147 new rows for SAF.PA (1m)\n",
      "2025-05-12 19:23:55,108 - PriorityDownloader - INFO - Added 3487 new rows for AI.PA (1m)\n",
      "2025-05-12 19:23:55,201 - PriorityDownloader - INFO - Added 3507 new rows for BNP.PA (1m)\n",
      "2025-05-12 19:23:55,356 - PriorityDownloader - INFO - Added 3439 new rows for CS.PA (1m)\n",
      "2025-05-12 19:23:55,445 - PriorityDownloader - INFO - Added 2987 new rows for DG.PA (1m)\n",
      "2025-05-12 19:23:58,511 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:23:59,537 - PriorityDownloader - INFO - Added 2918 new rows for DSY.PA (1m)\n",
      "2025-05-12 19:23:59,619 - PriorityDownloader - INFO - Added 3258 new rows for SGO.PA (1m)\n",
      "2025-05-12 19:23:59,705 - PriorityDownloader - INFO - Added 2890 new rows for BN.PA (1m)\n",
      "2025-05-12 19:23:59,790 - PriorityDownloader - INFO - Added 2961 new rows for ACA.PA (1m)\n",
      "2025-05-12 19:23:59,875 - PriorityDownloader - INFO - Added 3223 new rows for ENGI.PA (1m)\n",
      "2025-05-12 19:23:59,963 - PriorityDownloader - INFO - Added 3357 new rows for KER.PA (1m)\n",
      "2025-05-12 19:24:00,054 - PriorityDownloader - INFO - Added 3209 new rows for HO.PA (1m)\n",
      "2025-05-12 19:24:00,136 - PriorityDownloader - INFO - Added 3047 new rows for CAP.PA (1m)\n",
      "2025-05-12 19:24:00,285 - PriorityDownloader - INFO - Added 2875 new rows for RI.PA (1m)\n",
      "2025-05-12 19:24:00,365 - PriorityDownloader - INFO - Added 2978 new rows for LR.PA (1m)\n",
      "2025-05-12 19:24:00,446 - PriorityDownloader - INFO - Added 2682 new rows for ORA.PA (1m)\n",
      "2025-05-12 19:24:00,526 - PriorityDownloader - INFO - Added 2959 new rows for PUB.PA (1m)\n",
      "2025-05-12 19:24:00,608 - PriorityDownloader - INFO - Added 3404 new rows for GLE.PA (1m)\n",
      "2025-05-12 19:24:00,702 - PriorityDownloader - INFO - Added 2840 new rows for ML.PA (1m)\n",
      "2025-05-12 19:24:00,778 - PriorityDownloader - INFO - Added 2005 new rows for DIM.PA (1m)\n",
      "2025-05-12 19:24:03,817 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:24:04,841 - PriorityDownloader - INFO - Added 3049 new rows for VIE.PA (1m)\n",
      "2025-05-12 19:24:04,969 - PriorityDownloader - INFO - Added 2551 new rows for AM.PA (1m)\n",
      "2025-05-12 19:24:05,023 - PriorityDownloader - INFO - Added 1061 new rows for BOL.PA (1m)\n",
      "2025-05-12 19:24:05,065 - PriorityDownloader - INFO - Added 3003 new rows for RNO.PA (1m)\n",
      "2025-05-12 19:24:05,140 - PriorityDownloader - INFO - Added 1635 new rows for BVI.PA (1m)\n",
      "2025-05-12 19:24:05,188 - PriorityDownloader - INFO - Added 1463 new rows for AMUN.PA (1m)\n",
      "2025-05-12 19:24:05,234 - PriorityDownloader - INFO - Added 894 new rows for BIM.PA (1m)\n",
      "2025-05-12 19:24:05,275 - PriorityDownloader - INFO - Added 2901 new rows for AC.PA (1m)\n",
      "2025-05-12 19:24:05,351 - PriorityDownloader - INFO - Added 2558 new rows for EN.PA (1m)\n",
      "2025-05-12 19:24:05,417 - PriorityDownloader - INFO - Added 1823 new rows for ENX.PA (1m)\n",
      "2025-05-12 19:24:05,462 - PriorityDownloader - INFO - Added 1246 new rows for ADP.PA (1m)\n",
      "2025-05-12 19:24:05,502 - PriorityDownloader - INFO - Added 1366 new rows for SW.PA (1m)\n",
      "2025-05-12 19:24:05,563 - PriorityDownloader - INFO - Added 1024 new rows for IPN.PA (1m)\n",
      "2025-05-12 19:24:05,605 - PriorityDownloader - INFO - Added 2458 new rows for ERF.PA (1m)\n",
      "2025-05-12 19:24:05,678 - PriorityDownloader - INFO - Added 2612 new rows for ALO.PA (1m)\n",
      "2025-05-12 19:24:08,736 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:24:09,288 - yfinance - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-12 19:24:09,288 - yfinance - ERROR - ['FDJ.PA']: YFPricesMissingError('possibly delisted; no price data found  (period=7d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "2025-05-12 19:24:09,415 - StockDownloader - WARNING - Empty data for FDJ.PA (interval 1m)\n",
      "2025-05-12 19:24:09,762 - PriorityDownloader - INFO - Added 2585 new rows for CA.PA (1m)\n",
      "2025-05-12 19:24:09,836 - PriorityDownloader - INFO - Added 2048 new rows for FGR.PA (1m)\n",
      "2025-05-12 19:24:09,889 - PriorityDownloader - INFO - Added 1305 new rows for LI.PA (1m)\n",
      "2025-05-12 19:24:09,926 - PriorityDownloader - INFO - Added 1123 new rows for GET.PA (1m)\n",
      "2025-05-12 19:24:09,975 - PriorityDownloader - INFO - Added 2691 new rows for EDEN.PA (1m)\n",
      "2025-05-12 19:24:10,047 - PriorityDownloader - INFO - Added 2488 new rows for RXL.PA (1m)\n",
      "2025-05-12 19:24:10,096 - PriorityDownloader - INFO - Added 33 new rows for IAM.PA (1m)\n",
      "2025-05-12 19:24:10,104 - PriorityDownloader - INFO - Added 67 new rows for CBDG.PA (1m)\n",
      "2025-05-12 19:24:10,140 - PriorityDownloader - INFO - Added 1083 new rows for GFC.PA (1m)\n",
      "2025-05-12 19:24:10,169 - PriorityDownloader - INFO - Added 236 new rows for ODET.PA (1m)\n",
      "2025-05-12 19:24:10,188 - PriorityDownloader - INFO - Added 1194 new rows for NXI.PA (1m)\n",
      "2025-05-12 19:24:10,227 - PriorityDownloader - INFO - Added 942 new rows for XFAB.PA (1m)\n",
      "2025-05-12 19:24:10,250 - PriorityDownloader - INFO - Added 59 new rows for SDG.PA (1m)\n",
      "2025-05-12 19:24:10,259 - PriorityDownloader - INFO - Added 213 new rows for THEP.PA (1m)\n",
      "2025-05-12 19:24:13,275 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:24:14,284 - PriorityDownloader - INFO - Added 49 new rows for CRAV.PA (1m)\n",
      "2025-05-12 19:24:14,294 - PriorityDownloader - INFO - Added 108 new rows for CRSU.PA (1m)\n",
      "2025-05-12 19:24:14,303 - PriorityDownloader - INFO - Added 49 new rows for CRAP.PA (1m)\n",
      "2025-05-12 19:24:14,312 - PriorityDownloader - INFO - Added 142 new rows for CEN.PA (1m)\n",
      "2025-05-12 19:24:14,325 - PriorityDownloader - INFO - Added 390 new rows for SCHP.PA (1m)\n",
      "2025-05-12 19:24:14,341 - PriorityDownloader - INFO - Added 159 new rows for TFF.PA (1m)\n",
      "2025-05-12 19:24:14,358 - PriorityDownloader - INFO - Added 628 new rows for KOF.PA (1m)\n",
      "2025-05-12 19:24:14,380 - PriorityDownloader - INFO - Added 519 new rows for QDT.PA (1m)\n",
      "2025-05-12 19:24:14,400 - PriorityDownloader - INFO - Added 51 new rows for LPE.PA (1m)\n",
      "2025-05-12 19:24:14,409 - PriorityDownloader - INFO - Added 41 new rows for SBT.PA (1m)\n",
      "2025-05-12 19:24:14,422 - PriorityDownloader - INFO - Added 689 new rows for EQS.PA (1m)\n",
      "2025-05-12 19:24:14,442 - PriorityDownloader - INFO - Added 74 new rows for BUR.PA (1m)\n",
      "2025-05-12 19:24:14,473 - PriorityDownloader - INFO - Added 245 new rows for AUB.PA (1m)\n",
      "2025-05-12 19:24:14,490 - PriorityDownloader - INFO - Added 478 new rows for GLO.PA (1m)\n",
      "2025-05-12 19:24:14,577 - PriorityDownloader - INFO - Added 2546 new rows for NVDA (1m)\n",
      "2025-05-12 19:24:17,645 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:24:18,129 - StockDownloader - WARNING - Empty data for SSNLF (interval 1m)\n",
      "2025-05-12 19:24:18,166 - StockDownloader - WARNING - Empty data for ACGBF (interval 1m)\n",
      "2025-05-12 19:24:18,669 - PriorityDownloader - INFO - Added 2547 new rows for AAPL (1m)\n",
      "2025-05-12 19:24:18,749 - PriorityDownloader - INFO - Added 2548 new rows for MSFT (1m)\n",
      "2025-05-12 19:24:18,828 - PriorityDownloader - INFO - Added 2546 new rows for AMZN (1m)\n",
      "2025-05-12 19:24:18,912 - PriorityDownloader - INFO - Added 2548 new rows for GOOGL (1m)\n",
      "2025-05-12 19:24:18,993 - PriorityDownloader - INFO - Added 2547 new rows for GOOG (1m)\n",
      "2025-05-12 19:24:19,074 - PriorityDownloader - INFO - Added 2547 new rows for META (1m)\n",
      "2025-05-12 19:24:19,153 - PriorityDownloader - INFO - Added 2548 new rows for TSLA (1m)\n",
      "2025-05-12 19:24:19,285 - PriorityDownloader - INFO - Added 2554 new rows for ORCL (1m)\n",
      "2025-05-12 19:24:19,364 - PriorityDownloader - INFO - Added 2526 new rows for NFLX (1m)\n",
      "2025-05-12 19:24:19,427 - PriorityDownloader - INFO - Added 14 new rows for NONOF (1m)\n",
      "2025-05-12 19:24:19,434 - PriorityDownloader - INFO - Added 2 new rows for GDVTZ (1m)\n",
      "2025-05-12 19:24:19,440 - PriorityDownloader - INFO - Added 2 new rows for RTNTF (1m)\n",
      "2025-05-12 19:24:19,447 - PriorityDownloader - INFO - Added 3 new rows for UNCFF (1m)\n",
      "2025-05-12 19:24:22,449 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:24:22,933 - yfinance - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-12 19:24:22,934 - yfinance - ERROR - ['PPWLM']: YFPricesMissingError('possibly delisted; no price data found  (period=7d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "2025-05-12 19:24:23,009 - StockDownloader - WARNING - Empty data for CGXYY (interval 1m)\n",
      "2025-05-12 19:24:23,049 - StockDownloader - WARNING - Empty data for BCMXY (interval 1m)\n",
      "2025-05-12 19:24:23,087 - StockDownloader - WARNING - Empty data for TKOMF (interval 1m)\n",
      "2025-05-12 19:24:23,125 - StockDownloader - WARNING - Empty data for PSBKF (interval 1m)\n",
      "2025-05-12 19:24:23,163 - StockDownloader - WARNING - Empty data for RBSPF (interval 1m)\n",
      "2025-05-12 19:24:23,201 - StockDownloader - WARNING - Empty data for PPWLM (interval 1m)\n",
      "2025-05-12 19:24:23,459 - PriorityDownloader - INFO - Added 4 new rows for AXAHF (1m)\n",
      "2025-05-12 19:24:23,468 - PriorityDownloader - INFO - Added 3 new rows for CHGCF (1m)\n",
      "2025-05-12 19:24:23,494 - PriorityDownloader - INFO - Added 2418 new rows for PHM (1m)\n",
      "2025-05-12 19:24:23,571 - PriorityDownloader - INFO - Added 2540 new rows for PLD (1m)\n",
      "2025-05-12 19:24:23,653 - PriorityDownloader - INFO - Added 2553 new rows for PM (1m)\n",
      "2025-05-12 19:24:23,735 - PriorityDownloader - INFO - Added 2506 new rows for PNC (1m)\n",
      "2025-05-12 19:24:23,876 - PriorityDownloader - INFO - Added 2220 new rows for PNR (1m)\n",
      "2025-05-12 19:24:23,948 - PriorityDownloader - INFO - Added 2270 new rows for PNW (1m)\n",
      "2025-05-12 19:24:24,024 - PriorityDownloader - INFO - Added 2427 new rows for PPG (1m)\n",
      "2025-05-12 19:24:27,086 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:24:28,112 - PriorityDownloader - INFO - Added 2550 new rows for PPL (1m)\n",
      "2025-05-12 19:24:28,190 - PriorityDownloader - INFO - Added 2374 new rows for PRGO (1m)\n",
      "2025-05-12 19:24:28,264 - PriorityDownloader - INFO - Added 2490 new rows for PRU (1m)\n",
      "2025-05-12 19:24:28,337 - PriorityDownloader - INFO - Added 2067 new rows for PSA (1m)\n",
      "2025-05-12 19:24:28,463 - PriorityDownloader - INFO - Added 2525 new rows for PSX (1m)\n",
      "2025-05-12 19:24:28,541 - PriorityDownloader - INFO - Added 2374 new rows for PVH (1m)\n",
      "2025-05-12 19:24:28,614 - PriorityDownloader - INFO - Added 2374 new rows for PWR (1m)\n",
      "2025-05-12 19:24:28,691 - PriorityDownloader - INFO - Added 2377 new rows for QRVO (1m)\n",
      "2025-05-12 19:24:28,766 - PriorityDownloader - INFO - Added 2505 new rows for RCL (1m)\n",
      "2025-05-12 19:24:28,841 - PriorityDownloader - INFO - Added 1959 new rows for REG (1m)\n",
      "2025-05-12 19:24:28,909 - PriorityDownloader - INFO - Added 2548 new rows for RF (1m)\n",
      "2025-05-12 19:24:28,986 - PriorityDownloader - INFO - Added 2178 new rows for RHI (1m)\n",
      "2025-05-12 19:24:29,111 - PriorityDownloader - INFO - Added 2106 new rows for RJF (1m)\n",
      "2025-05-12 19:24:29,185 - PriorityDownloader - INFO - Added 2014 new rows for RL (1m)\n",
      "2025-05-12 19:24:29,250 - PriorityDownloader - INFO - Added 1969 new rows for RMD (1m)\n",
      "2025-05-12 19:24:32,306 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:24:33,332 - PriorityDownloader - INFO - Added 2321 new rows for ROK (1m)\n",
      "2025-05-12 19:24:33,399 - PriorityDownloader - INFO - Added 2426 new rows for ROL (1m)\n",
      "2025-05-12 19:24:33,471 - PriorityDownloader - INFO - Added 1381 new rows for ROP (1m)\n",
      "2025-05-12 19:24:33,527 - PriorityDownloader - INFO - Added 2434 new rows for ROST (1m)\n",
      "2025-05-12 19:24:33,604 - PriorityDownloader - INFO - Added 2184 new rows for RSG (1m)\n",
      "2025-05-12 19:24:33,729 - PriorityDownloader - INFO - Added 2547 new rows for RTX (1m)\n",
      "2025-05-12 19:24:33,807 - PriorityDownloader - INFO - Added 1752 new rows for SBAC (1m)\n",
      "2025-05-12 19:24:33,873 - PriorityDownloader - INFO - Added 2489 new rows for SEE (1m)\n",
      "2025-05-12 19:24:33,948 - PriorityDownloader - INFO - Added 2305 new rows for SHW (1m)\n",
      "2025-05-12 19:24:34,020 - PriorityDownloader - INFO - Added 2235 new rows for SJM (1m)\n",
      "2025-05-12 19:24:34,094 - PriorityDownloader - INFO - Added 2554 new rows for SLB (1m)\n",
      "2025-05-12 19:24:34,170 - PriorityDownloader - INFO - Added 1955 new rows for SLG (1m)\n",
      "2025-05-12 19:24:34,235 - PriorityDownloader - INFO - Added 1154 new rows for SNA (1m)\n",
      "2025-05-12 19:24:34,345 - PriorityDownloader - INFO - Added 2551 new rows for SO (1m)\n",
      "2025-05-12 19:24:34,425 - PriorityDownloader - INFO - Added 2389 new rows for SPG (1m)\n",
      "2025-05-12 19:24:37,479 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:24:38,506 - PriorityDownloader - INFO - Added 2547 new rows for SRE (1m)\n",
      "2025-05-12 19:24:38,585 - PriorityDownloader - INFO - Added 1760 new rows for STE (1m)\n",
      "2025-05-12 19:24:38,646 - PriorityDownloader - INFO - Added 2448 new rows for STT (1m)\n",
      "2025-05-12 19:24:38,728 - PriorityDownloader - INFO - Added 2518 new rows for STX (1m)\n",
      "2025-05-12 19:24:38,805 - PriorityDownloader - INFO - Added 2379 new rows for STZ (1m)\n",
      "2025-05-12 19:24:38,883 - PriorityDownloader - INFO - Added 2535 new rows for SWK (1m)\n",
      "2025-05-12 19:24:39,025 - PriorityDownloader - INFO - Added 2531 new rows for SWKS (1m)\n",
      "2025-05-12 19:24:39,105 - PriorityDownloader - INFO - Added 2549 new rows for SYY (1m)\n",
      "2025-05-12 19:24:39,184 - PriorityDownloader - INFO - Added 2553 new rows for T (1m)\n",
      "2025-05-12 19:24:39,264 - PriorityDownloader - INFO - Added 2551 new rows for TAP (1m)\n",
      "2025-05-12 19:24:39,334 - PriorityDownloader - INFO - Added 1294 new rows for TDG (1m)\n",
      "2025-05-12 19:24:39,380 - PriorityDownloader - INFO - Added 2476 new rows for TEL (1m)\n",
      "2025-05-12 19:24:39,457 - PriorityDownloader - INFO - Added 2513 new rows for TER (1m)\n",
      "2025-05-12 19:24:39,536 - PriorityDownloader - INFO - Added 2555 new rows for TFC (1m)\n",
      "2025-05-12 19:24:39,613 - PriorityDownloader - INFO - Added 1715 new rows for TFX (1m)\n",
      "2025-05-12 19:24:42,666 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:24:43,740 - PriorityDownloader - INFO - Added 2552 new rows for TGT (1m)\n",
      "2025-05-12 19:24:43,820 - PriorityDownloader - INFO - Added 2552 new rows for TJX (1m)\n",
      "2025-05-12 19:24:43,898 - PriorityDownloader - INFO - Added 2550 new rows for TPR (1m)\n",
      "2025-05-12 19:24:43,974 - PriorityDownloader - INFO - Added 2344 new rows for TRMB (1m)\n",
      "2025-05-12 19:24:44,050 - PriorityDownloader - INFO - Added 2445 new rows for TROW (1m)\n",
      "2025-05-12 19:24:44,125 - PriorityDownloader - INFO - Added 2242 new rows for TRV (1m)\n",
      "2025-05-12 19:24:44,199 - PriorityDownloader - INFO - Added 2545 new rows for TSCO (1m)\n",
      "2025-05-12 19:24:44,321 - PriorityDownloader - INFO - Added 2540 new rows for TSN (1m)\n",
      "2025-05-12 19:24:44,400 - PriorityDownloader - INFO - Added 2420 new rows for TT (1m)\n",
      "2025-05-12 19:24:44,472 - PriorityDownloader - INFO - Added 2461 new rows for TTWO (1m)\n",
      "2025-05-12 19:24:44,547 - PriorityDownloader - INFO - Added 2548 new rows for TXN (1m)\n",
      "2025-05-12 19:24:44,624 - PriorityDownloader - INFO - Added 2465 new rows for TXT (1m)\n",
      "2025-05-12 19:24:44,695 - PriorityDownloader - INFO - Added 1114 new rows for TYL (1m)\n",
      "2025-05-12 19:24:44,742 - PriorityDownloader - INFO - Added 2351 new rows for UA (1m)\n",
      "2025-05-12 19:24:44,817 - PriorityDownloader - INFO - Added 2546 new rows for UAA (1m)\n",
      "2025-05-12 19:24:47,872 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:24:48,914 - PriorityDownloader - INFO - Added 2546 new rows for UAL (1m)\n",
      "2025-05-12 19:24:49,044 - PriorityDownloader - INFO - Added 2413 new rows for UDR (1m)\n",
      "2025-05-12 19:24:49,119 - PriorityDownloader - INFO - Added 2013 new rows for UHS (1m)\n",
      "2025-05-12 19:24:49,183 - PriorityDownloader - INFO - Added 1787 new rows for ULTA (1m)\n",
      "2025-05-12 19:24:49,251 - PriorityDownloader - INFO - Added 2206 new rows for UNM (1m)\n",
      "2025-05-12 19:24:49,324 - PriorityDownloader - INFO - Added 2527 new rows for UNP (1m)\n",
      "2025-05-12 19:24:49,404 - PriorityDownloader - INFO - Added 2551 new rows for UPS (1m)\n",
      "2025-05-12 19:24:49,480 - PriorityDownloader - INFO - Added 1835 new rows for URI (1m)\n",
      "2025-05-12 19:24:49,547 - PriorityDownloader - INFO - Added 2552 new rows for USB (1m)\n",
      "2025-05-12 19:24:49,626 - PriorityDownloader - INFO - Added 2551 new rows for VFC (1m)\n",
      "2025-05-12 19:24:49,710 - PriorityDownloader - INFO - Added 2542 new rows for VLO (1m)\n",
      "2025-05-12 19:24:49,847 - PriorityDownloader - INFO - Added 2048 new rows for VMC (1m)\n",
      "2025-05-12 19:24:49,916 - PriorityDownloader - INFO - Added 2356 new rows for VNO (1m)\n",
      "2025-05-12 19:24:49,985 - PriorityDownloader - INFO - Added 1901 new rows for VRSK (1m)\n",
      "2025-05-12 19:24:50,046 - PriorityDownloader - INFO - Added 1743 new rows for VRSN (1m)\n",
      "2025-05-12 19:24:53,092 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:24:54,118 - PriorityDownloader - INFO - Added 2520 new rows for VTR (1m)\n",
      "2025-05-12 19:24:54,194 - PriorityDownloader - INFO - Added 1858 new rows for WAB (1m)\n",
      "2025-05-12 19:24:54,259 - PriorityDownloader - INFO - Added 1734 new rows for WAT (1m)\n",
      "2025-05-12 19:24:54,320 - PriorityDownloader - INFO - Added 2532 new rows for WBA (1m)\n",
      "2025-05-12 19:24:54,449 - PriorityDownloader - INFO - Added 2548 new rows for WDC (1m)\n",
      "2025-05-12 19:24:54,529 - PriorityDownloader - INFO - Added 2493 new rows for WEC (1m)\n",
      "2025-05-12 19:24:54,604 - PriorityDownloader - INFO - Added 2554 new rows for WFC (1m)\n",
      "2025-05-12 19:24:54,682 - PriorityDownloader - INFO - Added 2319 new rows for WHR (1m)\n",
      "2025-05-12 19:24:54,758 - PriorityDownloader - INFO - Added 2427 new rows for WM (1m)\n",
      "2025-05-12 19:24:54,835 - PriorityDownloader - INFO - Added 2554 new rows for WMB (1m)\n",
      "2025-05-12 19:24:54,913 - PriorityDownloader - INFO - Added 2405 new rows for WRB (1m)\n",
      "2025-05-12 19:24:54,989 - PriorityDownloader - INFO - Added 2528 new rows for WU (1m)\n",
      "2025-05-12 19:24:55,070 - PriorityDownloader - INFO - Added 2523 new rows for WY (1m)\n",
      "2025-05-12 19:24:55,148 - PriorityDownloader - INFO - Added 2487 new rows for WYNN (1m)\n",
      "2025-05-12 19:24:55,274 - PriorityDownloader - INFO - Added 2513 new rows for XEL (1m)\n",
      "2025-05-12 19:24:58,329 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:24:59,355 - PriorityDownloader - INFO - Added 2486 new rows for XRAY (1m)\n",
      "2025-05-12 19:24:59,433 - PriorityDownloader - INFO - Added 2477 new rows for XRX (1m)\n",
      "2025-05-12 19:24:59,507 - PriorityDownloader - INFO - Added 2301 new rows for XYL (1m)\n",
      "2025-05-12 19:24:59,585 - PriorityDownloader - INFO - Added 2381 new rows for YUM (1m)\n",
      "2025-05-12 19:24:59,665 - PriorityDownloader - INFO - Added 2534 new rows for ZBH (1m)\n",
      "2025-05-12 19:24:59,740 - PriorityDownloader - INFO - Added 1684 new rows for ZBRA (1m)\n",
      "2025-05-12 19:24:59,855 - PriorityDownloader - INFO - Added 2309 new rows for ZION (1m)\n",
      "2025-05-12 19:24:59,930 - PriorityDownloader - INFO - Added 2539 new rows for ZTS (1m)\n",
      "2025-05-12 19:25:00,009 - PriorityDownloader - INFO - Added 2920 new rows for ADS.DE (1m)\n",
      "2025-05-12 19:25:00,082 - PriorityDownloader - INFO - Added 2742 new rows for CON.DE (1m)\n",
      "2025-05-12 19:25:00,134 - PriorityDownloader - INFO - Added 2943 new rows for DB1.DE (1m)\n",
      "2025-05-12 19:25:00,211 - PriorityDownloader - INFO - Added 3029 new rows for LHA.DE (1m)\n",
      "2025-05-12 19:25:00,287 - PriorityDownloader - INFO - Added 1008 new rows for LIN.DE (1m)\n",
      "2025-05-12 19:25:00,335 - PriorityDownloader - INFO - Added 3260 new rows for MUV2.DE (1m)\n",
      "2025-05-12 19:25:00,484 - PriorityDownloader - INFO - Added 3011 new rows for RWE.DE (1m)\n",
      "2025-05-12 19:25:03,550 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:25:04,578 - PriorityDownloader - INFO - Added 3498 new rows for SAP.DE (1m)\n",
      "2025-05-12 19:25:04,671 - PriorityDownloader - INFO - Added 3469 new rows for SIE.DE (1m)\n",
      "2025-05-12 19:25:04,763 - PriorityDownloader - INFO - Added 3242 new rows for VOW3.DE (1m)\n",
      "2025-05-12 19:25:04,850 - PriorityDownloader - INFO - Added 3021 new rows for ZAL.DE (1m)\n",
      "2025-05-12 19:25:04,933 - PriorityDownloader - INFO - Added 3358 new rows for AAL.L (1m)\n",
      "2025-05-12 19:25:05,008 - PriorityDownloader - INFO - Added 2863 new rows for ABF.L (1m)\n",
      "2025-05-12 19:25:05,071 - PriorityDownloader - INFO - Added 2350 new rows for ADM.L (1m)\n",
      "2025-05-12 19:25:05,190 - PriorityDownloader - INFO - Added 2849 new rows for AHT.L (1m)\n",
      "2025-05-12 19:25:05,261 - PriorityDownloader - INFO - Added 3433 new rows for AV.L (1m)\n",
      "2025-05-12 19:25:05,352 - PriorityDownloader - INFO - Added 3473 new rows for BA.L (1m)\n",
      "2025-05-12 19:25:05,429 - PriorityDownloader - INFO - Added 3471 new rows for BARC.L (1m)\n",
      "2025-05-12 19:25:05,523 - PriorityDownloader - INFO - Added 3448 new rows for BATS.L (1m)\n",
      "2025-05-12 19:25:05,599 - PriorityDownloader - INFO - Added 3480 new rows for BP.L (1m)\n",
      "2025-05-12 19:25:05,699 - PriorityDownloader - INFO - Added 2548 new rows for BTI (1m)\n",
      "2025-05-12 19:25:05,849 - PriorityDownloader - INFO - Added 3146 new rows for CNA.L (1m)\n",
      "2025-05-12 19:25:08,922 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:25:09,488 - yfinance - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-12 19:25:09,488 - yfinance - ERROR - ['RDSA.VI']: YFPricesMissingError('possibly delisted; no price data found  (period=7d)')\n",
      "2025-05-12 19:25:09,639 - StockDownloader - WARNING - Empty data for RDSA.VI (interval 1m)\n",
      "2025-05-12 19:25:10,004 - PriorityDownloader - INFO - Added 3367 new rows for DGE.L (1m)\n",
      "2025-05-12 19:25:10,080 - PriorityDownloader - INFO - Added 3462 new rows for GSK.L (1m)\n",
      "2025-05-12 19:25:10,162 - PriorityDownloader - INFO - Added 3475 new rows for HSBA.L (1m)\n",
      "2025-05-12 19:25:10,252 - PriorityDownloader - INFO - Added 3218 new rows for IMB.L (1m)\n",
      "2025-05-12 19:25:10,320 - PriorityDownloader - INFO - Added 2085 new rows for ITV.L (1m)\n",
      "2025-05-12 19:25:10,391 - PriorityDownloader - INFO - Added 3463 new rows for LGEN.L (1m)\n",
      "2025-05-12 19:25:10,485 - PriorityDownloader - INFO - Added 3473 new rows for LLOY.L (1m)\n",
      "2025-05-12 19:25:10,578 - PriorityDownloader - INFO - Added 2797 new rows for PUM.DE (1m)\n",
      "2025-05-12 19:25:10,725 - PriorityDownloader - INFO - Added 2944 new rows for NOKIA.HE (1m)\n",
      "2025-05-12 19:25:10,808 - PriorityDownloader - INFO - Added 1806 new rows for 2388.HK (1m)\n",
      "2025-05-12 19:25:10,868 - PriorityDownloader - INFO - Added 1894 new rows for 1398.HK (1m)\n",
      "2025-05-12 19:25:10,931 - PriorityDownloader - INFO - Added 1117 new rows for 600519.SS (1m)\n",
      "2025-05-12 19:25:10,985 - PriorityDownloader - INFO - Added 1120 new rows for 601988.SS (1m)\n",
      "2025-05-12 19:25:11,041 - PriorityDownloader - INFO - Added 1117 new rows for 601288.SS (1m)\n",
      "2025-05-12 19:25:14,076 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:25:15,097 - PriorityDownloader - INFO - Added 1122 new rows for 601318.SS (1m)\n",
      "2025-05-12 19:25:15,153 - PriorityDownloader - INFO - Added 1571 new rows for 002475.SZ (1m)\n",
      "2025-05-12 19:25:15,220 - PriorityDownloader - INFO - Added 2448 new rows for BHP.AX (1m)\n",
      "2025-05-12 19:25:15,355 - PriorityDownloader - INFO - Added 2435 new rows for CBA.AX (1m)\n",
      "2025-05-12 19:25:15,425 - PriorityDownloader - INFO - Added 2372 new rows for TLS.AX (1m)\n",
      "2025-05-12 19:25:15,495 - PriorityDownloader - INFO - Added 2392 new rows for WBC.AX (1m)\n",
      "2025-05-12 19:25:15,565 - PriorityDownloader - INFO - Added 2436 new rows for CSL.AX (1m)\n",
      "2025-05-12 19:25:15,636 - PriorityDownloader - INFO - Added 2412 new rows for NAB.AX (1m)\n",
      "2025-05-12 19:25:15,710 - PriorityDownloader - INFO - Added 2450 new rows for ANZ.AX (1m)\n",
      "2025-05-12 19:25:15,783 - PriorityDownloader - INFO - Added 2410 new rows for RIO.AX (1m)\n",
      "2025-05-12 19:25:15,855 - PriorityDownloader - INFO - Added 2402 new rows for QBE.AX (1m)\n",
      "2025-05-12 19:25:15,926 - PriorityDownloader - INFO - Added 2395 new rows for WOW.AX (1m)\n",
      "2025-05-12 19:25:15,997 - PriorityDownloader - INFO - Added 2368 new rows for S32.AX (1m)\n",
      "2025-05-12 19:25:16,131 - PriorityDownloader - INFO - Added 2427 new rows for FMG.AX (1m)\n",
      "2025-05-12 19:25:16,203 - PriorityDownloader - INFO - Added 2423 new rows for MQG.AX (1m)\n",
      "2025-05-12 19:25:19,264 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:25:20,290 - PriorityDownloader - INFO - Added 2553 new rows for TD.TO (1m)\n",
      "2025-05-12 19:25:20,368 - PriorityDownloader - INFO - Added 2546 new rows for RY.TO (1m)\n",
      "2025-05-12 19:25:20,449 - PriorityDownloader - INFO - Added 2513 new rows for BNS.TO (1m)\n",
      "2025-05-12 19:25:20,526 - PriorityDownloader - INFO - Added 2570 new rows for ENB.TO (1m)\n",
      "2025-05-12 19:25:20,658 - PriorityDownloader - INFO - Added 2575 new rows for SU.TO (1m)\n",
      "2025-05-12 19:25:20,741 - PriorityDownloader - INFO - Added 2571 new rows for CNQ.TO (1m)\n",
      "2025-05-12 19:25:20,822 - PriorityDownloader - INFO - Added 2525 new rows for BMO.TO (1m)\n",
      "2025-05-12 19:25:20,900 - PriorityDownloader - INFO - Added 2560 new rows for SHOP.TO (1m)\n",
      "2025-05-12 19:25:20,978 - PriorityDownloader - INFO - Added 2340 new rows for SLF.TO (1m)\n",
      "2025-05-12 19:25:21,054 - PriorityDownloader - INFO - Added 2543 new rows for MFC.TO (1m)\n",
      "2025-05-12 19:25:21,131 - PriorityDownloader - INFO - Added 2530 new rows for PPL.TO (1m)\n",
      "2025-05-12 19:25:21,207 - PriorityDownloader - INFO - Added 2559 new rows for TRP.TO (1m)\n",
      "2025-05-12 19:25:21,327 - PriorityDownloader - INFO - Added 2554 new rows for TSM (1m)\n",
      "2025-05-12 19:25:21,408 - PriorityDownloader - INFO - Added 2365 new rows for SAP (1m)\n",
      "2025-05-12 19:25:21,477 - PriorityDownloader - INFO - Added 1519 new rows for VOW.DE (1m)\n",
      "2025-05-12 19:25:24,518 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:25:25,558 - PriorityDownloader - INFO - Added 7022 new rows for ZN=F (1m)\n",
      "2025-05-12 19:25:25,698 - PriorityDownloader - INFO - Added 6894 new rows for ZF=F (1m)\n",
      "2025-05-12 19:25:25,835 - PriorityDownloader - INFO - Added 7554 new rows for ES=F (1m)\n",
      "2025-05-12 19:25:25,964 - PriorityDownloader - INFO - Added 6318 new rows for ZT=F (1m)\n",
      "2025-05-12 19:25:26,095 - PriorityDownloader - INFO - Added 7527 new rows for NQ=F (1m)\n",
      "2025-05-12 19:25:26,286 - PriorityDownloader - INFO - Added 6521 new rows for ZB=F (1m)\n",
      "2025-05-12 19:25:26,415 - PriorityDownloader - INFO - Added 7556 new rows for CL=F (1m)\n",
      "2025-05-12 19:25:26,570 - PriorityDownloader - INFO - Added 7601 new rows for GC=F (1m)\n",
      "2025-05-12 19:25:26,718 - PriorityDownloader - INFO - Added 4791 new rows for ZC=F (1m)\n",
      "2025-05-12 19:25:26,811 - PriorityDownloader - INFO - Added 7387 new rows for RTY=F (1m)\n",
      "2025-05-12 19:25:26,962 - PriorityDownloader - INFO - Added 6849 new rows for NG=F (1m)\n",
      "2025-05-12 19:25:27,148 - PriorityDownloader - INFO - Added 7619 new rows for MGC=F (1m)\n",
      "2025-05-12 19:25:27,296 - PriorityDownloader - INFO - Added 7493 new rows for YM=F (1m)\n",
      "2025-05-12 19:25:27,408 - PriorityDownloader - INFO - Added 5234 new rows for ZS=F (1m)\n",
      "2025-05-12 19:25:27,505 - PriorityDownloader - INFO - Added 7128 new rows for HG=F (1m)\n",
      "2025-05-12 19:25:30,624 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:25:31,662 - PriorityDownloader - INFO - Added 7443 new rows for SI=F (1m)\n",
      "2025-05-12 19:25:31,855 - PriorityDownloader - INFO - Added 2972 new rows for SB=F (1m)\n",
      "2025-05-12 19:25:31,930 - PriorityDownloader - INFO - Added 5708 new rows for HO=F (1m)\n",
      "2025-05-12 19:25:32,019 - PriorityDownloader - INFO - Added 5435 new rows for RB=F (1m)\n",
      "2025-05-12 19:25:32,111 - PriorityDownloader - INFO - Added 5468 new rows for ZL=F (1m)\n",
      "2025-05-12 19:25:32,221 - PriorityDownloader - INFO - Added 3617 new rows for KE=F (1m)\n",
      "2025-05-12 19:25:32,291 - PriorityDownloader - INFO - Added 4509 new rows for ZM=F (1m)\n",
      "2025-05-12 19:25:32,397 - PriorityDownloader - INFO - Added 6185 new rows for BZ=F (1m)\n",
      "2025-05-12 19:25:32,523 - PriorityDownloader - INFO - Added 4695 new rows for CT=F (1m)\n",
      "2025-05-12 19:25:32,671 - PriorityDownloader - INFO - Added 2733 new rows for KC=F (1m)\n",
      "2025-05-12 19:25:32,758 - PriorityDownloader - INFO - Added 6974 new rows for PL=F (1m)\n",
      "2025-05-12 19:25:32,885 - PriorityDownloader - INFO - Added 1580 new rows for LE=F (1m)\n",
      "2025-05-12 19:25:32,951 - PriorityDownloader - INFO - Added 6925 new rows for SIL=F (1m)\n",
      "2025-05-12 19:25:33,088 - PriorityDownloader - INFO - Added 1574 new rows for HE=F (1m)\n",
      "2025-05-12 19:25:33,127 - PriorityDownloader - INFO - Added 2418 new rows for CC=F (1m)\n",
      "2025-05-12 19:25:36,161 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:25:37,180 - PriorityDownloader - INFO - Added 1557 new rows for GF=F (1m)\n",
      "2025-05-12 19:25:37,229 - PriorityDownloader - INFO - Added 3782 new rows for PA=F (1m)\n",
      "2025-05-12 19:25:37,371 - PriorityDownloader - INFO - Added 9448 new rows for JPY=X (1m)\n",
      "2025-05-12 19:25:37,559 - PriorityDownloader - INFO - Added 9450 new rows for GBPUSD=X (1m)\n",
      "2025-05-12 19:25:37,748 - PriorityDownloader - INFO - Added 9144 new rows for AUDUSD=X (1m)\n",
      "2025-05-12 19:25:37,912 - PriorityDownloader - INFO - Added 4725 new rows for NZDUSD=X (1m)\n",
      "2025-05-12 19:25:38,029 - PriorityDownloader - INFO - Added 9478 new rows for EURJPY=X (1m)\n",
      "2025-05-12 19:25:38,287 - PriorityDownloader - INFO - Added 9486 new rows for GBPJPY=X (1m)\n",
      "2025-05-12 19:25:38,482 - PriorityDownloader - INFO - Added 9475 new rows for EURGBP=X (1m)\n",
      "2025-05-12 19:25:38,673 - PriorityDownloader - INFO - Added 9477 new rows for EURCAD=X (1m)\n",
      "2025-05-12 19:25:38,868 - PriorityDownloader - INFO - Added 9359 new rows for EURSEK=X (1m)\n",
      "2025-05-12 19:25:39,060 - PriorityDownloader - INFO - Added 9389 new rows for EURCHF=X (1m)\n",
      "2025-05-12 19:25:39,306 - PriorityDownloader - INFO - Added 7823 new rows for EURHUF=X (1m)\n",
      "2025-05-12 19:25:39,437 - PriorityDownloader - INFO - Added 2276 new rows for CNY=X (1m)\n",
      "2025-05-12 19:25:39,522 - PriorityDownloader - INFO - Added 9501 new rows for HKD=X (1m)\n",
      "2025-05-12 19:25:42,667 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:25:43,713 - PriorityDownloader - INFO - Added 9426 new rows for SGD=X (1m)\n",
      "2025-05-12 19:25:43,944 - PriorityDownloader - INFO - Added 4869 new rows for INR=X (1m)\n",
      "2025-05-12 19:25:44,076 - PriorityDownloader - INFO - Added 9442 new rows for MXN=X (1m)\n",
      "2025-05-12 19:25:44,248 - PriorityDownloader - INFO - Added 4747 new rows for PHP=X (1m)\n",
      "2025-05-12 19:25:44,335 - PriorityDownloader - INFO - Added 761 new rows for IDR=X (1m)\n",
      "2025-05-12 19:25:44,387 - PriorityDownloader - INFO - Added 8857 new rows for THB=X (1m)\n",
      "2025-05-12 19:25:44,535 - PriorityDownloader - INFO - Added 768 new rows for MYR=X (1m)\n",
      "2025-05-12 19:25:44,593 - PriorityDownloader - INFO - Added 9286 new rows for ZAR=X (1m)\n",
      "2025-05-12 19:25:44,774 - PriorityDownloader - INFO - Added 2466 new rows for RUB=X (1m)\n",
      "2025-05-12 19:25:44,842 - PriorityDownloader - INFO - Added 1586 new rows for BX4.PA (1m)\n",
      "2025-05-12 19:25:44,876 - PriorityDownloader - INFO - Added 135 new rows for BXX.PA (1m)\n",
      "2025-05-12 19:25:44,967 - PriorityDownloader - INFO - Added 3399 new rows for WPEA.PA (1m)\n",
      "2025-05-12 19:25:45,026 - PriorityDownloader - INFO - Added 364 new rows for DSD.PA (1m)\n",
      "2025-05-12 19:25:45,038 - PriorityDownloader - INFO - Added 170 new rows for AUEM.PA (1m)\n",
      "2025-05-12 19:25:45,062 - PriorityDownloader - INFO - Added 1204 new rows for MSE.PA (1m)\n",
      "2025-05-12 19:25:48,088 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:25:48,541 - yfinance - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-12 19:25:48,541 - yfinance - ERROR - ['LCWD.PA']: YFPricesMissingError('possibly delisted; no price data found  (period=7d)')\n",
      "2025-05-12 19:25:48,671 - StockDownloader - WARNING - Empty data for LCWD.PA (interval 1m)\n",
      "2025-05-12 19:25:49,110 - PriorityDownloader - INFO - Added 3436 new rows for ESE.PA (1m)\n",
      "2025-05-12 19:25:49,169 - PriorityDownloader - INFO - Added 228 new rows for SHC.PA (1m)\n",
      "2025-05-12 19:25:49,187 - PriorityDownloader - INFO - Added 611 new rows for AEEM.PA (1m)\n",
      "2025-05-12 19:25:49,204 - PriorityDownloader - INFO - Added 115 new rows for MFEC.PA (1m)\n",
      "2025-05-12 19:25:49,218 - PriorityDownloader - INFO - Added 912 new rows for DFND-EUR.PA (1m)\n",
      "2025-05-12 19:25:49,246 - PriorityDownloader - INFO - Added 891 new rows for BNKE.PA (1m)\n",
      "2025-05-12 19:25:49,280 - PriorityDownloader - INFO - Added 1492 new rows for LVC.PA (1m)\n",
      "2025-05-12 19:25:49,312 - PriorityDownloader - INFO - Added 198 new rows for 500U.PA (1m)\n",
      "2025-05-12 19:25:49,338 - PriorityDownloader - INFO - Added 2917 new rows for PSP5.PA (1m)\n",
      "2025-05-12 19:25:49,392 - PriorityDownloader - INFO - Added 324 new rows for GRE.PA (1m)\n",
      "2025-05-12 19:25:49,408 - PriorityDownloader - INFO - Added 558 new rows for ESEH.PA (1m)\n",
      "2025-05-12 19:25:49,435 - PriorityDownloader - INFO - Added 1725 new rows for CL2.PA (1m)\n",
      "2025-05-12 19:25:49,471 - PriorityDownloader - INFO - Added 7 new rows for ISRA.PA (1m)\n",
      "2025-05-12 19:25:49,486 - PriorityDownloader - INFO - Added 1049 new rows for BNK.PA (1m)\n",
      "2025-05-12 19:25:52,508 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:25:53,527 - PriorityDownloader - INFO - Added 2362 new rows for ETZ.PA (1m)\n",
      "2025-05-12 19:25:53,575 - PriorityDownloader - INFO - Added 781 new rows for PASI.PA (1m)\n",
      "2025-05-12 19:25:53,598 - PriorityDownloader - INFO - Added 240 new rows for SEME.PA (1m)\n",
      "2025-05-12 19:25:53,611 - PriorityDownloader - INFO - Added 250 new rows for ETZD.PA (1m)\n",
      "2025-05-12 19:25:53,622 - PriorityDownloader - INFO - Added 226 new rows for CNY.PA (1m)\n",
      "2025-05-12 19:25:53,658 - PriorityDownloader - INFO - Added 1177 new rows for PAASI.PA (1m)\n",
      "2025-05-12 19:25:53,689 - PriorityDownloader - INFO - Added 546 new rows for PSPH.PA (1m)\n",
      "2025-05-12 19:25:53,730 - PriorityDownloader - INFO - Added 430 new rows for ESD.PA (1m)\n",
      "2025-05-12 19:25:53,750 - PriorityDownloader - INFO - Added 682 new rows for ABDJI.PA (1m)\n",
      "2025-05-12 19:25:53,768 - PriorityDownloader - INFO - Added 681 new rows for ABNSP.PA (1m)\n",
      "2025-05-12 19:25:53,791 - PriorityDownloader - INFO - Added 666 new rows for AABCH.PA (1m)\n",
      "2025-05-12 19:25:53,814 - PriorityDownloader - INFO - Added 657 new rows for AATCX.PA (1m)\n",
      "2025-05-12 19:25:53,834 - PriorityDownloader - INFO - Added 665 new rows for AAHLT.PA (1m)\n",
      "2025-05-12 19:25:53,852 - PriorityDownloader - INFO - Added 672 new rows for ABSMI.PA (1m)\n",
      "2025-05-12 19:25:53,876 - PriorityDownloader - INFO - Added 1507 new rows for CACC.PA (1m)\n",
      "2025-05-12 19:25:56,912 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:25:57,935 - PriorityDownloader - INFO - Added 3000 new rows for PUST.PA (1m)\n",
      "2025-05-12 19:25:57,990 - PriorityDownloader - INFO - Added 657 new rows for AAFIN.PA (1m)\n",
      "2025-05-12 19:25:58,008 - PriorityDownloader - INFO - Added 628 new rows for AABFB.PA (1m)\n",
      "2025-05-12 19:25:58,025 - PriorityDownloader - INFO - Added 16 new rows for GEMU.PA (1m)\n",
      "2025-05-12 19:25:58,035 - PriorityDownloader - INFO - Added 606 new rows for AARTL.PA (1m)\n",
      "2025-05-12 19:25:58,050 - PriorityDownloader - INFO - Added 337 new rows for OBLI.PA (1m)\n",
      "2025-05-12 19:25:58,064 - PriorityDownloader - INFO - Added 622 new rows for 8G19V.PA (1m)\n",
      "2025-05-12 19:25:58,081 - PriorityDownloader - INFO - Added 607 new rows for NB22V.PA (1m)\n",
      "2025-05-12 19:25:58,099 - PriorityDownloader - INFO - Added 593 new rows for NB28V.PA (1m)\n",
      "2025-05-12 19:25:58,114 - PriorityDownloader - INFO - Added 32 new rows for SPEEU.PA (1m)\n",
      "2025-05-12 19:25:58,124 - PriorityDownloader - INFO - Added 40 new rows for ERTH.PA (1m)\n",
      "2025-05-12 19:25:58,133 - PriorityDownloader - INFO - Added 604 new rows for AABEN.PA (1m)\n",
      "2025-05-12 19:25:58,151 - PriorityDownloader - INFO - Added 603 new rows for ABDJE.PA (1m)\n",
      "2025-05-12 19:25:58,169 - PriorityDownloader - INFO - Added 435 new rows for ABHSN.PA (1m)\n",
      "2025-05-12 19:25:58,184 - PriorityDownloader - INFO - Added 608 new rows for AAUTL.PA (1m)\n",
      "2025-05-12 19:26:01,199 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:26:02,210 - PriorityDownloader - INFO - Added 609 new rows for AAINS.PA (1m)\n",
      "2025-05-12 19:26:02,227 - PriorityDownloader - INFO - Added 252 new rows for HSTE.PA (1m)\n",
      "2025-05-12 19:26:02,242 - PriorityDownloader - INFO - Added 364 new rows for SP5.PA (1m)\n",
      "2025-05-12 19:26:02,261 - PriorityDownloader - INFO - Added 572 new rows for AASTX.PA (1m)\n",
      "2025-05-12 19:26:02,278 - PriorityDownloader - INFO - Added 669 new rows for ABNSQ.PA (1m)\n",
      "2025-05-12 19:26:02,295 - PriorityDownloader - INFO - Added 140 new rows for BRES.PA (1m)\n",
      "2025-05-12 19:26:02,378 - PriorityDownloader - INFO - Added 1918 new rows for PE500.PA (1m)\n",
      "2025-05-12 19:26:02,419 - PriorityDownloader - INFO - Added 584 new rows for AABKX.PA (1m)\n",
      "2025-05-12 19:26:02,442 - PriorityDownloader - INFO - Added 2097 new rows for PAEEM.PA (1m)\n",
      "2025-05-12 19:26:02,478 - PriorityDownloader - INFO - Added 27 new rows for EEE.PA (1m)\n",
      "2025-05-12 19:26:02,489 - PriorityDownloader - INFO - Added 522 new rows for AATLC.PA (1m)\n",
      "2025-05-12 19:26:02,505 - PriorityDownloader - INFO - Added 201 new rows for E40.PA (1m)\n",
      "2025-05-12 19:26:02,515 - PriorityDownloader - INFO - Added 25 new rows for MUSRI.PA (1m)\n",
      "2025-05-12 19:26:02,526 - PriorityDownloader - INFO - Added 138 new rows for ESDD.PA (1m)\n",
      "2025-05-12 19:26:02,540 - PriorityDownloader - INFO - Added 663 new rows for XQ48V.PA (1m)\n",
      "2025-05-12 19:26:05,551 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:26:05,917 - yfinance - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-12 19:26:05,917 - yfinance - ERROR - ['0DZF.IL']: YFPricesMissingError('possibly delisted; no price data found  (period=7d)')\n",
      "2025-05-12 19:26:05,988 - StockDownloader - WARNING - Empty data for 0DZF.IL (interval 1m)\n",
      "2025-05-12 19:26:06,574 - PriorityDownloader - INFO - Added 1167 new rows for CAC.PA (1m)\n",
      "2025-05-12 19:26:06,612 - PriorityDownloader - INFO - Added 1256 new rows for UST.PA (1m)\n",
      "2025-05-12 19:26:06,644 - PriorityDownloader - INFO - Added 56 new rows for EEMK.PA (1m)\n",
      "2025-05-12 19:26:06,654 - PriorityDownloader - INFO - Added 227 new rows for CEC.PA (1m)\n",
      "2025-05-12 19:26:06,662 - PriorityDownloader - INFO - Added 39 new rows for EGRI.PA (1m)\n",
      "2025-05-12 19:26:06,668 - PriorityDownloader - INFO - Added 19 new rows for ETHC-EUR.PA (1m)\n",
      "2025-05-12 19:26:06,675 - PriorityDownloader - INFO - Added 1 new rows for 0G28.IL (1m)\n",
      "2025-05-12 19:26:06,681 - PriorityDownloader - INFO - Added 4 new rows for 0Y4H.IL (1m)\n",
      "2025-05-12 19:26:06,688 - PriorityDownloader - INFO - Added 2 new rows for 0MPR.IL (1m)\n",
      "2025-05-12 19:26:06,703 - PriorityDownloader - INFO - Added 1248 new rows for TS3S.L (1m)\n",
      "2025-05-12 19:26:06,737 - PriorityDownloader - INFO - Added 1 new rows for 0A09.L (1m)\n",
      "2025-05-12 19:26:06,745 - PriorityDownloader - INFO - Added 66 new rows for XT2D.L (1m)\n",
      "2025-05-12 19:26:06,757 - PriorityDownloader - INFO - Added 516 new rows for CNYA.L (1m)\n",
      "2025-05-12 19:26:06,776 - PriorityDownloader - INFO - Added 35 new rows for SUOE.L (1m)\n",
      "2025-05-12 19:26:09,782 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:26:10,201 - yfinance - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-12 19:26:10,201 - yfinance - ERROR - ['JCAU.L']: YFPricesMissingError('possibly delisted; no price data found  (period=7d)')\n",
      "2025-05-12 19:26:10,278 - StockDownloader - WARNING - Empty data for JCAU.L (interval 1m)\n",
      "2025-05-12 19:26:10,799 - PriorityDownloader - INFO - Added 98 new rows for FRXD.L (1m)\n",
      "2025-05-12 19:26:10,808 - PriorityDownloader - INFO - Added 127 new rows for XSD2.L (1m)\n",
      "2025-05-12 19:26:10,817 - PriorityDownloader - INFO - Added 12 new rows for 0HOV.IL (1m)\n",
      "2025-05-12 19:26:10,835 - PriorityDownloader - INFO - Added 2952 new rows for ISF.L (1m)\n",
      "2025-05-12 19:26:10,886 - PriorityDownloader - INFO - Added 17 new rows for N100.L (1m)\n",
      "2025-05-12 19:26:10,893 - PriorityDownloader - INFO - Added 56 new rows for 0Y8R.IL (1m)\n",
      "2025-05-12 19:26:10,914 - PriorityDownloader - INFO - Added 2011 new rows for DTLA.L (1m)\n",
      "2025-05-12 19:26:10,952 - PriorityDownloader - INFO - Added 2 new rows for 0MRJ.IL (1m)\n",
      "2025-05-12 19:26:10,969 - PriorityDownloader - INFO - Added 754 new rows for IBTA.L (1m)\n",
      "2025-05-12 19:26:10,998 - PriorityDownloader - INFO - Added 788 new rows for SUSW.L (1m)\n",
      "2025-05-12 19:26:11,022 - PriorityDownloader - INFO - Added 8 new rows for SPEH.L (1m)\n",
      "2025-05-12 19:26:11,029 - PriorityDownloader - INFO - Added 15 new rows for HIGG.L (1m)\n",
      "2025-05-12 19:26:11,037 - PriorityDownloader - INFO - Added 19 new rows for 0XC5.IL (1m)\n",
      "2025-05-12 19:26:11,043 - PriorityDownloader - INFO - Added 2 new rows for HAGG.L (1m)\n",
      "2025-05-12 19:26:14,044 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:26:14,410 - yfinance - ERROR - \n",
      "2 Failed downloads:\n",
      "2025-05-12 19:26:14,410 - yfinance - ERROR - ['0GBX.IL', '0Y2B.L']: YFPricesMissingError('possibly delisted; no price data found  (period=7d)')\n",
      "2025-05-12 19:26:14,508 - StockDownloader - WARNING - Empty data for 0Y2B.L (interval 1m)\n",
      "2025-05-12 19:26:14,547 - StockDownloader - WARNING - Empty data for 0GBX.IL (interval 1m)\n",
      "2025-05-12 19:26:15,056 - PriorityDownloader - INFO - Added 18 new rows for UC76.L (1m)\n",
      "2025-05-12 19:26:15,071 - PriorityDownloader - INFO - Added 622 new rows for AGBP.L (1m)\n",
      "2025-05-12 19:26:15,113 - PriorityDownloader - INFO - Added 992 new rows for MIDD.L (1m)\n",
      "2025-05-12 19:26:15,136 - PriorityDownloader - INFO - Added 9 new rows for FUSR.L (1m)\n",
      "2025-05-12 19:26:15,142 - PriorityDownloader - INFO - Added 2 new rows for 0DZB.L (1m)\n",
      "2025-05-12 19:26:15,154 - PriorityDownloader - INFO - Added 483 new rows for DTLE.L (1m)\n",
      "2025-05-12 19:26:15,177 - PriorityDownloader - INFO - Added 1901 new rows for IGLT.L (1m)\n",
      "2025-05-12 19:26:15,219 - PriorityDownloader - INFO - Added 477 new rows for SDIA.L (1m)\n",
      "2025-05-12 19:26:15,238 - PriorityDownloader - INFO - Added 3 new rows for IEBB.IL (1m)\n",
      "2025-05-12 19:26:15,254 - PriorityDownloader - INFO - Added 509 new rows for IHYA.L (1m)\n",
      "2025-05-12 19:26:15,271 - PriorityDownloader - INFO - Added 239 new rows for EWSX.L (1m)\n",
      "2025-05-12 19:26:15,286 - PriorityDownloader - INFO - Added 34 new rows for 0L4R.L (1m)\n",
      "2025-05-12 19:26:15,294 - PriorityDownloader - INFO - Added 237 new rows for HYLA.L (1m)\n",
      "2025-05-12 19:26:18,298 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:26:18,747 - yfinance - ERROR - \n",
      "3 Failed downloads:\n",
      "2025-05-12 19:26:18,748 - yfinance - ERROR - ['EMAU.L', '0HEP.L', 'HGAS.L']: YFPricesMissingError('possibly delisted; no price data found  (period=7d)')\n",
      "2025-05-12 19:26:18,838 - StockDownloader - WARNING - Empty data for 0HEP.L (interval 1m)\n",
      "2025-05-12 19:26:18,879 - StockDownloader - WARNING - Empty data for EMAU.L (interval 1m)\n",
      "2025-05-12 19:26:18,916 - StockDownloader - WARNING - Empty data for HGAS.L (interval 1m)\n",
      "2025-05-12 19:26:19,313 - PriorityDownloader - INFO - Added 883 new rows for IDTL.L (1m)\n",
      "2025-05-12 19:26:19,345 - PriorityDownloader - INFO - Added 1820 new rows for IUIT.L (1m)\n",
      "2025-05-12 19:26:19,384 - PriorityDownloader - INFO - Added 6 new rows for 0DYZ.IL (1m)\n",
      "2025-05-12 19:26:19,391 - PriorityDownloader - INFO - Added 6 new rows for PAWD.L (1m)\n",
      "2025-05-12 19:26:19,398 - PriorityDownloader - INFO - Added 104 new rows for HCGU.L (1m)\n",
      "2025-05-12 19:26:19,405 - PriorityDownloader - INFO - Added 14 new rows for 0MP3.IL (1m)\n",
      "2025-05-12 19:26:19,410 - PriorityDownloader - INFO - Added 21 new rows for SNGB.L (1m)\n",
      "2025-05-12 19:26:19,417 - PriorityDownloader - INFO - Added 2 new rows for 0WA3.IL (1m)\n",
      "2025-05-12 19:26:19,423 - PriorityDownloader - INFO - Added 22 new rows for MTHG.L (1m)\n",
      "2025-05-12 19:26:19,437 - PriorityDownloader - INFO - Added 649 new rows for FLOA.L (1m)\n",
      "2025-05-12 19:26:19,479 - PriorityDownloader - INFO - Added 301 new rows for LQDA.L (1m)\n",
      "2025-05-12 19:26:19,499 - PriorityDownloader - INFO - Added 507 new rows for IEAC.L (1m)\n",
      "2025-05-12 19:26:22,517 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:26:23,033 - yfinance - ERROR - \n",
      "1 Failed download:\n",
      "2025-05-12 19:26:23,033 - yfinance - ERROR - ['V3SU.L']: YFPricesMissingError('possibly delisted; no price data found  (period=7d)')\n",
      "2025-05-12 19:26:23,098 - StockDownloader - WARNING - Empty data for V3SU.L (interval 1m)\n",
      "2025-05-12 19:26:23,530 - PriorityDownloader - INFO - Added 6 new rows for AREG.L (1m)\n",
      "2025-05-12 19:26:23,539 - PriorityDownloader - INFO - Added 1 new rows for 0H9U.L (1m)\n",
      "2025-05-12 19:26:23,552 - PriorityDownloader - INFO - Added 2676 new rows for NDIA.L (1m)\n",
      "2025-05-12 19:26:23,614 - PriorityDownloader - INFO - Added 2910 new rows for FWRG.L (1m)\n",
      "2025-05-12 19:26:23,675 - PriorityDownloader - INFO - Added 1782 new rows for IGTM.L (1m)\n",
      "2025-05-12 19:26:23,709 - PriorityDownloader - INFO - Added 35 new rows for GDMS.L (1m)\n",
      "2025-05-12 19:26:23,720 - PriorityDownloader - INFO - Added 234 new rows for 0WA5.IL (1m)\n",
      "2025-05-12 19:26:23,736 - PriorityDownloader - INFO - Added 610 new rows for UIFS.L (1m)\n",
      "2025-05-12 19:26:23,752 - PriorityDownloader - INFO - Added 42 new rows for XGSI.L (1m)\n",
      "2025-05-12 19:26:23,764 - PriorityDownloader - INFO - Added 785 new rows for 0KZC.L (1m)\n",
      "2025-05-12 19:26:23,784 - PriorityDownloader - INFO - Added 4 new rows for BS0A.L (1m)\n",
      "2025-05-12 19:26:23,791 - PriorityDownloader - INFO - Added 3 new rows for XDNS.L (1m)\n",
      "2025-05-12 19:26:23,799 - PriorityDownloader - INFO - Added 114 new rows for I50D.L (1m)\n",
      "2025-05-12 19:26:23,820 - PriorityDownloader - INFO - Added 2549 new rows for FXI (1m)\n",
      "2025-05-12 19:26:26,864 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:26:27,893 - PriorityDownloader - INFO - Added 2553 new rows for SPY (1m)\n",
      "2025-05-12 19:26:27,953 - PriorityDownloader - INFO - Added 2550 new rows for KWEB (1m)\n",
      "2025-05-12 19:26:28,076 - PriorityDownloader - INFO - Added 2548 new rows for IBIT (1m)\n",
      "2025-05-12 19:26:28,138 - PriorityDownloader - INFO - Added 2555 new rows for MSTU (1m)\n",
      "2025-05-12 19:26:28,201 - PriorityDownloader - INFO - Added 2556 new rows for XLF (1m)\n",
      "2025-05-12 19:26:28,265 - PriorityDownloader - INFO - Added 2548 new rows for EEM (1m)\n",
      "2025-05-12 19:26:28,327 - PriorityDownloader - INFO - Added 2551 new rows for TLT (1m)\n",
      "2025-05-12 19:26:28,388 - PriorityDownloader - INFO - Added 2557 new rows for HYG (1m)\n",
      "2025-05-12 19:26:28,448 - PriorityDownloader - INFO - Added 2551 new rows for EWZ (1m)\n",
      "2025-05-12 19:26:28,511 - PriorityDownloader - INFO - Added 2557 new rows for IWM (1m)\n",
      "2025-05-12 19:26:28,631 - PriorityDownloader - INFO - Added 2555 new rows for SLV (1m)\n",
      "2025-05-12 19:26:28,697 - PriorityDownloader - INFO - Added 2551 new rows for LQD (1m)\n",
      "2025-05-12 19:26:28,761 - PriorityDownloader - INFO - Added 2556 new rows for MSTZ (1m)\n",
      "2025-05-12 19:26:28,823 - PriorityDownloader - INFO - Added 2556 new rows for GDX (1m)\n",
      "2025-05-12 19:26:28,884 - PriorityDownloader - INFO - Added 2554 new rows for SCHD (1m)\n",
      "2025-05-12 19:26:31,941 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:26:32,964 - PriorityDownloader - INFO - Added 2555 new rows for VEA (1m)\n",
      "2025-05-12 19:26:33,092 - PriorityDownloader - INFO - Added 2554 new rows for EFA (1m)\n",
      "2025-05-12 19:26:33,156 - PriorityDownloader - INFO - Added 2530 new rows for SCHF (1m)\n",
      "2025-05-12 19:26:33,216 - PriorityDownloader - INFO - Added 2556 new rows for XBI (1m)\n",
      "2025-05-12 19:26:33,283 - PriorityDownloader - INFO - Added 2555 new rows for KRE (1m)\n",
      "2025-05-12 19:26:33,343 - PriorityDownloader - INFO - Added 2556 new rows for XLE (1m)\n",
      "2025-05-12 19:26:33,405 - PriorityDownloader - INFO - Added 2558 new rows for XLV (1m)\n",
      "2025-05-12 19:26:33,467 - PriorityDownloader - INFO - Added 2526 new rows for BITO (1m)\n",
      "2025-05-12 19:26:33,528 - PriorityDownloader - INFO - Added 2495 new rows for USHY (1m)\n",
      "2025-05-12 19:26:33,595 - PriorityDownloader - INFO - Added 2554 new rows for IEMG (1m)\n",
      "2025-05-12 19:26:33,711 - PriorityDownloader - INFO - Added 2525 new rows for SCHX (1m)\n",
      "2025-05-12 19:26:33,772 - PriorityDownloader - INFO - Added 2556 new rows for XLI (1m)\n",
      "2025-05-12 19:26:33,837 - PriorityDownloader - INFO - Added 2556 new rows for ARKK (1m)\n",
      "2025-05-12 19:26:33,899 - PriorityDownloader - INFO - Added 2280 new rows for ASHR (1m)\n",
      "2025-05-12 19:26:33,957 - PriorityDownloader - INFO - Added 2557 new rows for IEFA (1m)\n",
      "2025-05-12 19:26:37,012 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:26:38,031 - PriorityDownloader - INFO - Added 2366 new rows for EMXC (1m)\n",
      "2025-05-12 19:26:38,088 - PriorityDownloader - INFO - Added 2556 new rows for GLD (1m)\n",
      "2025-05-12 19:26:38,155 - PriorityDownloader - INFO - Added 2400 new rows for RWM (1m)\n",
      "2025-05-12 19:26:38,266 - PriorityDownloader - INFO - Added 2556 new rows for VOO (1m)\n",
      "2025-05-12 19:26:38,344 - PriorityDownloader - INFO - Added 2553 new rows for VWO (1m)\n",
      "2025-05-12 19:26:38,408 - PriorityDownloader - INFO - Added 2374 new rows for MCHI (1m)\n",
      "2025-05-12 19:26:38,466 - PriorityDownloader - INFO - Added 2555 new rows for IJH (1m)\n",
      "2025-05-12 19:26:38,529 - PriorityDownloader - INFO - Added 2464 new rows for ETHA (1m)\n",
      "2025-05-12 19:26:38,589 - PriorityDownloader - INFO - Added 2554 new rows for XLP (1m)\n",
      "2025-05-12 19:26:38,654 - PriorityDownloader - INFO - Added 2543 new rows for MSTX (1m)\n",
      "2025-05-12 19:26:38,721 - PriorityDownloader - INFO - Added 2541 new rows for JAAA (1m)\n",
      "2025-05-12 19:26:38,785 - PriorityDownloader - INFO - Added 2553 new rows for SCHG (1m)\n",
      "2025-05-12 19:26:38,850 - PriorityDownloader - INFO - Added 2534 new rows for EWJ (1m)\n",
      "2025-05-12 19:26:38,988 - PriorityDownloader - INFO - Added 2557 new rows for XLU (1m)\n",
      "2025-05-12 19:26:39,056 - PriorityDownloader - INFO - Added 2549 new rows for SMH (1m)\n",
      "2025-05-12 19:26:42,118 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:26:43,159 - PriorityDownloader - INFO - Added 2554 new rows for IAU (1m)\n",
      "2025-05-12 19:26:43,236 - PriorityDownloader - INFO - Added 2413 new rows for SGOL (1m)\n",
      "2025-05-12 19:26:43,301 - PriorityDownloader - INFO - Added 2434 new rows for QYLD (1m)\n",
      "2025-05-12 19:26:43,364 - PriorityDownloader - INFO - Added 2552 new rows for XLB (1m)\n",
      "2025-05-12 19:26:43,432 - PriorityDownloader - INFO - Added 2550 new rows for XRT (1m)\n",
      "2025-05-12 19:26:43,497 - PriorityDownloader - INFO - Added 2244 new rows for NVD (1m)\n",
      "2025-05-12 19:26:43,613 - PriorityDownloader - INFO - Added 2556 new rows for SGOV (1m)\n",
      "2025-05-12 19:26:43,691 - PriorityDownloader - INFO - Added 2556 new rows for RSP (1m)\n",
      "2025-05-12 19:26:43,753 - PriorityDownloader - INFO - Added 753 new rows for KORU (1m)\n",
      "2025-05-12 19:26:43,792 - PriorityDownloader - INFO - Added 2541 new rows for BND (1m)\n",
      "2025-05-12 19:26:43,853 - PriorityDownloader - INFO - Added 2558 new rows for BIL (1m)\n",
      "2025-05-12 19:26:43,925 - PriorityDownloader - INFO - Added 2552 new rows for AGG (1m)\n",
      "2025-05-12 19:26:43,991 - PriorityDownloader - INFO - Added 2393 new rows for BKLN (1m)\n",
      "2025-05-12 19:26:44,053 - PriorityDownloader - INFO - Added 2377 new rows for SCHH (1m)\n",
      "2025-05-12 19:26:44,120 - PriorityDownloader - INFO - Added 2555 new rows for SPLG (1m)\n",
      "2025-05-12 19:26:47,172 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:26:48,242 - PriorityDownloader - INFO - Added 2519 new rows for UNG (1m)\n",
      "2025-05-12 19:26:48,306 - PriorityDownloader - INFO - Added 1856 new rows for EMLC (1m)\n",
      "2025-05-12 19:26:48,363 - PriorityDownloader - INFO - Added 2538 new rows for INDA (1m)\n",
      "2025-05-12 19:26:48,442 - PriorityDownloader - INFO - Added 2453 new rows for FEZ (1m)\n",
      "2025-05-12 19:26:48,508 - PriorityDownloader - INFO - Added 2532 new rows for CONY (1m)\n",
      "2025-05-12 19:26:48,575 - PriorityDownloader - INFO - Added 2475 new rows for SCHB (1m)\n",
      "2025-05-12 19:26:48,630 - PriorityDownloader - INFO - Added 2037 new rows for SPTI (1m)\n",
      "2025-05-12 19:26:48,698 - PriorityDownloader - INFO - Added 2487 new rows for VCIT (1m)\n",
      "2025-05-12 19:26:48,765 - PriorityDownloader - INFO - Added 2506 new rows for GOVT (1m)\n",
      "2025-05-12 19:26:48,831 - PriorityDownloader - INFO - Added 2555 new rows for IGV (1m)\n",
      "2025-05-12 19:26:48,972 - PriorityDownloader - INFO - Added 2272 new rows for MSOS (1m)\n",
      "2025-05-12 19:26:49,031 - PriorityDownloader - INFO - Added 2554 new rows for GDXJ (1m)\n",
      "2025-05-12 19:26:49,095 - PriorityDownloader - INFO - Added 2435 new rows for SBIT (1m)\n",
      "2025-05-12 19:26:49,164 - PriorityDownloader - INFO - Added 2359 new rows for IQLT (1m)\n",
      "2025-05-12 19:26:49,227 - PriorityDownloader - INFO - Added 2546 new rows for VXX (1m)\n",
      "2025-05-12 19:26:52,276 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:26:53,294 - PriorityDownloader - INFO - Added 2381 new rows for SHV (1m)\n",
      "2025-05-12 19:26:53,361 - PriorityDownloader - INFO - Added 2453 new rows for PSQ (1m)\n",
      "2025-05-12 19:26:53,426 - PriorityDownloader - INFO - Added 2428 new rows for EMB (1m)\n",
      "2025-05-12 19:26:53,490 - PriorityDownloader - INFO - Added 2545 new rows for VXUS (1m)\n",
      "2025-05-12 19:26:53,612 - PriorityDownloader - INFO - Added 2545 new rows for JEPQ (1m)\n",
      "2025-05-12 19:26:53,684 - PriorityDownloader - INFO - Added 2554 new rows for IYR (1m)\n",
      "2025-05-12 19:26:53,755 - PriorityDownloader - INFO - Added 2511 new rows for VTEB (1m)\n",
      "2025-05-12 19:26:53,828 - PriorityDownloader - INFO - Added 2187 new rows for SPIB (1m)\n",
      "2025-05-12 19:26:53,884 - PriorityDownloader - INFO - Added 2532 new rows for IEF (1m)\n",
      "2025-05-12 19:26:53,954 - PriorityDownloader - INFO - Added 2556 new rows for MSTY (1m)\n",
      "2025-05-12 19:26:54,023 - PriorityDownloader - INFO - Added 2548 new rows for JPST (1m)\n",
      "2025-05-12 19:26:54,088 - PriorityDownloader - INFO - Added 2525 new rows for FBTC (1m)\n",
      "2025-05-12 19:26:54,152 - PriorityDownloader - INFO - Added 2554 new rows for XLK (1m)\n",
      "2025-05-12 19:26:54,223 - PriorityDownloader - INFO - Added 2491 new rows for SPDW (1m)\n",
      "2025-05-12 19:26:54,362 - PriorityDownloader - INFO - Added 2127 new rows for EWH (1m)\n",
      "2025-05-12 19:26:57,405 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:26:58,437 - PriorityDownloader - INFO - Added 2552 new rows for JEPI (1m)\n",
      "2025-05-12 19:26:58,499 - PriorityDownloader - INFO - Added 2191 new rows for ILF (1m)\n",
      "2025-05-12 19:26:58,561 - PriorityDownloader - INFO - Added 2193 new rows for PGX (1m)\n",
      "2025-05-12 19:26:58,626 - PriorityDownloader - INFO - Added 2551 new rows for IJR (1m)\n",
      "2025-05-12 19:26:58,695 - PriorityDownloader - INFO - Added 1348 new rows for IYZ (1m)\n",
      "2025-05-12 19:26:58,755 - PriorityDownloader - INFO - Added 2345 new rows for SPHY (1m)\n",
      "2025-05-12 19:26:58,895 - PriorityDownloader - INFO - Added 2519 new rows for CGGR (1m)\n",
      "2025-05-12 19:26:58,960 - PriorityDownloader - INFO - Added 2513 new rows for EWY (1m)\n",
      "2025-05-12 19:26:59,028 - PriorityDownloader - INFO - Added 2555 new rows for KOLD (1m)\n",
      "2025-05-12 19:26:59,092 - PriorityDownloader - INFO - Added 2393 new rows for SCHP (1m)\n",
      "2025-05-12 19:26:59,158 - PriorityDownloader - INFO - Added 2551 new rows for VTI (1m)\n",
      "2025-05-12 19:26:59,238 - PriorityDownloader - INFO - Added 2520 new rows for CGDV (1m)\n",
      "2025-05-12 19:26:59,305 - PriorityDownloader - INFO - Added 2403 new rows for SHY (1m)\n",
      "2025-05-12 19:26:59,371 - PriorityDownloader - INFO - Added 2249 new rows for ITB (1m)\n",
      "2025-05-12 19:26:59,435 - PriorityDownloader - INFO - Added 2418 new rows for SILJ (1m)\n",
      "2025-05-12 19:27:02,479 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:27:03,567 - PriorityDownloader - INFO - Added 2554 new rows for IVV (1m)\n",
      "2025-05-12 19:27:03,635 - PriorityDownloader - INFO - Added 2409 new rows for SPTL (1m)\n",
      "2025-05-12 19:27:03,698 - PriorityDownloader - INFO - Added 2509 new rows for SOXX (1m)\n",
      "2025-05-12 19:27:03,775 - PriorityDownloader - INFO - Added 2148 new rows for SRLN (1m)\n",
      "2025-05-12 19:27:03,837 - PriorityDownloader - INFO - Added 2393 new rows for XHB (1m)\n",
      "2025-05-12 19:27:03,902 - PriorityDownloader - INFO - Added 2354 new rows for TIP (1m)\n",
      "2025-05-12 19:27:03,959 - PriorityDownloader - INFO - Added 826 new rows for EZA (1m)\n",
      "2025-05-12 19:27:03,998 - PriorityDownloader - INFO - Added 2354 new rows for ETHE (1m)\n",
      "2025-05-12 19:27:04,062 - PriorityDownloader - INFO - Added 2550 new rows for XLC (1m)\n",
      "2025-05-12 19:27:04,129 - PriorityDownloader - INFO - Added 2403 new rows for FBND (1m)\n",
      "2025-05-12 19:27:04,274 - PriorityDownloader - INFO - Added 2352 new rows for VGIT (1m)\n",
      "2025-05-12 19:27:04,341 - PriorityDownloader - INFO - Added 2519 new rows for USFR (1m)\n",
      "2025-05-12 19:27:04,401 - PriorityDownloader - INFO - Added 884 new rows for VCRB (1m)\n",
      "2025-05-12 19:27:04,438 - PriorityDownloader - INFO - Added 2199 new rows for HEFA (1m)\n",
      "2025-05-12 19:27:04,498 - PriorityDownloader - INFO - Added 2432 new rows for GBTC (1m)\n",
      "2025-05-12 19:27:07,548 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:27:08,575 - PriorityDownloader - INFO - Added 2489 new rows for ARKG (1m)\n",
      "2025-05-12 19:27:08,637 - PriorityDownloader - INFO - Added 2440 new rows for VGSH (1m)\n",
      "2025-05-12 19:27:08,698 - PriorityDownloader - INFO - Added 2557 new rows for XLY (1m)\n",
      "2025-05-12 19:27:08,761 - PriorityDownloader - INFO - Added 2360 new rows for SJNK (1m)\n",
      "2025-05-12 19:27:08,821 - PriorityDownloader - INFO - Added 2438 new rows for ACWI (1m)\n",
      "2025-05-12 19:27:08,943 - PriorityDownloader - INFO - Added 1944 new rows for ICLN (1m)\n",
      "2025-05-12 19:27:09,002 - PriorityDownloader - INFO - Added 2541 new rows for VTV (1m)\n",
      "2025-05-12 19:27:09,066 - PriorityDownloader - INFO - Added 2524 new rows for GLDM (1m)\n",
      "2025-05-12 19:27:09,132 - PriorityDownloader - INFO - Added 2546 new rows for XOP (1m)\n",
      "2025-05-12 19:27:09,192 - PriorityDownloader - INFO - Added 1762 new rows for JCPB (1m)\n",
      "2025-05-12 19:27:09,245 - PriorityDownloader - INFO - Added 2546 new rows for VNQ (1m)\n",
      "2025-05-12 19:27:09,308 - PriorityDownloader - INFO - Added 2440 new rows for SCHA (1m)\n",
      "2025-05-12 19:27:09,368 - PriorityDownloader - INFO - Added 2464 new rows for PFF (1m)\n",
      "2025-05-12 19:27:09,430 - PriorityDownloader - INFO - Added 2411 new rows for PAVE (1m)\n",
      "2025-05-12 19:27:09,491 - PriorityDownloader - INFO - Added 2285 new rows for PDBC (1m)\n",
      "2025-05-12 19:27:12,534 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:27:13,554 - PriorityDownloader - INFO - Added 2449 new rows for EFV (1m)\n",
      "2025-05-12 19:27:13,615 - PriorityDownloader - INFO - Added 2447 new rows for BNDX (1m)\n",
      "2025-05-12 19:27:13,676 - PriorityDownloader - INFO - Added 1774 new rows for DOG (1m)\n",
      "2025-05-12 19:27:13,733 - PriorityDownloader - INFO - Added 2517 new rows for EWT (1m)\n",
      "2025-05-12 19:27:13,792 - PriorityDownloader - INFO - Added 2341 new rows for IUSB (1m)\n",
      "2025-05-12 19:27:13,853 - PriorityDownloader - INFO - Added 2487 new rows for EZU (1m)\n",
      "2025-05-12 19:27:13,914 - PriorityDownloader - INFO - Added 2312 new rows for BITB (1m)\n",
      "2025-05-12 19:27:13,973 - PriorityDownloader - INFO - Added 2518 new rows for SPYV (1m)\n",
      "2025-05-12 19:27:14,034 - PriorityDownloader - INFO - Added 2494 new rows for JNK (1m)\n",
      "2025-05-12 19:27:14,095 - PriorityDownloader - INFO - Added 1099 new rows for BSCT (1m)\n",
      "2025-05-12 19:27:14,137 - PriorityDownloader - INFO - Added 2506 new rows for DIA (1m)\n",
      "2025-05-12 19:27:14,266 - PriorityDownloader - INFO - Added 2421 new rows for IBB (1m)\n",
      "2025-05-12 19:27:14,330 - PriorityDownloader - INFO - Added 2432 new rows for XME (1m)\n",
      "2025-05-12 19:27:14,379 - PriorityDownloader - INFO - Added 173 new rows for RSHO (1m)\n",
      "2025-05-12 19:27:14,402 - PriorityDownloader - INFO - Added 2454 new rows for EWW (1m)\n",
      "2025-05-12 19:27:17,446 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:27:18,469 - PriorityDownloader - INFO - Added 2435 new rows for SPSM (1m)\n",
      "2025-05-12 19:27:18,530 - PriorityDownloader - INFO - Added 2289 new rows for SCHO (1m)\n",
      "2025-05-12 19:27:18,590 - PriorityDownloader - INFO - Added 2380 new rows for EWC (1m)\n",
      "2025-05-12 19:27:18,650 - PriorityDownloader - INFO - Added 2508 new rows for VEU (1m)\n",
      "2025-05-12 19:27:18,712 - PriorityDownloader - INFO - Added 2439 new rows for CALF (1m)\n",
      "2025-05-12 19:27:18,833 - PriorityDownloader - INFO - Added 2274 new rows for SCHM (1m)\n",
      "2025-05-12 19:27:18,888 - PriorityDownloader - INFO - Added 2515 new rows for SPYG (1m)\n",
      "2025-05-12 19:27:18,956 - PriorityDownloader - INFO - Added 2551 new rows for USO (1m)\n",
      "2025-05-12 19:27:19,021 - PriorityDownloader - INFO - Added 2548 new rows for TSLT (1m)\n",
      "2025-05-12 19:27:19,084 - PriorityDownloader - INFO - Added 2550 new rows for VGK (1m)\n",
      "2025-05-12 19:27:19,145 - PriorityDownloader - INFO - Added 2543 new rows for MUB (1m)\n",
      "2025-05-12 19:27:19,208 - PriorityDownloader - INFO - Added 2268 new rows for SPMD (1m)\n",
      "2025-05-12 19:27:19,267 - PriorityDownloader - INFO - Added 2532 new rows for COWZ (1m)\n",
      "2025-05-12 19:27:19,390 - PriorityDownloader - INFO - Added 2268 new rows for ETH (1m)\n",
      "2025-05-12 19:27:19,449 - PriorityDownloader - INFO - Added 2338 new rows for COPX (1m)\n",
      "2025-05-12 19:27:22,502 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:27:23,524 - PriorityDownloader - INFO - Added 2404 new rows for AMLP (1m)\n",
      "2025-05-12 19:27:23,585 - PriorityDownloader - INFO - Added 2526 new rows for URA (1m)\n",
      "2025-05-12 19:27:23,647 - PriorityDownloader - INFO - Added 2181 new rows for KBWB (1m)\n",
      "2025-05-12 19:27:23,706 - PriorityDownloader - INFO - Added 2382 new rows for PULS (1m)\n",
      "2025-05-12 19:27:23,766 - PriorityDownloader - INFO - Added 1941 new rows for EWA (1m)\n",
      "2025-05-12 19:27:23,821 - PriorityDownloader - INFO - Added 2376 new rows for BSV (1m)\n",
      "2025-05-12 19:27:23,884 - PriorityDownloader - INFO - Added 2205 new rows for IDEV (1m)\n",
      "2025-05-12 19:27:24,000 - PriorityDownloader - INFO - Added 2480 new rows for EWG (1m)\n",
      "2025-05-12 19:27:24,060 - PriorityDownloader - INFO - Added 2170 new rows for VMBS (1m)\n",
      "2025-05-12 19:27:24,113 - PriorityDownloader - INFO - Added 1862 new rows for SPTS (1m)\n",
      "2025-05-12 19:27:24,168 - PriorityDownloader - INFO - Added 2349 new rows for IXUS (1m)\n",
      "2025-05-12 19:27:24,229 - PriorityDownloader - INFO - Added 2520 new rows for SVIX (1m)\n",
      "2025-05-12 19:27:24,291 - PriorityDownloader - INFO - Added 2096 new rows for VIXY (1m)\n",
      "2025-05-12 19:27:24,350 - PriorityDownloader - INFO - Added 2375 new rows for DFAC (1m)\n",
      "2025-05-12 19:27:24,409 - PriorityDownloader - INFO - Added 2319 new rows for SDVY (1m)\n",
      "2025-05-12 19:27:27,455 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:27:28,476 - PriorityDownloader - INFO - Added 2175 new rows for TFLO (1m)\n",
      "2025-05-12 19:27:28,528 - PriorityDownloader - INFO - Added 2121 new rows for SCHZ (1m)\n",
      "2025-05-12 19:27:28,632 - PriorityDownloader - INFO - Added 1867 new rows for MLPX (1m)\n",
      "2025-05-12 19:27:28,682 - PriorityDownloader - INFO - Added 2329 new rows for SPEM (1m)\n",
      "2025-05-12 19:27:28,741 - PriorityDownloader - INFO - Added 2159 new rows for SPSB (1m)\n",
      "2025-05-12 19:27:28,795 - PriorityDownloader - INFO - Added 2474 new rows for LABU (1m)\n",
      "2025-05-12 19:27:28,852 - PriorityDownloader - INFO - Added 2486 new rows for DYNF (1m)\n",
      "2025-05-12 19:27:28,910 - PriorityDownloader - INFO - Added 2263 new rows for IGSB (1m)\n",
      "2025-05-12 19:27:28,968 - PriorityDownloader - INFO - Added 2305 new rows for CGUS (1m)\n",
      "2025-05-12 19:27:29,026 - PriorityDownloader - INFO - Added 2259 new rows for ETHT (1m)\n",
      "2025-05-12 19:27:29,079 - PriorityDownloader - INFO - Added 1867 new rows for BLV (1m)\n",
      "2025-05-12 19:27:29,133 - PriorityDownloader - INFO - Added 2149 new rows for BBJP (1m)\n",
      "2025-05-12 19:27:29,259 - PriorityDownloader - INFO - Added 2485 new rows for UCO (1m)\n",
      "2025-05-12 19:27:29,319 - PriorityDownloader - INFO - Added 2358 new rows for YMAX (1m)\n",
      "2025-05-12 19:27:29,378 - PriorityDownloader - INFO - Added 2315 new rows for IAUM (1m)\n",
      "2025-05-12 19:27:32,426 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:27:33,448 - PriorityDownloader - INFO - Added 2378 new rows for VCSH (1m)\n",
      "2025-05-12 19:27:33,508 - PriorityDownloader - INFO - Added 2249 new rows for AAAU (1m)\n",
      "2025-05-12 19:27:33,565 - PriorityDownloader - INFO - Added 2269 new rows for VGLT (1m)\n",
      "2025-05-12 19:27:33,624 - PriorityDownloader - INFO - Added 2062 new rows for VTWO (1m)\n",
      "2025-05-12 19:27:33,684 - PriorityDownloader - INFO - Added 2442 new rows for SPMO (1m)\n",
      "2025-05-12 19:27:33,746 - PriorityDownloader - INFO - Added 2440 new rows for TSLR (1m)\n",
      "2025-05-12 19:27:33,807 - PriorityDownloader - INFO - Added 2526 new rows for DGRO (1m)\n",
      "2025-05-12 19:27:33,932 - PriorityDownloader - INFO - Added 1995 new rows for SPAB (1m)\n",
      "2025-05-12 19:27:33,989 - PriorityDownloader - INFO - Added 2445 new rows for KBE (1m)\n",
      "2025-05-12 19:27:34,044 - PriorityDownloader - INFO - Added 437 new rows for AUSF (1m)\n",
      "2025-05-12 19:27:34,070 - PriorityDownloader - INFO - Added 2216 new rows for PYLD (1m)\n",
      "2025-05-12 19:27:34,126 - PriorityDownloader - INFO - Added 2309 new rows for VCLT (1m)\n",
      "2025-05-12 19:27:34,185 - PriorityDownloader - INFO - Added 2028 new rows for NVDU (1m)\n",
      "2025-05-12 19:27:34,244 - PriorityDownloader - INFO - Added 2502 new rows for JETS (1m)\n",
      "2025-05-12 19:27:34,307 - PriorityDownloader - INFO - Added 2426 new rows for IWD (1m)\n",
      "2025-05-12 19:27:37,363 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:27:38,383 - PriorityDownloader - INFO - Added 1862 new rows for CWEB (1m)\n",
      "2025-05-12 19:27:38,434 - PriorityDownloader - INFO - Added 2306 new rows for FNDF (1m)\n",
      "2025-05-12 19:27:38,494 - PriorityDownloader - INFO - Added 1969 new rows for SCHR (1m)\n",
      "2025-05-12 19:27:38,608 - PriorityDownloader - INFO - Added 2173 new rows for FLOT (1m)\n",
      "2025-05-12 19:27:38,663 - PriorityDownloader - INFO - Added 2002 new rows for IGIB (1m)\n",
      "2025-05-12 19:27:38,719 - PriorityDownloader - INFO - Added 2316 new rows for BIV (1m)\n",
      "2025-05-12 19:27:38,773 - PriorityDownloader - INFO - Added 1521 new rows for JBBB (1m)\n",
      "2025-05-12 19:27:38,821 - PriorityDownloader - INFO - Added 2206 new rows for MOAT (1m)\n",
      "2025-05-12 19:27:38,878 - PriorityDownloader - INFO - Added 2010 new rows for DFIC (1m)\n",
      "2025-05-12 19:27:38,931 - PriorityDownloader - INFO - Added 2440 new rows for MBB (1m)\n",
      "2025-05-12 19:27:38,991 - PriorityDownloader - INFO - Added 1873 new rows for URNM (1m)\n",
      "2025-05-12 19:27:39,034 - PriorityDownloader - INFO - Added 348 new rows for QEFA (1m)\n",
      "2025-05-12 19:27:39,059 - PriorityDownloader - INFO - Added 2087 new rows for SCHE (1m)\n",
      "2025-05-12 19:27:39,113 - PriorityDownloader - INFO - Added 1699 new rows for PVAL (1m)\n",
      "2025-05-12 19:27:39,157 - PriorityDownloader - INFO - Added 661 new rows for FGD (1m)\n",
      "2025-05-12 19:27:42,183 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:27:43,204 - PriorityDownloader - INFO - Added 2072 new rows for IEUR (1m)\n",
      "2025-05-12 19:27:43,259 - PriorityDownloader - INFO - Added 2370 new rows for XLG (1m)\n",
      "2025-05-12 19:27:43,386 - PriorityDownloader - INFO - Added 2470 new rows for IVW (1m)\n",
      "2025-05-12 19:27:43,447 - PriorityDownloader - INFO - Added 2212 new rows for BUFR (1m)\n",
      "2025-05-12 19:27:43,506 - PriorityDownloader - INFO - Added 2185 new rows for DFSV (1m)\n",
      "2025-05-12 19:27:43,562 - PriorityDownloader - INFO - Added 2065 new rows for OUNZ (1m)\n",
      "2025-05-12 19:27:43,613 - PriorityDownloader - INFO - Added 1492 new rows for SCHI (1m)\n",
      "2025-05-12 19:27:43,656 - PriorityDownloader - INFO - Added 1909 new rows for VFLO (1m)\n",
      "2025-05-12 19:27:43,710 - PriorityDownloader - INFO - Added 2130 new rows for DFAI (1m)\n",
      "2025-05-12 19:27:43,767 - PriorityDownloader - INFO - Added 2113 new rows for FETH (1m)\n",
      "2025-05-12 19:27:43,827 - PriorityDownloader - INFO - Added 2438 new rows for SPLV (1m)\n",
      "2025-05-12 19:27:43,893 - PriorityDownloader - INFO - Added 2213 new rows for GRNY (1m)\n",
      "2025-05-12 19:27:43,949 - PriorityDownloader - INFO - Added 2160 new rows for IEI (1m)\n",
      "2025-05-12 19:27:43,995 - PriorityDownloader - INFO - Added 190 new rows for EEMA (1m)\n",
      "2025-05-12 19:27:44,017 - PriorityDownloader - INFO - Added 2333 new rows for CIBR (1m)\n",
      "2025-05-12 19:27:47,055 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:27:48,136 - PriorityDownloader - INFO - Added 2095 new rows for CGCP (1m)\n",
      "2025-05-12 19:27:48,187 - PriorityDownloader - INFO - Added 2445 new rows for ITOT (1m)\n",
      "2025-05-12 19:27:48,249 - PriorityDownloader - INFO - Added 2220 new rows for SHYG (1m)\n",
      "2025-05-12 19:27:48,302 - PriorityDownloader - INFO - Added 1511 new rows for BSCR (1m)\n",
      "2025-05-12 19:27:48,346 - PriorityDownloader - INFO - Added 2338 new rows for IWF (1m)\n",
      "2025-05-12 19:27:48,403 - PriorityDownloader - INFO - Added 2249 new rows for RDVY (1m)\n",
      "2025-05-12 19:27:48,461 - PriorityDownloader - INFO - Added 1969 new rows for FPE (1m)\n",
      "2025-05-12 19:27:48,515 - PriorityDownloader - INFO - Added 855 new rows for PXH (1m)\n",
      "2025-05-12 19:27:48,552 - PriorityDownloader - INFO - Added 1734 new rows for BAR (1m)\n",
      "2025-05-12 19:27:48,601 - PriorityDownloader - INFO - Added 1719 new rows for TFI (1m)\n",
      "2025-05-12 19:27:48,729 - PriorityDownloader - INFO - Added 2078 new rows for IWP (1m)\n",
      "2025-05-12 19:27:48,787 - PriorityDownloader - INFO - Added 2237 new rows for BINC (1m)\n",
      "2025-05-12 19:27:48,847 - PriorityDownloader - INFO - Added 2334 new rows for MTUM (1m)\n",
      "2025-05-12 19:27:48,904 - PriorityDownloader - INFO - Added 1510 new rows for UUP (1m)\n",
      "2025-05-12 19:27:48,950 - PriorityDownloader - INFO - Added 2179 new rows for ACWX (1m)\n",
      "2025-05-12 19:27:51,993 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:27:53,012 - PriorityDownloader - INFO - Added 1700 new rows for PZA (1m)\n",
      "2025-05-12 19:27:53,068 - PriorityDownloader - INFO - Added 2254 new rows for MINT (1m)\n",
      "2025-05-12 19:27:53,125 - PriorityDownloader - INFO - Added 1664 new rows for YMAG (1m)\n",
      "2025-05-12 19:27:53,171 - PriorityDownloader - INFO - Added 1682 new rows for SPLB (1m)\n",
      "2025-05-12 19:27:53,221 - PriorityDownloader - INFO - Added 2411 new rows for IWR (1m)\n",
      "2025-05-12 19:27:53,281 - PriorityDownloader - INFO - Added 2469 new rows for USMV (1m)\n",
      "2025-05-12 19:27:53,393 - PriorityDownloader - INFO - Added 2376 new rows for VUG (1m)\n",
      "2025-05-12 19:27:53,447 - PriorityDownloader - INFO - Added 325 new rows for ACES (1m)\n",
      "2025-05-12 19:27:53,474 - PriorityDownloader - INFO - Added 2396 new rows for QUAL (1m)\n",
      "2025-05-12 19:27:53,532 - PriorityDownloader - INFO - Added 1806 new rows for IGLB (1m)\n",
      "2025-05-12 19:27:53,585 - PriorityDownloader - INFO - Added 2408 new rows for SVXY (1m)\n",
      "2025-05-12 19:27:53,645 - PriorityDownloader - INFO - Added 2142 new rows for SCHV (1m)\n",
      "2025-05-12 19:27:53,707 - PriorityDownloader - INFO - Added 2366 new rows for BTC (1m)\n",
      "2025-05-12 19:27:53,765 - PriorityDownloader - INFO - Added 2202 new rows for IYT (1m)\n",
      "2025-05-12 19:27:53,815 - PriorityDownloader - INFO - Added 1481 new rows for AMDY (1m)\n",
      "2025-05-12 19:27:56,846 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:27:57,868 - PriorityDownloader - INFO - Added 1476 new rows for AVGX (1m)\n",
      "2025-05-12 19:27:57,912 - PriorityDownloader - INFO - Added 2165 new rows for SPYD (1m)\n",
      "2025-05-12 19:27:57,967 - PriorityDownloader - INFO - Added 1695 new rows for MRNY (1m)\n",
      "2025-05-12 19:27:58,014 - PriorityDownloader - INFO - Added 2151 new rows for ARKB (1m)\n",
      "2025-05-12 19:27:58,072 - PriorityDownloader - INFO - Added 2423 new rows for VIG (1m)\n",
      "2025-05-12 19:27:58,187 - PriorityDownloader - INFO - Added 2132 new rows for TCAF (1m)\n",
      "2025-05-12 19:27:58,244 - PriorityDownloader - INFO - Added 1979 new rows for ITA (1m)\n",
      "2025-05-12 19:27:58,295 - PriorityDownloader - INFO - Added 2284 new rows for KIE (1m)\n",
      "2025-05-12 19:27:58,349 - PriorityDownloader - INFO - Added 1870 new rows for HYD (1m)\n",
      "2025-05-12 19:27:58,400 - PriorityDownloader - INFO - Added 2365 new rows for TSDD (1m)\n",
      "2025-05-12 19:27:58,456 - PriorityDownloader - INFO - Added 1913 new rows for VUSB (1m)\n",
      "2025-05-12 19:27:58,507 - PriorityDownloader - INFO - Added 2300 new rows for VTIP (1m)\n",
      "2025-05-12 19:27:58,564 - PriorityDownloader - INFO - Added 2138 new rows for FDVV (1m)\n",
      "2025-05-12 19:27:58,612 - PriorityDownloader - INFO - Added 788 new rows for HTRB (1m)\n",
      "2025-05-12 19:27:58,643 - PriorityDownloader - INFO - Added 1718 new rows for FTSM (1m)\n",
      "2025-05-12 19:28:01,683 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n",
      "2025-05-12 19:28:02,717 - PriorityDownloader - INFO - Added 1116 new rows for AMZZ (1m)\n",
      "2025-05-12 19:28:02,754 - PriorityDownloader - INFO - Added 1722 new rows for FLTR (1m)\n",
      "2025-05-12 19:28:02,803 - PriorityDownloader - INFO - Added 2328 new rows for BIZD (1m)\n",
      "2025-05-12 19:28:02,858 - PriorityDownloader - INFO - Added 2101 new rows for PTIR (1m)\n",
      "2025-05-12 19:28:02,912 - PriorityDownloader - INFO - Added 1890 new rows for DIVO (1m)\n",
      "2025-05-12 19:28:02,962 - PriorityDownloader - INFO - Added 1467 new rows for VSS (1m)\n",
      "2025-05-12 19:28:03,007 - PriorityDownloader - INFO - Added 1903 new rows for DFEM (1m)\n",
      "2025-05-12 19:28:03,125 - PriorityDownloader - INFO - Added 2226 new rows for EPI (1m)\n",
      "2025-05-12 19:28:03,200 - PriorityDownloader - INFO - Added 949 new rows for IOO (1m)\n",
      "2025-05-12 19:28:03,243 - PriorityDownloader - INFO - Added 2378 new rows for AVUV (1m)\n",
      "2025-05-12 19:28:03,307 - PriorityDownloader - INFO - Added 2238 new rows for VONG (1m)\n",
      "2025-05-12 19:28:03,366 - PriorityDownloader - INFO - Added 2468 new rows for VYM (1m)\n",
      "2025-05-12 19:28:03,428 - PriorityDownloader - INFO - Added 1952 new rows for FNDE (1m)\n",
      "2025-05-12 19:28:03,483 - PriorityDownloader - INFO - Added 2377 new rows for SPHQ (1m)\n",
      "2025-05-12 19:28:03,542 - PriorityDownloader - INFO - Added 1703 new rows for FLRN (1m)\n",
      "2025-05-12 19:28:06,571 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  14 of 14 completed\n",
      "2025-05-12 19:28:07,155 - StockDownloader - WARNING - No data found for  (interval 1m)\n",
      "2025-05-12 19:28:07,604 - PriorityDownloader - INFO - Added 535 new rows for HYEM (1m)\n",
      "2025-05-12 19:28:07,637 - PriorityDownloader - INFO - Added 2210 new rows for MDY (1m)\n",
      "2025-05-12 19:28:07,759 - PriorityDownloader - INFO - Added 1958 new rows for SIVR (1m)\n",
      "2025-05-12 19:28:07,811 - PriorityDownloader - INFO - Added 2018 new rows for USIG (1m)\n",
      "2025-05-12 19:28:07,859 - PriorityDownloader - INFO - Added 1109 new rows for DIVI (1m)\n",
      "2025-05-12 19:28:07,895 - PriorityDownloader - INFO - Added 1540 new rows for BUG (1m)\n",
      "2025-05-12 19:28:07,938 - PriorityDownloader - INFO - Added 2028 new rows for IWB (1m)\n",
      "2025-05-12 19:28:07,992 - PriorityDownloader - INFO - Added 1360 new rows for GSLC (1m)\n",
      "2025-05-12 19:28:08,035 - PriorityDownloader - INFO - Added 1493 new rows for UCON (1m)\n",
      "2025-05-12 19:28:08,078 - PriorityDownloader - INFO - Added 1189 new rows for CHAU (1m)\n",
      "2025-05-12 19:28:08,119 - PriorityDownloader - INFO - Added 1966 new rows for AVDV (1m)\n",
      "2025-05-12 19:28:08,170 - PriorityDownloader - INFO - Added 2020 new rows for BOTZ (1m)\n",
      "2025-05-12 19:28:08,223 - PriorityDownloader - INFO - Added 1981 new rows for FNDA (1m)\n",
      "2025-05-12 19:28:08,273 - PriorityDownloader - INFO - Added 1053 new rows for IBDQ (1m)\n",
      "2025-05-12 19:28:11,308 - StockDownloader - INFO - Downloading 15 tickers for interval 1m\n",
      "[*********************100%***********************]  15 of 15 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import concurrent.futures\n",
    "import requests\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Optional\n",
    "import io\n",
    "\n",
    "# Paramètres de téléchargement\n",
    "INTERVALS = ['15m', '1h','1d', '1m', '5m', '30m']\n",
    "# Paramètres système\n",
    "METADATA_FILE = 'tickers_metadata.json'\n",
    "DATA_DIR = 'datasets'  # Répertoire des données\n",
    "DATA_DIR_ENOUGH_DATA = 'datasets_enough_data'\n",
    "TECH_DATA_DIR = 'datasets_technicals' #Répertoire pour sauvegarder les fichiers avec Indicateurs techniques\n",
    "EDITED_DATA_DIR = 'datasets_edit'  # Répertoire pour sauvegarder les fichiers modifiés\n",
    "\n",
    "\n",
    "# Paramètres de priorisation\n",
    "UPDATE_THRESHOLDS = {\n",
    "    '1m': timedelta(minutes=15),\n",
    "    '5m': timedelta(minutes=30),\n",
    "    '15m': timedelta(hours=1),\n",
    "    '15m': timedelta(hours=1),\n",
    "    '30m': timedelta(hours=2),\n",
    "    '1h': timedelta(hours=4),\n",
    "    '1d': timedelta(days=1)\n",
    "}\n",
    "\n",
    "INTERVAL_PRIORITY = {\n",
    "    '1m': 6,    # Priorité la plus élevée\n",
    "    '5m': 5,\n",
    "    '15m': 4,\n",
    "    '30m': 3,\n",
    "    '1h': 2,\n",
    "    '1d': 1     # Priorité la plus basse\n",
    "}\n",
    "\n",
    "\n",
    "MAX_CONSECUTIVE_ERRORS = 5\n",
    "ERROR_COOLDOWN = timedelta(hours=2)\n",
    "MIN_NB_LINES = 200  # Minimum number of lines required\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:89.0) Gecko/20100101 Firefox/89.0\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0\",\n",
    "    \"Mozilla/5.0 (Linux; Android 10; SM-G970F) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Mobile Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36 Edg/109.0.1518.78\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.3 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 16_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.2 Mobile/15E148 Safari/604.1\",\n",
    "    \"Mozilla/5.0 (iPad; CPU OS 16_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/109.0.5414.83 Mobile/15E148 Safari/604.1\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/109.0\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/109.0\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36 OPR/95.0.0.0\",\n",
    "    \"Mozilla/5.0 (Linux; Android 13; SM-S908B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Mobile Safari/537.36\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "PARIS_TICKERS = [\n",
    "#CAC40\n",
    "    \"MC.PA\",\"OR.PA\",\"SU.PA\",\"AIR.PA\",\"TTE.PA\",\"SAN.PA\",\"CDI.PA\",\"EL.PA\",\"SAF.PA\",\"AI.PA\",\"BNP.PA\",\"CS.PA\",\"AXA SA\",\"DG.PA\",\"DSY.PA\",\"SGO.PA\",\"BN.PA\",\"ACA.PA\",\"ENGI.PA\",\"KER.PA\",\"HO.PA\",\"CAP.PA\",\"RI.PA\",\"LR.PA\",\"ORA.PA\",\"PUB.PA\",\"GLE.PA\",\n",
    "    \"ML.PA\",\"DIM.PA\",\"VIE.PA\",\"AM.PA\",\"BOL.PA\",\"RNO.PA\",\"BVI.PA\",\"AMUN.PA\",\"BIM.PA\",\"AC.PA\",\"EN.PA\",\"ENX.PA\",\"ADP.PA\",\"URW.PA\",\"SW.PA\",\"IPN.PA\",\"RNL.PA\",\"ERF.PA\",\"ALO.PA\",\"CA.PA\",\"FGR.PA\",\"LI.PA\",\"GET.PA\",\"EDEN.PA\",\"RXL.PA\",\"IAM.PA\",\"CBDG.PA\",\"GFC.PA\",\n",
    "    \"FDJ.PA\",\"ODET.PA\",\"COTY.PA\",\"AKE.PA\",\"AYV.PA\",\"RF.PA\",\"COV.PA\",\"GTT.PA\",\"SPIE.PA\",\"SPIE SA\",\"TEP.PA\",\"SK.PA\",\"SEB SA\",\"TE.PA\",\"ELIS.PA\",\"Elis SA\",\"SCR.PA\",\"VK.PA\",\"NEX.PA\",\"MF.PA\",\"MLHK.PA\",\"TKO.PA\",\"FLY.PA\",\"SOP.PA\",\n",
    "    \"DEC.PA\",\"PLX.PA\",\"ITP.PA\",\"VRLA.PA\",\"SOI.PA\",\"RCO.PA\",\"COVH.PA\",\"MMB.PA\",\"ATE.PA\",\"VU.PA\",\"FR.PA\",\"IDL.PA\",\"BB.PA\",\"RUI.PA\",\"VIRP.PA\",\"TRI.PA\",\"BAIN.PA\",\"VIV.PA\",\"COFA.PA\",\"CARM.PA\",\"LOUP.PA\",\"NK.PA\",\"WLN.PA\",\"ALTA.PA\",\"UNBL.PA\",\"IPS.PA\",\n",
    "    \"CAF.PA\",\"AF.PA\",\"PLNW.PA\",\"CBE.PA\",\"VCT.PA\",\"PEUG.PA\",\"RBT.PA\",\"EXN.PA\",\"STF.PA\",\"STEF SA\",\"ICAD.PA\",\"SESG.PA\",\"OPM.PA\",\"ERA.PA\",\"ARG.PA\",\"TFI.PA\",\"TF1 SA\",\"UBI.PA\",\"OVH.PA\",\"MMT.PA\",\"ES.PA\",\"BLV.PA\",\"MAU.PA\",\"GDS.PA\",\"FII.PA\",\"WAVE.PA\",\n",
    "    \"CRLA.PA\",\"NRO.PA\",\"LSS.PA\",\"MERY.PA\",\"ETL.PA\",\"ELEC.PA\",\"FREY.PA\",\"DBG.PA\",\"CNDF.PA\",\"LTA.PA\",\"CDA.PA\",\"FNAC.PA\",\"MTU.PA\",\"VETO.PA\",\"TKTT.PA\",\"VIL.PA\",\"BEN.PA\",\"EC.PA\",\"VAC.PA\",\"SAVE.PA\",\"BASS.PA\",\"NXI.PA\",\"XFAB.PA\",\"SDG.PA\",\n",
    "    \"THEP.PA\",\"CRAV.PA\",\"CRSU.PA\",\"CRAP.PA\",\"CEN.PA\",\"SCHP.PA\",\"TFF.PA\",\"KOF.PA\",\"QDT.PA\",\"LPE.PA\",\"SBT.PA\",\"EQS.PA\",\"BUR.PA\",\"AUB.PA\",\"GLO.PA\",\n",
    "]\n",
    "\n",
    "US_ETF = [\"SOXL\",\"SPXS\",\"FXI\",\"TSLL\",\"TSLZ\",\"SQQQ\",\"TQQQ\",\"SOXS\",\"ETHU\",\"NVDQ\",\"SPY\",\"KWEB\",\"IBIT\",\"MSTU\",\"XLF\",\"EEM\",\"TLT\",\"HYG\",\"UVXY\",\"EWZ\",\"TZA\",\"QQQ\",\"IWM\",\"SLV\",\"FAZ\",\"LQD\",\"NVDL\",\"LABD\",\"AMDL\",\"SDS\",\"MSTZ\",\"GDX\",\"NVDX\",\"SCHD\",\"VEA\",\"EFA\",\"TNA\",\"SPXU\",\n",
    "          \"YINN\",\"SCHF\",\"XBI\",\"KRE\",\"BITX\",\"XLE\",\"XLV\",\"BITO\",\"USHY\",\"IEMG\",\"SCHX\",\"XLI\",\"UVIX\",\"ARKK\",\"ASHR\",\"IEFA\",\"EMXC\",\"GLD\",\"RWM\",\"VOO\",\"VWO\",\"MCHI\",\"IJH\",\"ETHA\",\"NVDD\",\"XLP\",\"MSTX\",\"JAAA\",\"SCHG\",\"EWJ\",\"XLU\",\"SMH\",\"IAU\",\"TSLS\",\"SGOL\",\"QID\",\"QYLD\",\"XLB\",\n",
    "          \"XRT\",\"NVD\",\"SGOV\",\"RSP\",\"TMF\",\"KORU\",\"TSLQ\",\"BND\",\"BIL\",\"AGG\",\"BKLN\",\"SCHH\",\"SPLG\",\"UNG\",\"EMLC\",\"INDA\",\"FEZ\",\"CONY\",\"SCHB\",\"SPTI\",\"YANG\",\"VCIT\",\"FNGD\",\"GOVT\",\"IGV\",\"MSOS\",\"SPDN\",\"SRTY\",\"GDXJ\",\"SBIT\",\"IQLT\",\"VXX\",\"SHV\",\"PSQ\",\"EMB\",\"VXUS\",\"DRIP\",\"JEPQ\",\n",
    "          \"IYR\",\"VTEB\",\"SPIB\",\"IEF\",\"MSTY\",\"JPST\",\"UPRO\",\"FBTC\",\"XLK\",\"SPDW\",\"EWH\",\"JEPI\",\"ILF\",\"PGX\",\"CONL\",\"IJR\",\"IYZ\",\"SPHY\",\"CGGR\",\"GGLL\",\"EWY\",\"KOLD\",\"SCHP\",\"VTI\",\"CGDV\",\"SHY\",\"ITB\",\"SILJ\",\"IVV\",\"SPTL\",\"BITU\",\"SOXX\",\"SRLN\",\"SPXL\",\"SDOW\",\"XHB\",\"TIP\",\"EZA\",\n",
    "          \"ETHE\",\"XLC\",\"FBND\",\"VGIT\",\"USFR\",\"ULTY\",\"VCRB\",\"HEFA\",\"GBTC\",\"ARKG\",\"TSLY\",\"VGSH\",\"XLY\",\"SJNK\",\"ACWI\",\"ICLN\",\"VTV\",\"AMZU\",\"MAGS\",\"AGQ\",\"GLDM\",\"XOP\",\"JCPB\",\"VNQ\",\"SCHA\",\"PFF\",\"PAVE\",\"PDBC\",\"EFV\",\"QQQM\",\"BNDX\",\"DOG\",\"BOIL\",\"EWT\",\"IUSB\",\"EZU\",\"BITB\",\n",
    "          \"SPYV\",\"JNK\",\"SSO\",\"BSCT\",\"BABX\",\"DIA\",\"QLD\",\"IBB\",\"XME\",\"RSHO\",\"EWW\",\"SPSM\",\"SCHO\",\"EWC\",\"VEU\",\"CALF\",\"SCHM\",\"SPYG\",\"USO\",\"BITI\",\"TSLT\",\"VGK\",\"MUB\",\"SPMD\",\"COWZ\",\"ETH\",\"TMV\",\"COPX\",\"UDOW\",\"AMLP\",\"URA\",\"NVDY\",\"KBWB\",\"PULS\",\"EWA\",\"BSV\",\"IDEV\",\"EWG\",\n",
    "          \"CLOZ\",\"VMBS\",\"SPTS\",\"IXUS\",\"SVIX\",\"VIXY\",\"DFAC\",\"SDVY\",\"TFLO\",\"SCHZ\",\"MLPX\",\"SPEM\",\"SPSB\",\"LABU\",\"DYNF\",\"IGSB\",\"CGUS\",\"ETHT\",\"BLV\",\"BBJP\",\"UCO\",\"YMAX\",\"IAUM\",\"VCSH\",\"AAAU\",\"VGLT\",\"VTWO\",\"SPMO\",\"TSLR\",\"DGRO\",\"SPAB\",\"KBE\",\"AUSF\",\"PYLD\",\"VCLT\",\"NVDU\",\n",
    "          \"JETS\",\"IWD\",\"CWEB\",\"FNDF\",\"SCHR\",\"DXD\",\"FLOT\",\"IGIB\",\"BIV\",\"JBBB\",\"MOAT\",\"DFIC\",\"MBB\",\"URNM\",\"TBIL\",\"QEFA\",\"SCHE\",\"PVAL\",\"FGD\",\"IEUR\",\"XLG\",\"NUGT\",\"IVW\",\"BUFR\",\"DFSV\",\"OUNZ\",\"SCHI\",\"VFLO\",\"CQQQ\",\"DFAI\",\"FETH\",\"SPLV\",\"NVDS\",\"GRNY\",\"MSFU\",\"AAPU\",\"IEI\",\n",
    "          \"EEMA\",\"CIBR\",\"CGCP\",\"ITOT\",\"SHYG\",\"BSCR\",\"IWF\",\"TECL\",\"RDVY\",\"QGRW\",\"FPE\",\"PXH\",\"BAR\",\"TFI\",\"IWP\",\"BINC\",\"MTUM\",\"UUP\",\"ACWX\",\"PZA\",\"GDXD\",\"MINT\",\"AAPD\",\"YMAG\",\"SPLB\",\"IWR\",\"USMV\",\"TECS\",\"VUG\",\"ACES\",\"QUAL\",\"IGLB\",\"SVXY\",\"SCHV\",\"BTC\",\"IYT\",\"AMDY\",\"FAS\",\n",
    "          \"AVGX\",\"SPYD\",\"MRNY\",\"ARKB\",\"VIG\",\"ZSL\",\"URTY\",\"NAIL\",\"DFLV\",\"TCAF\",\"ITA\",\"KIE\",\"URNJ\",\"HYD\",\"TSDD\",\"SPYI\",\"VUSB\",\"VTIP\",\"FDVV\",\"HTRB\",\"SCO\",\"FTSM\",\"AMZZ\",\"FLTR\",\"BIZD\",\"PTIR\",\"DIVO\",\"COWG\",\"VSS\",\"FBL\",\"DFEM\",\"EPI\",\"IOO\",\"AVUV\",\"VONG\",\"VYM\",\"FNDE\",\"SPHQ\",\n",
    "          \"FLRN\",\"HYEM\",\"MDY\",\"SIVR\",\"USIG\",\"DUST\",\"DIVI\",\"BUG\",\"IWB\",\"GSLC\",\"UCON\",\"CHAU\",\"AVDV\",\"BOTZ\",\"JDST\",\"FNDA\",\"IBDQ\",\"GUNR\",\"PAAA\",\"AIQ\",\"VWOB\",\"SIL\",\"JNUG\",\"DBA\",\"SCZ\",\"DUHP\",\"SVOL\",\"AVEM\",\"CGMS\",\"DFSD\",\"HYLB\",\"TWM\",\"FENY\",\"DFCF\",\"GDXU\",\"XSMO\",\"AMZY\",\"REM\"\n",
    "          ,\"DRN\",\"SLYV\",\"IYW\",\"BSCP\",\"BSCQ\",\"AIYY\",\"CGBL\",\"DBEF\",\"FELC\",\"GLL\",\"EWU\",\"FNGU\",\"WEAT\",\"DFAE\",\"USD\",\"CGGO\",\"EDZ\",\"GBIL\",\"IUSV\",\"EFG\",\"BTCZ\",\"IBDV\",\"SPTM\",\"SPYU\",\"DPST\",\"OIH\",\"EDV\",\"AMZD\",\"DJAN\",\"FALN\",\"EUFN\",\"PFFD\",\"METU\",\"AIRR\",\"ETHD\",\"TLTW\",\"DFAU\",\n",
    "          \"CETH\",\"VFH\",\"FBCG\",\"IDV\",\"BSCS\",\"GSY\",\"ICSH\",\"ESGE\",\"JGRO\",\"DBC\",\"CTA\",\"FIAT\",\"SDIV\",\"AVL\",\"FHLC\",\"CGXU\",\"IBDU\",\"LVHI\",\"IBDS\",\"SCHK\",\"BUFD\",\"DFAX\",\"TLH\",\"JMST\",\"FJP\",\"IBDR\",\"DFIV\",\"DGRW\",\"FIXD\",\"RYLD\",\"QDTE\",\"EVTR\",\"FLCB\",\"BBIN\",\"JMEE\",\"WGMI\",\"SPGP\",\n",
    "          \"HYMB\",\"JPIE\",\"IWN\",]\n",
    "\n",
    "EU_ETF = [\"BX4.PA\",\"BXX.PA\",\"WPEA.PA\",\"DSD.PA\",\"AUEM.PA\",\"MSE.PA\",\"ESE.PA\",\"SHC.PA\",\"AEEM.PA\",\"MFEC.PA\",\"DFND-EUR.PA\",\"BNKE.PA\",\"LVC.PA\",\"500U.PA\",\"LCWD.PA\",\"PSP5.PA\",\"GRE.PA\",\"ESEH.PA\",\"CL2.PA\",\"ISRA.PA\",\"BNK.PA\",\"ETZ.PA\",\"PASI.PA\",\"SEME.PA\",\"ETZD.PA\",\n",
    "          \"CNY.PA\",\"PAASI.PA\",\"PSPH.PA\",\"ESD.PA\",\"ABDJI.PA\",\"ABNSP.PA\",\"AABCH.PA\",\"AATCX.PA\",\"AAHLT.PA\",\"ABSMI.PA\",\"CACC.PA\",\"PUST.PA\",\"AAFIN.PA\",\"AABFB.PA\",\"GEMU.PA\",\"AARTL.PA\",\"OBLI.PA\",\"8G19V.PA\",\"NB22V.PA\",\"NB28V.PA\",\"SPEEU.PA\",\"ERTH.PA\",\"AABEN.PA\",\n",
    "          \"ABDJE.PA\",\"ABHSN.PA\",\"AAUTL.PA\",\"AAINS.PA\",\"HSTE.PA\",\"SP5.PA\",\"AASTX.PA\",\"ABNSQ.PA\",\"BRES.PA\",\"PE500.PA\",\"HEMA.PA\",\"AABKX.PA\",\"PAEEM.PA\",\"EEE.PA\",\"AATLC.PA\",\"E40.PA\",\"MUSRI.PA\",\"ESDD.PA\",\"XQ48V.PA\",\"CAC.PA\",\"UST.PA\",\"EEMK.PA\",\"CEC.PA\",\n",
    "          \"EGRI.PA\",\"ETHC-EUR.PA\",\"0G28.IL\",\"0Y4H.IL\",\"0MPR.IL\",\"WDTE.L\",\"0MPY.IL\",\"TS3S.L\",\"0A09.L\",\"XT2D.L\",\"0DZF.IL\",\"CNYA.L\",\"SUOE.L\",\"FRXD.L\",\"WHCE.L\",\"XSD2.L\",\"0HOV.IL\",\"ISF.L\",\"JCAU.L\",\"N100.L\",\"0Y8R.IL\",\n",
    "          \"DTLA.L\",\"0MRJ.IL\",\"IBTA.L\",\"SUSW.L\",\"SPEH.L\",\"HIGG.L\",\"0XC5.IL\",\"HAGG.L\",\"UC76.L\",\"FBTC.L\",\"AGBP.L\",\"MIDD.L\",\"FUSR.L\",\"0DZB.L\",\"DTLE.L\",\"0MMG.IL\",\"IGLT.L\",\"0Y2B.L\",\"SDIA.L\",\"IEBB.IL\",\"0GBX.IL\",\"JCPN.L\",\n",
    "          \"IHYA.L\",\"EWSX.L\",\"0L4R.L\",\"HYLA.L\",\"IDTL.L\",\"EWSP.L\",\"IUIT.L\",\"WNDI.L\",\"0DYZ.IL\",\"0HEP.L\",\"PAWD.L\",\"HCGU.L\",\"0MP3.IL\",\"SNGB.L\",\"0WA3.IL\",\"MTHG.L\",\"FLOA.L\",\"EMAU.L\",\"LQDA.L\",\"HGAS.L\",\"IEAC.L\",\n",
    "          \"V3SU.L\",\"AREG.L\",\"0H9U.L\",\"NDIA.L\",\"FWRG.L\",\"IGTM.L\",\"TSLQ.L\",\"GDMS.L\",\"0WA5.IL\",\"UIFS.L\",\"XGSI.L\",\"0KZC.L\",\"BS0A.L\",\"XDNS.L\",\"I50D.L\",\"QQQ5.L\"]\n",
    "\n",
    "CURRENCY_AND_FUTURES = [\"ZN=F\",\"ZF=F\",\"ES=F\",\"ZT=F\",\"NQ=F\",\"ZB=F\",\"CL=F\",\"GC=F\",\"ZC=F\",\"RTY=F\",\"NG=F\",\"MGC=F\",\"YM=F\",\"ZS=F\",\"HG=F\",\"SI=F\",\"SB=F\",\"HO=F\",\"RB=F\",\"ZL=F\",\"KE=F\",\"ZM=F\",\"BZ=F\",\"CT=F\",\"KC=F\",\"PL=F\",\"LE=F\",\"SIL=F\",\n",
    "                        \"HE=F\",\"CC=F\",\"GF=F\",\"PA=F\",\"EURUSD=X\",\"JPY=X\",\"GBPUSD=X\",\"AUDUSD=X\",\"NZDUSD=X\",\"EURJPY=X\",\"GBPJPY=X\",\"EURGBP=X\",\"EURCAD=X\",\"EURSEK=X\",\"EURCHF=X\",\"EURHUF=X\",\"CNY=X\",\"HKD=X\",\n",
    "                        \"SGD=X\",\"INR=X\",\"MXN=X\",\"PHP=X\",\"IDR=X\",\"THB=X\",\"MYR=X\",\"ZAR=X\",\"RUB=X\"]\n",
    "\n",
    "US_TICKERS = [\n",
    "    #US main tickers\n",
    "'NVDA','AAPL','MSFT','AMZN','GOOGL','GOOG','META','TSLA','AVGO','BRK-B','ORCL','TCEHY','TCTZF','NFLX','COST','NONOF','LVMHF','LVMUY','JPM-PD','JPM-PC','BML-PG','SAPGF','BML-PH','BML-PL','BAC-PE','IDCBY','BAC-PK','SSNLF','ABBV','IDCBF','HESAY','ASMLF','ASML','GDVTZ',\n",
    "    'ACGBF','TMUS','BML-PJ','BAC-PB','RHHBF','CSCO','RHHVF','RHHBY','TOYOF','ACGBY','BABAF','AZNCF','BABA','NSRGY','NSRGF','ISRG','CICHY','RYDAF','BACHY','LRLCY','WFC-PY','NVSEF','BACHF','SHEL','CICHF','LRLCF','PCCYF','ADBE','QCOM','HBCYF','HSBC','CMWAY','PLTR','SIEGY',\n",
    "    'SMAWF','INTU','ANET','CBAUF','IDEXF','SBGSF','SPGI','IDEXY','SBGSY','MBFJF','DTEGF','AMAT','DTEGY','FMXUF','SCHW','CIHKY','MUFG','AMGN','UBER','CMCSA','UNLYF','SHOP','EADSF','EADSY','BHPLF','SNYNF','TTFNF','SNEJF','CHDRY','CILJF','SONY','CHDRF',\n",
    "    'WFC-PC','ALIZF','ALIZY','HTHIF','ESLOY','RTNTF','HTHIY','MPNGF','Meituan','ESLOF','CIHHF','XIACY','MPNGY','Meituan','PNGAY','XIACF','CIIHF','GILD','PIAIF','VRTX','BYDDF','BYDDY','SBUX','SAFRF','SAFRY','CFRUY','CUAEF','CFRHF','ABBNY','ABLZF','MRVL','KYCCF','RCRUY',\n",
    "    'UNCFF','UNCRY','CSUAY','SPOT','FRCOF','RCRRF','LRCX','KLAC','SMFNF','SNPMF','SFTBF','FRCOY','AIQUY','AIQUF','SFTBY','SMFG','RTPPF','BUDFF','USB-PH','IBKR','CRWD','DBSDY','RLXXF','EQIX','RELX','INTC','INFY','IVSXF','PYPL','EBBNF','DBSDF','PROSF','PROSY','GS-PA','IBDRY',\n",
    "    'IBDSF','CDNS','NPPXF','IVSBF','ZFSVF','MS-PA','ZURVY','WELL','BNPQF','BNPQY','SNPS','ATLCY','TOELF','BPAQF','AXAHF','AXAHY','CSLLY','MSTR','CMXHF','ATLKY','MS-PK','TOELY','GS-PD','MS-PI','PBR-A','NTTYY','MS-PF','IITSF','BTAFF','BCDRF','DELL','CTAS','ABNB','MS-PE','AAIGF',\n",
    "    'LNSTY','LDNXF','ISNPY','RACE','MDLZ','HNHPF','AAGIY','SCCO','DASH','CGXYY','PBCRF','USB-PP','COIN','NTDOF','SBKFF','FTNT','REGN','NTDOY','MURGY','MURGF','PBCRY','ESOCF','WEBNF','ENLAY','NABZY','BKFCF','PSTVY','GLAXF','BCMXY','TEAM','CHGCY','TKOMF','CHGCF','PSBKF','WDAY',\n",
    "    'ITOCF','RLLCF','MKGAF','NTES','MKKGY','SHECY','BBVXF','ITOCY','STOHF','RBSPF','TKOMY','DGEAF','EQNR','PPWLM','ADSK','BBVA','RYCEF'\n",
    "]\n",
    "\n",
    "# Liste noire de tickers problématiques à exclure\n",
    "BLACKLISTED_TICKERS = {\n",
    "    'AXA SA',  # Format incorrect, utiliser CS.PA à la place\n",
    "    # Vous pouvez ajouter d'autres tickers problématiques ici\n",
    "}\n",
    "\n",
    "\n",
    "# Liste de tickers (sans leverage)\n",
    "TICKERS =['^GSPC','^FCHI','MC.PA', 'OR.PA', 'SU.PA', 'AIR.PA', 'TTE.PA', 'SAN.PA', 'CDI.PA', 'EL.PA', 'SAF.PA', 'AI.PA', 'BNP.PA', 'CS.PA', 'DG.PA', 'DSY.PA', 'SGO.PA', 'BN.PA', 'ACA.PA', 'ENGI.PA', 'KER.PA', 'HO.PA', 'CAP.PA', 'RI.PA', 'LR.PA', 'ORA.PA', 'PUB.PA',\n",
    "          'GLE.PA', 'ML.PA', 'DIM.PA', 'VIE.PA', 'AM.PA', 'BOL.PA', 'RNO.PA', 'BVI.PA', 'AMUN.PA', 'BIM.PA', 'AC.PA', 'EN.PA', 'ENX.PA', 'ADP.PA', 'URW.PA', 'SW.PA', 'IPN.PA', 'RNL.PA', 'ERF.PA', 'ALO.PA', 'CA.PA', 'FGR.PA', 'LI.PA', 'GET.PA', 'EDEN.PA',\n",
    "          'RXL.PA', 'IAM.PA', 'CBDG.PA', 'GFC.PA', 'FDJ.PA', 'ODET.PA', 'COTY.PA', 'AKE.PA', 'AYV.PA', 'RF.PA', 'COV.PA', 'GTT.PA', 'SPIE.PA', 'TEP.PA', 'SK.PA', 'TE.PA', 'ELIS.PA', 'SCR.PA', 'VK.PA', 'NEX.PA', 'MF.PA', \n",
    "          'MLHK.PA', 'TKO.PA', 'FLY.PA', 'SOP.PA', 'DEC.PA', 'PLX.PA', 'ITP.PA', 'VRLA.PA', 'SOI.PA', 'RCO.PA', 'COVH.PA', 'MMB.PA', 'ATE.PA', 'VU.PA', 'FR.PA', 'IDL.PA', 'BB.PA', 'RUI.PA', 'VIRP.PA', 'TRI.PA', 'BAIN.PA', 'VIV.PA', 'COFA.PA', 'CARM.PA',\n",
    "          'LOUP.PA', 'NK.PA', 'WLN.PA', 'ALTA.PA', 'UNBL.PA', 'IPS.PA', 'CAF.PA', 'AF.PA', 'PLNW.PA', 'CBE.PA', 'VCT.PA', 'PEUG.PA', 'RBT.PA', 'EXN.PA', 'STF.PA', 'ICAD.PA', 'SESG.PA', 'OPM.PA', 'ERA.PA', 'ARG.PA', 'TFI.PA', 'UBI.PA', 'OVH.PA',\n",
    "          'MMT.PA', 'ES.PA', 'BLV.PA', 'MAU.PA', 'GDS.PA', 'FII.PA', 'WAVE.PA', 'CRLA.PA', 'NRO.PA', 'LSS.PA', 'MERY.PA', 'ETL.PA', 'ELEC.PA', 'FREY.PA', 'DBG.PA', 'CNDF.PA', 'LTA.PA', 'CDA.PA', 'FNAC.PA', 'MTU.PA', 'VETO.PA', 'TKTT.PA', 'VIL.PA', 'BEN.PA',\n",
    "          'EC.PA', 'VAC.PA', 'SAVE.PA', 'BASS.PA', 'NXI.PA', 'XFAB.PA', 'SDG.PA', 'THEP.PA', 'CRAV.PA', 'CRSU.PA', 'CRAP.PA', 'CEN.PA', 'SCHP.PA', 'TFF.PA', 'KOF.PA', 'QDT.PA', 'LPE.PA', 'SBT.PA', 'EQS.PA', 'BUR.PA', 'AUB.PA', 'GLO.PA', 'NVDA', 'AAPL', 'MSFT',\n",
    "          'AMZN', 'GOOGL', 'GOOG', 'META', 'TSLA', 'AVGO', 'BRK-B', 'ORCL', 'TCEHY', 'TCTZF', 'NFLX', 'COST', 'NONOF', 'LVMHF', 'LVMUY', 'JPM-PD', 'JPM-PC', 'BML-PG', 'SAPGF', 'BML-PH', 'BML-PL', 'BAC-PE', 'IDCBY', 'BAC-PK', 'SSNLF', 'ABBV', 'IDCBF', 'HESAY',\n",
    "          'ASMLF', 'ASML', 'GDVTZ', 'ACGBF', 'TMUS', 'BML-PJ', 'BAC-PB', 'RHHBF', 'CSCO', 'RHHVF', 'RHHBY', 'TOYOF', 'ACGBY', 'BABAF', 'AZNCF', 'BABA', 'NSRGY', 'NSRGF', 'ISRG', 'CICHY', 'RYDAF', 'BACHY', 'LRLCY', 'WFC-PY', 'NVSEF', 'BACHF', 'SHEL', 'CICHF',\n",
    "          'LRLCF', 'PCCYF', 'ADBE', 'QCOM', 'HBCYF', 'HSBC', 'CMWAY', 'PLTR', 'SIEGY', 'SMAWF', 'INTU', 'ANET', 'CBAUF', 'IDEXF', 'SBGSF', 'SPGI', 'IDEXY', 'SBGSY', 'MBFJF', 'DTEGF', 'AMAT', 'DTEGY', 'FMXUF', 'SCHW', 'CIHKY', 'MUFG', 'AMGN', 'UBER', 'CMCSA',\n",
    "          'UNLYF', 'SHOP', 'EADSF', 'EADSY', 'BHPLF', 'SNYNF', 'TTFNF', 'SNEJF', 'CHDRY', 'CILJF', 'SONY', 'CHDRF', 'WFC-PC', 'ALIZF', 'ALIZY', 'HTHIF', 'ESLOY', 'RTNTF', 'HTHIY', 'MPNGF', 'ESLOF', 'CIHHF', 'XIACY', 'MPNGY', 'PNGAY', 'XIACF', 'CIIHF', 'GILD',\n",
    "          'PIAIF', 'VRTX', 'BYDDF', 'BYDDY', 'SBUX', 'SAFRF', 'SAFRY', 'CFRUY', 'CUAEF', 'CFRHF', 'ABBNY', 'ABLZF', 'MRVL', 'KYCCF', 'RCRUY', 'UNCFF', 'UNCRY', 'CSUAY', 'SPOT', 'FRCOF', 'RCRRF', 'LRCX', 'KLAC', 'SMFNF', 'SNPMF', 'SFTBF', 'FRCOY', 'AIQUY',\n",
    "          'AIQUF', 'SFTBY', 'SMFG', 'RTPPF', 'BUDFF', 'USB-PH', 'IBKR', 'CRWD', 'DBSDY', 'RLXXF', 'EQIX', 'RELX', 'INTC', 'INFY', 'IVSXF', 'PYPL', 'EBBNF', 'DBSDF', 'PROSF', 'PROSY', 'GS-PA', 'IBDRY', 'IBDSF', 'CDNS', 'NPPXF', 'IVSBF', 'ZFSVF', 'MS-PA',\n",
    "          'ZURVY', 'WELL', 'BNPQF', 'BNPQY', 'SNPS', 'ATLCY', 'TOELF', 'BPAQF', 'AXAHF', 'AXAHY', 'CSLLY', 'MSTR', 'CMXHF', 'ATLKY', 'MS-PK', 'TOELY', 'GS-PD', 'MS-PI', 'PBR-A', 'NTTYY', 'MS-PF', 'IITSF', 'BTAFF', 'BCDRF', 'DELL', 'CTAS', 'ABNB', 'MS-PE',\n",
    "          'AAIGF', 'LNSTY', 'LDNXF', 'ISNPY', 'RACE', 'MDLZ', 'HNHPF', 'AAGIY', 'SCCO', 'DASH', 'CGXYY', 'PBCRF', 'USB-PP', 'COIN', 'NTDOF', 'SBKFF', 'FTNT', 'REGN', 'NTDOY', 'MURGY', 'MURGF', 'PBCRY', 'ESOCF', 'WEBNF', 'ENLAY', 'NABZY', 'BKFCF', 'PSTVY',\n",
    "          'GLAXF', 'BCMXY', 'TEAM', 'CHGCY', 'TKOMF', 'CHGCF', 'PSBKF', 'WDAY', 'ITOCF', 'RLLCF', 'MKGAF', 'NTES', 'MKKGY', 'SHECY', 'BBVXF', 'ITOCY', 'STOHF', 'RBSPF', 'TKOMY', 'DGEAF', 'EQNR', 'PPWLM', 'ADSK', 'BBVA', 'RYCEF', 'DBK.DE', 'EI.PA', 'ENEL.MI',\n",
    "          'FRE.DE', 'IBE.MC', 'INGA.AS', 'ISP.MI', 'EOAN.DE', 'G.MI', 'ALV.DE', 'BBVA.MC', 'BAYN.DE', 'ABI.BR', 'ENI.MI', 'BMW.DE', 'ASML.AS', 'DTE.DE', 'BAS.DE', 'EURUSD=X', 'MT.AS', 'RMS.PA', 'STLAP.PA', 'STMPA.PA', 'V', 'JPM', 'JNJ', 'WMT', 'PG', 'MA',\n",
    "          'DIS', 'HD', 'VZ', 'UNH', 'KO', 'PFE', 'XOM', 'MRK', 'NKE', 'ABT', 'PEP', 'CRM', 'TMO', 'MDT', 'LLY', 'MS', 'BA', 'STLA', 'NESN.SW', 'A', 'AAL', 'AAP', 'ACN', 'ADI', 'ADM', 'ADP', 'AEE', 'AEP', 'AES', 'AFL', 'AIG', 'AIV', 'AIZ', 'AJG', 'AKAM',\n",
    "          'ALB', 'ALGN', 'ALK', 'ALL', 'ALLE', 'AMD', 'AME', 'AMP', 'AMT', 'ANSS', 'AON', 'AOS', 'APA', 'APD', 'APH', 'APTV', 'ARE', 'ATO', 'AVB', 'AVY', 'AWK', 'AXP', 'AZO', 'BAC', 'BAX', 'BBY', 'BDX', 'BEN', 'BIIB', 'BK', 'BKNG', 'BKR', 'BLK', 'BMY', 'BR',\n",
    "          'BSX', 'BWA', 'BXP', 'C', 'CAG', 'CAH', 'CAT', 'CB', 'CBOE', 'CBRE', 'CCI', 'CCL', 'CE', 'CF', 'CFG', 'CHD', 'CHRW', 'CHTR', 'CI', 'CINF', 'CL', 'CLX', 'CMA', 'CME', 'CMG', 'CMI', 'CMS', 'CNC', 'CNP', 'COF', 'COO', 'COP', 'CPB', 'CPRT', 'CSX', 'CVS',\n",
    "          'CVX', 'D', 'DAL', 'DD', 'DE', 'DFS', 'DG', 'DGX', 'DHI', 'DHR', 'DLR', 'DLTR', 'DOV', 'DOW', 'DRI', 'DTE', 'DUK', 'DVA', 'DVN', 'DXC', 'EA', 'EBAY', 'ECL', 'ED', 'EFX', 'EIX', 'EL', 'EMN', 'EMR', 'EOG', 'EQR', 'ES', 'ESS', 'ETN', 'ETR', 'EVRG',\n",
    "          'EW', 'EXC', 'EXPD', 'EXPE', 'EXR', 'F', 'FANG', 'FAST', 'FCX', 'FDX', 'FE', 'FFIV', 'FIS', 'FITB', 'FLR', 'FLS', 'FMC', 'FOX', 'FOXA', 'FTV', 'GD', 'GE', 'GIS', 'GL', 'GLW', 'GM', 'GPC', 'GPN', 'GS', 'GWW', 'HAL', 'HAS', 'HBAN', 'HBI', 'HCA', 'HCP',\n",
    "          'HES', 'HIG', 'HII', 'HLT', 'HOG', 'HOLX', 'HON', 'HP', 'HPE', 'HPQ', 'HRB', 'HRL', 'HSIC', 'HST', 'HSY', 'HUM', 'IBM', 'ICE', 'IDXX', 'IEX', 'IFF', 'ILMN', 'INCY', 'INFO', 'IP', 'IPG', 'IPGP', 'IQV', 'IR', 'IRM', 'IT', 'ITW', 'IVZ', 'J', 'JBHT',\n",
    "          'JCI', 'JKHY', 'JNPR', 'JWN', 'K', 'KEY', 'KEYS', 'KHC', 'KIM', 'KMB', 'KMI', 'KMX', 'KR', 'KSS', 'L', 'LB', 'LDOS', 'LEG', 'LEN', 'LH', 'LHX', 'LIN', 'LKQ', 'LMT', 'LNC', 'LNT', 'LOW', 'LUV', 'LW', 'LYB', 'M', 'MAA', 'MAC', 'MAR', 'MAS', 'MCD',\n",
    "          'MCHP', 'MCK', 'MCO', 'MET', 'MGM', 'MHK', 'MKC', 'MKTX', 'MLM', 'MMC', 'MMM', 'MNST', 'MO', 'MOS', 'MPC', 'MSCI', 'MSI', 'MTB', 'MTD', 'MU', 'NAVI', 'NCLH', 'NDAQ', 'NEE', 'NEM', 'NI', 'NOC', 'NOV', 'NRG', 'NSC', 'NTAP', 'NTRS', 'NUE', 'NVR', 'NWL',\n",
    "          'NWS', 'NWSA', 'O', 'ODFL', 'OKE', 'OMC', 'ORLY', 'OXY', 'PAYC', 'PAYX', 'PCAR', 'PEG', 'PFG', 'PGR', 'PH', 'PHM', 'PLD', 'PM', 'PNC', 'PNR', 'PNW', 'PPG', 'PPL', 'PRGO', 'PRU', 'PSA', 'PSX', 'PVH', 'PWR', 'QRVO', 'RCL', 'REG', 'RF', 'RHI', 'RJF',\n",
    "          'RL', 'RMD', 'ROK', 'ROL', 'ROP', 'ROST', 'RSG', 'RTX', 'SBAC', 'SEE', 'SHW', 'SJM', 'SLB', 'SLG', 'SNA', 'SO', 'SPG', 'SRE', 'STE', 'STT', 'STX', 'STZ', 'SWK', 'SWKS', 'SYY', 'T', 'TAP', 'TDG', 'TEL', 'TER', 'TFC', 'TFX', 'TGT', 'TJX', 'TPR', 'TRMB', \n",
    "          'TROW', 'TRV', 'TSCO', 'TSN', 'TT', 'TTWO', 'TXN', 'TXT', 'TYL', 'UA', 'UAA', 'UAL', 'UDR', 'UHS', 'ULTA', 'UNM', 'UNP', 'UPS', 'URI', 'USB', 'VFC', 'VLO', 'VMC', 'VNO', 'VRSK', 'VRSN', 'VTR', 'WAB', 'WAT', 'WBA', 'WDC', 'WEC', 'WFC', 'WHR', 'WM', \n",
    "          'WMB', 'WRB', 'WU', 'WY', 'WYNN', 'XEL', 'XRAY', 'XRX', 'XYL', 'YUM', 'ZBH', 'ZBRA', 'ZION', 'ZTS', 'ADS.DE', 'CON.DE', 'DB1.DE', 'LHA.DE', 'LIN.DE', 'MUV2.DE', 'RWE.DE', 'SAP.DE', 'SIE.DE', 'VOW3.DE', 'ZAL.DE', 'AAL.L', 'ABF.L', 'ADM.L', 'AHT.L', \n",
    "          'AV.L', 'BA.L', 'BARC.L', 'BATS.L', 'BP.L', 'BTI', 'CNA.L', 'DGE.L', 'GSK.L', 'HSBA.L', 'IMB.L', 'ITV.L', 'LGEN.L', 'LLOY.L', 'RDSA.VI', 'PUM.DE', 'NOKIA.HE', '2388.HK', '1398.HK', '600519.SS', '601988.SS', '601288.SS', '601318.SS', '002475.SZ', 'BHP.AX', 'CBA.AX', 'TLS.AX', 'WBC.AX', 'CSL.AX', 'NAB.AX', 'ANZ.AX', 'RIO.AX', 'QBE.AX', 'WOW.AX', 'S32.AX', 'FMG.AX', 'MQG.AX', 'TD.TO', 'RY.TO', 'BNS.TO', 'ENB.TO', 'SU.TO', 'CNQ.TO', 'BMO.TO', 'SHOP.TO', 'SLF.TO', 'MFC.TO', 'PPL.TO',\n",
    "          'TRP.TO', 'TSM', 'SAP', 'VOW.DE', 'ZN=F', 'ZF=F', 'ES=F', 'ZT=F', 'NQ=F', 'ZB=F', 'CL=F', 'GC=F', 'ZC=F', 'RTY=F', 'NG=F', 'MGC=F', 'YM=F', 'ZS=F', 'HG=F', 'SI=F', 'SB=F', 'HO=F', 'RB=F', 'ZL=F', 'KE=F', 'ZM=F', 'BZ=F', 'CT=F', 'KC=F', 'PL=F', 'LE=F', \n",
    "          'SIL=F', 'HE=F', 'CC=F', 'GF=F', 'PA=F', 'EURUSD=X', 'JPY=X', 'GBPUSD=X', 'AUDUSD=X', 'NZDUSD=X', 'EURJPY=X', 'GBPJPY=X', 'EURGBP=X', 'EURCAD=X', 'EURSEK=X', 'EURCHF=X', 'EURHUF=X', 'CNY=X', 'HKD=X', 'SGD=X', 'INR=X', 'MXN=X', 'PHP=X', 'IDR=X', 'THB=X',\n",
    "          'MYR=X', 'ZAR=X', 'RUB=X', 'BX4.PA', 'BXX.PA', 'WPEA.PA', 'DSD.PA', 'AUEM.PA', 'MSE.PA', 'ESE.PA', 'SHC.PA', 'AEEM.PA', 'MFEC.PA', 'DFND-EUR.PA', 'BNKE.PA', 'LVC.PA', '500U.PA', 'LCWD.PA', 'PSP5.PA', 'GRE.PA', 'ESEH.PA', 'CL2.PA', 'ISRA.PA', 'BNK.PA', \n",
    "          'ETZ.PA', 'PASI.PA', 'SEME.PA', 'ETZD.PA', 'CNY.PA', 'PAASI.PA', 'PSPH.PA', 'ESD.PA', 'ABDJI.PA', 'ABNSP.PA', 'AABCH.PA', 'AATCX.PA', 'AAHLT.PA', 'ABSMI.PA', 'CACC.PA', 'PUST.PA', 'AAFIN.PA', 'AABFB.PA', 'GEMU.PA', 'AARTL.PA', 'OBLI.PA', '8G19V.PA', \n",
    "          'NB22V.PA', 'NB28V.PA', 'SPEEU.PA', 'ERTH.PA', 'AABEN.PA', 'ABDJE.PA', 'ABHSN.PA', 'AAUTL.PA', 'AAINS.PA', 'HSTE.PA', 'SP5.PA', 'AASTX.PA', 'ABNSQ.PA', 'BRES.PA', 'PE500.PA', 'HEMA.PA', 'AABKX.PA', 'PAEEM.PA', 'EEE.PA', 'AATLC.PA', 'E40.PA', 'MUSRI.PA',\n",
    "          'ESDD.PA', 'XQ48V.PA', 'CAC.PA', 'UST.PA', 'EEMK.PA', 'CEC.PA', 'EGRI.PA', 'ETHC-EUR.PA', '0G28.IL', '0Y4H.IL', '0MPR.IL', 'WDTE.L', '0MPY.IL', 'TS3S.L', '0A09.L', 'XT2D.L', '0DZF.IL', 'CNYA.L', 'SUOE.L', 'FRXD.L', 'WHCE.L', 'XSD2.L', '0HOV.IL', 'ISF.L',\n",
    "          'JCAU.L', 'N100.L', '0Y8R.IL', 'DTLA.L', '0MRJ.IL', 'IBTA.L', 'SUSW.L', 'SPEH.L', 'HIGG.L', '0XC5.IL', 'HAGG.L', 'UC76.L', 'FBTC.L', 'AGBP.L', 'MIDD.L', 'FUSR.L', '0DZB.L', 'DTLE.L', '0MMG.IL', 'IGLT.L', '0Y2B.L', 'SDIA.L', 'IEBB.IL', '0GBX.IL', 'JCPN.L',\n",
    "          'IHYA.L', 'EWSX.L', '0L4R.L', 'HYLA.L', 'IDTL.L', 'EWSP.L', 'IUIT.L', 'WNDI.L', '0DYZ.IL', '0HEP.L', 'PAWD.L', 'HCGU.L', '0MP3.IL', 'SNGB.L', '0WA3.IL', 'MTHG.L', 'FLOA.L', 'EMAU.L', 'LQDA.L', 'HGAS.L', 'IEAC.L', 'V3SU.L', 'AREG.L', '0H9U.L',\n",
    "          'NDIA.L', 'FWRG.L', 'IGTM.L', 'GDMS.L', '0WA5.IL', 'UIFS.L', 'XGSI.L', '0KZC.L', 'BS0A.L', 'XDNS.L', 'I50D.L',  'FXI', 'SPY', 'KWEB', 'IBIT', 'MSTU', 'XLF', 'EEM', 'TLT', 'HYG', 'EWZ',  'IWM', 'SLV', 'LQD', 'MSTZ', 'GDX',\n",
    "          'SCHD', 'VEA', 'EFA', 'SCHF', 'XBI', 'KRE', 'XLE', 'XLV', 'BITO', 'USHY', 'IEMG', 'SCHX', 'XLI', 'ARKK', 'ASHR', 'IEFA', 'EMXC', 'GLD', 'RWM', 'VOO', 'VWO', 'MCHI', 'IJH', 'ETHA', 'XLP', 'MSTX', 'JAAA', 'SCHG', 'EWJ', 'XLU', 'SMH', 'IAU',\n",
    "          'SGOL', 'QYLD', 'XLB', 'XRT', 'NVD', 'SGOV', 'RSP', 'KORU', 'BND', 'BIL', 'AGG', 'BKLN', 'SCHH', 'SPLG', 'UNG', 'EMLC', 'INDA', 'FEZ', 'CONY', 'SCHB', 'SPTI', 'VCIT', 'GOVT', 'IGV', 'MSOS', 'GDXJ', 'SBIT', 'IQLT', 'VXX', 'SHV', 'PSQ', 'EMB',\n",
    "          'VXUS', 'JEPQ', 'IYR', 'VTEB', 'SPIB', 'IEF', 'MSTY', 'JPST', 'FBTC', 'XLK', 'SPDW', 'EWH', 'JEPI', 'ILF', 'PGX', 'CONL', 'IJR', 'IYZ', 'SPHY', 'CGGR', 'GGLL', 'EWY', 'KOLD', 'SCHP', 'VTI', 'CGDV', 'SHY', 'ITB', 'SILJ', 'IVV', 'SPTL', \n",
    "          'SOXX', 'SRLN', 'XHB', 'TIP', 'EZA', 'ETHE', 'XLC', 'FBND', 'VGIT', 'USFR', 'VCRB', 'HEFA', 'GBTC', 'ARKG', 'VGSH', 'XLY', 'SJNK', 'ACWI', 'ICLN', 'VTV', 'AMZU', 'MAGS', 'GLDM', 'XOP', 'JCPB', 'VNQ', 'SCHA', 'PFF', 'PAVE', 'PDBC', 'EFV',  \n",
    "          'BNDX', 'DOG', 'EWT', 'IUSB', 'EZU', 'BITB', 'SPYV', 'JNK', 'BSCT', 'DIA', 'IBB', 'XME', 'RSHO', 'EWW', 'SPSM', 'SCHO', 'EWC', 'VEU', 'CALF', 'SCHM', 'SPYG', 'USO', 'TSLT', 'VGK', 'MUB', 'SPMD', 'COWZ', 'ETH', 'COPX', 'AMLP', 'URA', \n",
    "          'KBWB', 'PULS', 'EWA', 'BSV', 'IDEV', 'EWG', 'CLOZ', 'VMBS', 'SPTS', 'IXUS', 'SVIX', 'VIXY', 'DFAC', 'SDVY', 'TFLO', 'SCHZ', 'MLPX', 'SPEM', 'SPSB', 'LABU', 'DYNF', 'IGSB', 'CGUS', 'ETHT', 'BLV', 'BBJP', 'UCO', 'YMAX', 'IAUM', 'VCSH', 'AAAU', 'VGLT',\n",
    "          'VTWO', 'SPMO', 'TSLR', 'DGRO', 'SPAB', 'KBE', 'AUSF', 'PYLD', 'VCLT', 'NVDU', 'JETS', 'IWD', 'CWEB', 'FNDF', 'SCHR', 'FLOT', 'IGIB', 'BIV', 'JBBB', 'MOAT', 'DFIC', 'MBB', 'URNM', 'TBIL', 'QEFA', 'SCHE', 'PVAL', 'FGD', 'IEUR', 'XLG', 'IVW', 'BUFR',\n",
    "          'DFSV', 'OUNZ', 'SCHI', 'VFLO',  'DFAI', 'FETH', 'SPLV', 'NVDS', 'GRNY', 'MSFU', 'AAPU', 'IEI', 'EEMA', 'CIBR', 'CGCP', 'ITOT', 'SHYG', 'BSCR', 'IWF', 'RDVY', 'QGRW', 'FPE', 'PXH', 'BAR', 'TFI', 'IWP', 'BINC', 'MTUM', 'UUP', 'ACWX', 'PZA',\n",
    "          'MINT', 'AAPD', 'YMAG', 'SPLB', 'IWR', 'USMV', 'VUG', 'ACES', 'QUAL', 'IGLB', 'SVXY', 'SCHV', 'BTC', 'IYT', 'AMDY', 'AVGX', 'SPYD', 'MRNY', 'ARKB', 'VIG', 'DFLV', 'TCAF', 'ITA', 'KIE', 'URNJ', 'HYD', 'TSDD', 'SPYI', 'VUSB', 'VTIP', 'FDVV', 'HTRB', \n",
    "          'FTSM', 'AMZZ', 'FLTR', 'BIZD', 'PTIR', 'DIVO', 'COWG', 'VSS', 'FBL', 'DFEM', 'EPI', 'IOO', 'AVUV', 'VONG', 'VYM', 'FNDE', 'SPHQ', 'FLRN', 'HYEM', 'MDY', 'SIVR', 'USIG', 'DIVI', 'BUG', 'IWB', 'GSLC', 'UCON', 'CHAU', 'AVDV', 'BOTZ', '', 'FNDA',\n",
    "          'IBDQ', 'GUNR', 'PAAA', 'AIQ', 'VWOB', 'SIL', 'DBA', 'SCZ', 'DUHP', 'SVOL', 'AVEM', 'CGMS', 'DFSD', 'HYLB', 'FENY', 'DFCF', 'XSMO', 'AMZY', 'REM', 'SLYV', 'IYW', 'BSCP', 'BSCQ', 'AIYY', 'CGBL', 'DBEF', 'FELC', 'EWU', 'WEAT', 'DFAE', 'USD',\n",
    "          'CGGO', 'GBIL', 'IUSV', 'EFG', 'BTCZ', 'IBDV', 'SPTM', 'SPYU', 'DPST', 'OIH', 'AMZD', 'DJAN', 'FALN', 'EUFN', 'PFFD', 'METU', 'AIRR', 'ETHD', 'DFAU', 'CETH', 'VFH', 'FBCG', 'IDV', 'BSCS', 'GSY', 'ICSH', 'ESGE', 'JGRO', 'DBC', 'CTA', 'FIAT', 'SDIV',\n",
    "          'AVL', 'FHLC', 'CGXU', 'IBDU', 'LVHI', 'IBDS', 'SCHK', 'BUFD', 'DFAX', 'TLH', 'JMST', 'FJP', 'IBDR', 'DFIV', 'DGRW', 'FIXD', 'RYLD', 'QDTE', 'EVTR', 'FLCB', 'BBIN', 'JMEE', 'WGMI', 'SPGP', 'HYMB', 'JPIE', 'IWN','RR.L']\n",
    "\n",
    "\n",
    "\n",
    "# Ticker du taux sans risque (bons du Trésor à 13 semaines)\n",
    "RISK_FREE_TICKER = '^IRX'\n",
    "# Avant le download du risk free ticker\n",
    "riskfreerate = yf.download(RISK_FREE_TICKER, period='max', interval='1d')\n",
    "# Vérifier si le DataFrame n'est pas vide\n",
    "if riskfreerate.empty:\n",
    "    print(\"Aucune donnée récupérée pour le taux sans risque.\")\n",
    "else:\n",
    "    # Sélectionner uniquement les colonnes 'Date' et 'Close' et réinitialiser l'index\n",
    "    riskfreerate = riskfreerate[['Close']].reset_index()\n",
    "    # Renommer la colonne 'Date' si nécessaire et supprimer la ligne de titre incorrecte\n",
    "    riskfreerate.columns = ['Date', 'Close']  # Si le nom de la colonne Date ne correspond pas à votre besoin\n",
    "    # Sauvegarder dans un fichier CSV sans l'index\n",
    "    riskfreerate.to_csv('RISK_FREE_TICKER.csv', index=False)\n",
    "    print(f'Données sauvegardées dans RISK_FREE_TICKER.csv')\n",
    "riskfreerate\n",
    "\n",
    "\n",
    "\n",
    "# Configuration du logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"downloader.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(\"StockDownloader\")\n",
    "\n",
    "# Paramètres système\n",
    "METADATA_FILE = 'tickers_metadata.json'\n",
    "DATA_DIR = 'datasets'  # Répertoire des données\n",
    "DATA_DIR_ENOUGH_DATA = 'datasets_enough_data'\n",
    "TECH_DATA_DIR = 'datasets_technicals'  # Répertoire pour sauvegarder les fichiers avec Indicateurs techniques\n",
    "EDITED_DATA_DIR = 'datasets_edit'  # Répertoire pour sauvegarder les fichiers modifiés\n",
    "\n",
    "# Paramètres de priorisation\n",
    "UPDATE_THRESHOLDS = {\n",
    "    '1m': timedelta(minutes=15),\n",
    "    '5m': timedelta(minutes=30),\n",
    "    '15m': timedelta(hours=1),\n",
    "    '30m': timedelta(hours=2),\n",
    "    '1h': timedelta(hours=4),\n",
    "    '1d': timedelta(days=1)\n",
    "}\n",
    "MAX_CONSECUTIVE_ERRORS = 5\n",
    "ERROR_COOLDOWN = timedelta(hours=2)\n",
    "MIN_NB_LINES = 200  # Minimum number of lines required\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.6167.184 Safari/537.36 Edg/121.0.2277.128\",\n",
    "\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.3 Safari/605.1.15\",\n",
    "\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\",\n",
    "\"Mozilla/5.0 (iPhone; CPU iPhone OS 17_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4 Mobile/15E148 Safari/604.1\",\n",
    "\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0\",\n",
    "\"Mozilla/5.0 (Linux; Android 14; SM-S918B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Mobile Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:89.0) Gecko/20100101 Firefox/89.0\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0\",\n",
    "    \"Mozilla/5.0 (Linux; Android 10; SM-G970F) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Mobile Safari/537.36\"\n",
    "]\n",
    "\n",
    "\n",
    "class SmartRateLimiter:\n",
    "    \"\"\"Classe pour gérer intelligemment les délais entre les requêtes API.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_delay=1.0, max_delay=60.0, error_penalty=5.0):\n",
    "        self.base_delay = base_delay\n",
    "        self.max_delay = max_delay\n",
    "        self.error_penalty = error_penalty\n",
    "        self.last_request = 0\n",
    "        self.error_count = 0\n",
    "        self.logger = logging.getLogger(\"SmartRateLimiter\")\n",
    "        \n",
    "    def wait(self, error_occurred=False):\n",
    "        \"\"\"Attend un délai approprié avant la prochaine requête.\n",
    "        \n",
    "        Args:\n",
    "            error_occurred (bool): Indique si une erreur s'est produite lors de la dernière requête\n",
    "        \"\"\"\n",
    "        current_time = time.time()\n",
    "        elapsed = current_time - self.last_request\n",
    "        \n",
    "        # Calcul dynamique du délai\n",
    "        delay = self.base_delay * (1 + self.error_count * self.error_penalty)\n",
    "        delay = min(delay, self.max_delay)\n",
    "        \n",
    "        if error_occurred:\n",
    "            self.error_count += 1\n",
    "            delay = min(delay * 2, self.max_delay)  # Backoff plus agressif après erreur\n",
    "            self.logger.warning(f\"Error occurred, increasing delay to {delay:.2f}s\")\n",
    "        else:\n",
    "            self.error_count = max(0, self.error_count - 0.5)  # Réduction progressive\n",
    "            \n",
    "        remaining_delay = max(0, delay - elapsed)\n",
    "        if remaining_delay > 0:\n",
    "            if remaining_delay > 5:\n",
    "                self.logger.info(f\"Waiting {remaining_delay:.2f}s before next request\")\n",
    "            time.sleep(remaining_delay)\n",
    "            \n",
    "        self.last_request = time.time()\n",
    "\n",
    "\n",
    "class TickerMetadata:\n",
    "    \"\"\"Classe pour gérer les métadonnées des tickers avec fenêtre temporelle pour les erreurs.\"\"\"\n",
    "    \n",
    "    def __init__(self, error_window_days=30):\n",
    "        # Initialiser d'abord le logger\n",
    "        self.logger = logging.getLogger(\"TickerMetadata\")\n",
    "        # Puis charger les données\n",
    "        self.data = self._load_metadata()\n",
    "        self._save_counter = 0\n",
    "        self._save_threshold = 10  # Sauvegarder après 10 mises à jour\n",
    "        self.error_window_days = error_window_days  # Fenêtre temporelle en jours\n",
    "        \n",
    "        # Migrer les anciennes données vers le nouveau format si nécessaire\n",
    "        self._migrate_error_format()\n",
    "    \n",
    "    def _migrate_error_format(self):\n",
    "        \"\"\"Migre les anciennes données vers le nouveau format avec timestamps d'erreurs.\"\"\"\n",
    "        migration_needed = False\n",
    "        \n",
    "        for ticker, info in self.data.items():\n",
    "            # Vérifier si le format actuel contient déjà une liste d'erreurs datées\n",
    "            if 'error_timestamps' not in info:\n",
    "                # Migrer en créant une liste vide\n",
    "                info['error_timestamps'] = []\n",
    "                \n",
    "                # Si l'ancien compteur existe, l'utiliser pour initialiser\n",
    "                if 'error_count' in info:\n",
    "                    # Nous ne pouvons pas savoir quand les erreurs se sont produites,\n",
    "                    # mais nous préservons le compteur pour référence\n",
    "                    old_count = info['error_count']\n",
    "                    self.logger.info(f\"Migrating error count for {ticker}: {old_count} errors\")\n",
    "                \n",
    "                migration_needed = True\n",
    "        \n",
    "        if migration_needed:\n",
    "            self.logger.info(\"Migration completed: error counts now use timestamped format\")\n",
    "            self.save()\n",
    "    \n",
    "    def _load_metadata(self):\n",
    "        \"\"\"Charge les métadonnées depuis le fichier.\"\"\"\n",
    "        if os.path.exists(METADATA_FILE):\n",
    "            try:\n",
    "                with open(METADATA_FILE, 'r') as f:\n",
    "                    return json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                self.logger.error(f\"Error decoding {METADATA_FILE}, creating new metadata\")\n",
    "                return {}\n",
    "        return {}\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"Sauvegarde les métadonnées dans un fichier.\"\"\"\n",
    "        # Assurer que le répertoire parent existe\n",
    "        os.makedirs(os.path.dirname(os.path.abspath(METADATA_FILE)), exist_ok=True)\n",
    "        \n",
    "        with open(METADATA_FILE, 'w') as f:\n",
    "            json.dump(self.data, f, indent=2)\n",
    "    \n",
    "    def get_ticker_info(self, ticker: str) -> dict:\n",
    "        \"\"\"Récupère les informations d'un ticker.\n",
    "        \n",
    "        Args:\n",
    "            ticker (str): Le symbole du ticker\n",
    "            \n",
    "        Returns:\n",
    "            dict: Les informations du ticker\n",
    "        \"\"\"\n",
    "        if ticker not in self.data:\n",
    "            # Créer un nouvel enregistrement avec le nouveau format\n",
    "            return {\n",
    "                'last_updates': {},\n",
    "                'error_timestamps': [],  # Nouveau format: liste de timestamps d'erreurs\n",
    "                'consecutive_errors': 0,\n",
    "                'last_attempt': None\n",
    "            }\n",
    "        return self.data[ticker]\n",
    "    \n",
    "    def _clean_old_errors(self, info: dict) -> None:\n",
    "        \"\"\"Nettoie les erreurs plus anciennes que la fenêtre temporelle.\n",
    "        \n",
    "        Args:\n",
    "            info (dict): Les informations du ticker à nettoyer\n",
    "        \"\"\"\n",
    "        if 'error_timestamps' not in info:\n",
    "            return\n",
    "            \n",
    "        now = datetime.now()\n",
    "        cutoff = now - timedelta(days=self.error_window_days)\n",
    "        \n",
    "        # Filtrer pour ne garder que les erreurs récentes\n",
    "        recent_errors = [ts for ts in info['error_timestamps'] \n",
    "                         if datetime.fromisoformat(ts) >= cutoff]\n",
    "        \n",
    "        # Mettre à jour la liste\n",
    "        info['error_timestamps'] = recent_errors\n",
    "    \n",
    "    def get_error_count(self, ticker: str) -> int:\n",
    "        \"\"\"Retourne le nombre d'erreurs dans la fenêtre temporelle.\n",
    "        \n",
    "        Args:\n",
    "            ticker (str): Le symbole du ticker\n",
    "            \n",
    "        Returns:\n",
    "            int: Le nombre d'erreurs récentes\n",
    "        \"\"\"\n",
    "        info = self.get_ticker_info(ticker)\n",
    "        self._clean_old_errors(info)\n",
    "        \n",
    "        return len(info.get('error_timestamps', []))\n",
    "    \n",
    "    def update_success(self, ticker: str, interval: str):\n",
    "        \"\"\"Met à jour les métadonnées après un téléchargement réussi.\n",
    "        \n",
    "        Args:\n",
    "            ticker (str): Le symbole du ticker\n",
    "            interval (str): L'intervalle de temps\n",
    "        \"\"\"\n",
    "        now = datetime.now().isoformat()\n",
    "        info = self.get_ticker_info(ticker)\n",
    "        info['last_updates'][interval] = now\n",
    "        info['consecutive_errors'] = 0\n",
    "        self.data[ticker] = info\n",
    "        \n",
    "        # Sauvegarde progressive pour éviter de trop fréquentes écritures disque\n",
    "        self._save_counter += 1\n",
    "        if self._save_counter >= self._save_threshold:\n",
    "            self.save()\n",
    "            self._save_counter = 0\n",
    "    \n",
    "    def update_failure(self, ticker: str):\n",
    "        \"\"\"Met à jour les métadonnées après un échec de téléchargement.\n",
    "        \n",
    "        Args:\n",
    "            ticker (str): Le symbole du ticker\n",
    "        \"\"\"\n",
    "        now = datetime.now()\n",
    "        now_iso = now.isoformat()\n",
    "        \n",
    "        info = self.get_ticker_info(ticker)\n",
    "        \n",
    "        # Ajouter le timestamp de l'erreur actuelle\n",
    "        if 'error_timestamps' not in info:\n",
    "            info['error_timestamps'] = []\n",
    "        info['error_timestamps'].append(now_iso)\n",
    "        \n",
    "        # Nettoyer les anciennes erreurs\n",
    "        self._clean_old_errors(info)\n",
    "        \n",
    "        # Mettre à jour les autres attributs\n",
    "        info['consecutive_errors'] += 1\n",
    "        info['last_attempt'] = now_iso\n",
    "        self.data[ticker] = info\n",
    "        \n",
    "        # Toujours sauvegarder après un échec pour préserver l'information\n",
    "        self.save()\n",
    "\n",
    "\n",
    "class StockDownloader:\n",
    "    \"\"\"Classe pour télécharger les données d'actions.\"\"\"\n",
    "    \n",
    "    def __init__(self, metadata: TickerMetadata, batch_size=20):\n",
    "        self.metadata = metadata\n",
    "        self.batch_size = batch_size\n",
    "        self.rate_limiter = SmartRateLimiter()\n",
    "        self.logger = logging.getLogger(\"StockDownloader\")\n",
    "        self.session = self._create_optimized_session()\n",
    "        self.session.headers.update({'User-Agent': random.choice(USER_AGENTS)})\n",
    "        \n",
    "    def _create_optimized_session(self):\n",
    "        \"\"\"Crée une session HTTP avec une configuration optimisée du pool de connexions.\"\"\"\n",
    "        session = requests.Session()\n",
    "        # Configuration avancée du pool de connexions\n",
    "        adapter = requests.adapters.HTTPAdapter(\n",
    "            pool_connections=30,    # Augmentation du nombre de pools\n",
    "            pool_maxsize=30,       # Taille maximale du pool\n",
    "            pool_block=False,      # Ne pas bloquer quand le pool est plein\n",
    "            max_retries=3          # Nombre de tentatives de réessai\n",
    "        )\n",
    "        # Appliquer l'adaptateur à tous les préfixes HTTPS\n",
    "        session.mount('https://', adapter)\n",
    "        # Rotation des User-Agents\n",
    "        session.headers.update({'User-Agent': self._get_random_user_agent()})\n",
    "        return session\n",
    "\n",
    "        \n",
    "    def _get_random_user_agent(self):\n",
    "        \"\"\"Retourne un User-Agent aléatoire avec une meilleure rotation.\"\"\"\n",
    "        # Ajouter des variations aux User-Agents existants pour créer plus de diversité\n",
    "        user_agent = random.choice(USER_AGENTS)\n",
    "\n",
    "        # Ajouter des variations mineures pour éviter la détection de modèles\n",
    "        variations = [\n",
    "            f\"; rv:{random.randint(80, 100)}.0\",\n",
    "            f\"; Chrome/{random.randint(90, 110)}.0.{random.randint(1000, 9999)}.{random.randint(10, 200)}\",\n",
    "            \"\",  # Parfois ne pas ajouter de variation\n",
    "            f\"; AppleWebKit/537.{random.randint(30, 36)}\",\n",
    "        ]\n",
    "\n",
    "        if \"Chrome\" in user_agent and random.random() > 0.7:\n",
    "            return user_agent + random.choice(variations)\n",
    "\n",
    "        return user_agent\n",
    "\n",
    "    def download_batch(self, tickers: List[str], interval: str) -> Dict[str, pd.DataFrame]:\n",
    "        results = {}\n",
    "        error_occurred = False\n",
    "\n",
    "        if not tickers:\n",
    "            self.logger.warning(f\"Empty ticker list for interval {interval}\")\n",
    "            return results\n",
    "\n",
    "        try:\n",
    "            self.rate_limiter.wait(error_occurred)\n",
    "\n",
    "            # Utiliser la méthode améliorée de rotation des User-Agents\n",
    "            self.session.headers.update({'User-Agent': self._get_random_user_agent()})\n",
    "\n",
    "            # Ajuster la période en fonction de l'intervalle\n",
    "            if interval == '1m':\n",
    "                # Pour les données 1 minute, limiter à 7 jours pour rester sous les 8 jours max\n",
    "                period = '7d'\n",
    "            elif interval in ['5m', '15m', '30m']:\n",
    "                # Pour les autres intervalles courts, limiter à 60 jours maximum\n",
    "                period = '60d'\n",
    "            elif interval == '1h':\n",
    "                period = '730d'  # ~2 ans pour les données horaires\n",
    "            else:\n",
    "                period = 'max'  # Période maximale pour les données journalières\n",
    "\n",
    "            self.logger.info(f\"Downloading {len(tickers)} tickers for interval {interval}\")\n",
    "            data = yf.download(\n",
    "                tickers=\" \".join(tickers),\n",
    "                interval=interval,\n",
    "                period=period,  # Utiliser la période adaptée à l'intervalle\n",
    "                group_by='ticker',\n",
    "                #auto_adjust=True,\n",
    "                prepost=False,\n",
    "                threads=True,\n",
    "                timeout=15\n",
    "            )\n",
    "            \n",
    "            # Cas spécial: si un seul ticker est demandé, yfinance ne groupe pas par ticker\n",
    "            if len(tickers) == 1 and isinstance(data, pd.DataFrame):\n",
    "                ticker = tickers[0]\n",
    "                processed_data = self._process_data(data)\n",
    "                if not processed_data.empty:\n",
    "                    results[ticker] = processed_data\n",
    "                    self.metadata.update_success(ticker, interval)\n",
    "                else:\n",
    "                    self.logger.warning(f\"Empty data for {ticker} (interval {interval})\")\n",
    "                    self.metadata.update_failure(ticker)\n",
    "            else:\n",
    "                for ticker in tickers:\n",
    "                    if ticker in data:\n",
    "                        processed_data = self._process_data(data[ticker])\n",
    "                        if not processed_data.empty:\n",
    "                            results[ticker] = processed_data\n",
    "                            self.metadata.update_success(ticker, interval)\n",
    "                        else:\n",
    "                            self.logger.warning(f\"Empty data for {ticker} (interval {interval})\")\n",
    "                            self.metadata.update_failure(ticker)\n",
    "                    else:\n",
    "                        self.logger.warning(f\"No data found for {ticker} (interval {interval})\")\n",
    "                        self.metadata.update_failure(ticker)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            error_occurred = True\n",
    "            self.logger.error(f\"Batch error: {str(e)}\", exc_info=True)\n",
    "            for ticker in tickers:\n",
    "                self.metadata.update_failure(ticker)\n",
    "        finally:\n",
    "            self.rate_limiter.wait(error_occurred)\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def _process_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Nettoyage standard des données.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame brut\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame nettoyé\n",
    "        \"\"\"\n",
    "        # Vérifier si le DataFrame est None ou vide\n",
    "        if df is None or df.empty:\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        try:\n",
    "            # Suppression des lignes entièrement NA\n",
    "            df = df.dropna(how='all')\n",
    "            \n",
    "            # Conversion de l'index en datetime si nécessaire\n",
    "            if not isinstance(df.index, pd.DatetimeIndex):\n",
    "                df.index = pd.to_datetime(df.index)\n",
    "                \n",
    "            # Triage par index\n",
    "            df = df.sort_index()\n",
    "            \n",
    "            # Vérification des colonnes essentielles\n",
    "            required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "            missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "            \n",
    "            if missing_columns:\n",
    "                self.logger.warning(f\"Missing columns: {missing_columns}\")\n",
    "                return pd.DataFrame()\n",
    "                \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing data: {str(e)}\", exc_info=True)\n",
    "            return pd.DataFrame()\n",
    "\n",
    "\n",
    "class PriorityDownloader:\n",
    "    \"\"\"Classe pour télécharger les données selon la priorité.\"\"\"\n",
    "    \n",
    "    def __init__(self, batch_size=20):\n",
    "        self.metadata = TickerMetadata()\n",
    "        self.batch_size = batch_size\n",
    "        # Tailles de lots adaptées par intervalle\n",
    "        self.batch_sizes = {\n",
    "            '1m': 15,    # Plus petit lot pour les données à haute fréquence (plus de risque d'erreurs)\n",
    "            '5m': 15,\n",
    "            '15m': 20,\n",
    "            '30m': 20,\n",
    "            '1h': 30,\n",
    "            '1d': 30     # Plus grand lot pour les données journalières (moins de risque d'erreurs)\n",
    "        }\n",
    "        self.rate_limiter = SmartRateLimiter()\n",
    "        self.logger = logging.getLogger(\"PriorityDownloader\")\n",
    "        self.downloader = StockDownloader(self.metadata, batch_size)\n",
    "        self.mode_manager = DownloadModeManager()\n",
    "        self.parallel_success_rate = {}  # Taux de succès par intervalle\n",
    "        self.max_workers = {interval: 3 for interval in INTERVALS}  # Niveau de parallélisme par défaut\n",
    "        self.parallel_success_rate = {}\n",
    "        self.max_workers = {interval: 3 for interval in INTERVALS}\n",
    "        self.dashboard = DashboardGenerator(self.metadata)\n",
    "\n",
    "\n",
    "        # Assurez-vous que les répertoires principaux existent\n",
    "        for directory in [DATA_DIR, DATA_DIR_ENOUGH_DATA, TECH_DATA_DIR, EDITED_DATA_DIR]:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "\n",
    "    def download_with_interval_rotation(self, max_tickers=None, max_workers=1):\n",
    "        \"\"\"Télécharge les tickers en alternant l'intervalle à chaque téléchargement.\n",
    "        \n",
    "        Args:\n",
    "            max_tickers (int, optional): Nombre maximum de tickers à télécharger par intervalle\n",
    "            max_workers (int, optional): Nombre de téléchargements parallèles à effectuer\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Starting downloads with interval rotation for each ticker\")\n",
    "        \n",
    "        # Créer une queue combinée avec tous les intervalles\n",
    "        combined_queue = []\n",
    "        for interval in INTERVALS:\n",
    "            queue = self.get_download_queue(interval)\n",
    "            if max_tickers:\n",
    "                queue = queue[:max_tickers]\n",
    "            for ticker in queue:\n",
    "                score = self._get_priority_score(ticker, interval)\n",
    "                if score is not None:\n",
    "                    combined_queue.append((ticker, interval, score))\n",
    "        \n",
    "        # Trier la queue combinée par score (priorité)\n",
    "        combined_queue.sort(key=lambda x: -x[2])\n",
    "        \n",
    "        if not combined_queue:\n",
    "            self.logger.info(\"No tickers need updating for any interval\")\n",
    "            return\n",
    "        \n",
    "        self.logger.info(f\"Found {len(combined_queue)} tickers across all intervals that need updating\")\n",
    "        \n",
    "        # Créer des sous-queues par intervalle pour alterner\n",
    "        interval_queues = {interval: [] for interval in INTERVALS}\n",
    "        for ticker, interval, _ in combined_queue:\n",
    "            interval_queues[interval].append(ticker)\n",
    "        \n",
    "        # Créer une liste circulaire d'intervalles qui ont des tickers\n",
    "        active_intervals = [interval for interval in INTERVALS if interval_queues[interval]]\n",
    "        \n",
    "        # Télécharger les tickers en alternant les intervalles\n",
    "        current_index = 0\n",
    "        download_count = 0\n",
    "        \n",
    "        # Créer les répertoires nécessaires\n",
    "        for interval in INTERVALS:\n",
    "            interval_dir = os.path.join(DATA_DIR, interval)\n",
    "            os.makedirs(interval_dir, exist_ok=True)\n",
    "        \n",
    "        # Fonction de téléchargement pour un ticker unique\n",
    "        def download_single(ticker_info):\n",
    "            ticker, interval = ticker_info\n",
    "            try:\n",
    "                self.logger.info(f\"Downloading {ticker} - interval {interval}\")\n",
    "                \n",
    "                # Ajouter du jitter pour éviter les accès simultanés\n",
    "                jitter = random.uniform(0.1, 0.5)\n",
    "                time.sleep(jitter)\n",
    "                \n",
    "                df = self._download_ticker_directly(ticker, interval)\n",
    "                \n",
    "                if df is not None and not df.empty:\n",
    "                    self._save_data(ticker, interval, df)\n",
    "                    self.metadata.update_success(ticker, interval)\n",
    "                    self.logger.info(f\"Successfully downloaded {ticker} - {len(df)} rows\")\n",
    "                    return (ticker, interval, True)\n",
    "                else:\n",
    "                    self.metadata.update_failure(ticker)\n",
    "                    self.logger.warning(f\"Failed to download {ticker}\")\n",
    "                    return (ticker, interval, False)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error downloading {ticker}: {str(e)}\")\n",
    "                self.metadata.update_failure(ticker)\n",
    "                return (ticker, interval, False)\n",
    "        \n",
    "        # Traiter les tickers en alternant les intervalles\n",
    "        with tqdm(total=len(combined_queue), desc=\"Téléchargement rotatif\") as pbar:\n",
    "            while True:\n",
    "                # Vérifier si tous les intervalles sont vides\n",
    "                if not any(interval_queues[interval] for interval in active_intervals):\n",
    "                    break\n",
    "                \n",
    "                # Trouver le prochain intervalle actif\n",
    "                attempts = 0\n",
    "                while attempts < len(active_intervals):\n",
    "                    current_interval = active_intervals[current_index]\n",
    "                    current_index = (current_index + 1) % len(active_intervals)\n",
    "                    \n",
    "                    if interval_queues[current_interval]:\n",
    "                        break\n",
    "                        \n",
    "                    attempts += 1\n",
    "                \n",
    "                if not interval_queues[current_interval]:\n",
    "                    continue\n",
    "                \n",
    "                # Prendre le prochain lot de tickers pour cet intervalle\n",
    "                if max_workers > 1:\n",
    "                    # Mode parallèle\n",
    "                    batch_size = min(max_workers, len(interval_queues[current_interval]))\n",
    "                    batch = [(interval_queues[current_interval].pop(0), current_interval) for _ in range(batch_size)]\n",
    "                    \n",
    "                    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "                        futures = {executor.submit(download_single, ticker_info): ticker_info for ticker_info in batch}\n",
    "                        \n",
    "                        for future in concurrent.futures.as_completed(futures):\n",
    "                            try:\n",
    "                                result = future.result()\n",
    "                                if result:\n",
    "                                    pbar.update(1)\n",
    "                                    download_count += 1\n",
    "                            except Exception as e:\n",
    "                                ticker_info = futures[future]\n",
    "                                self.logger.error(f\"Worker for {ticker_info[0]} raised exception: {str(e)}\")\n",
    "                                self.metadata.update_failure(ticker_info[0])\n",
    "                                pbar.update(1)\n",
    "                    \n",
    "                else:\n",
    "                    # Mode séquentiel\n",
    "                    ticker = interval_queues[current_interval].pop(0)\n",
    "                    result = download_single((ticker, current_interval))\n",
    "                    if result:\n",
    "                        pbar.update(1)\n",
    "                        download_count += 1\n",
    "                \n",
    "                # Pause pour éviter les blocages\n",
    "                time.sleep(1 + random.uniform(0, 2))\n",
    "                \n",
    "        self.logger.info(f\"Rotation download completed: {download_count} tickers downloaded across {len(active_intervals)} intervals\")\n",
    "        \n",
    "    def _download_ticker_directly(self, ticker, interval):\n",
    "        \"\"\"Télécharge un seul ticker directement avec un user agent aléatoire.\"\"\"\n",
    "        try:\n",
    "            # Sélectionner un user agent aléatoire\n",
    "            headers = {'User-Agent': random.choice(USER_AGENTS)}\n",
    "            \n",
    "            # Ajuster la période en fonction de l'intervalle\n",
    "            if interval == '1m':\n",
    "                period = '7d'\n",
    "            elif interval in ['5m', '15m', '30m']:\n",
    "                period = '60d'\n",
    "            elif interval == '1h':\n",
    "                period = '730d'\n",
    "            else:\n",
    "                period = 'max'\n",
    "                \n",
    "            \n",
    "            df = yf.download(\n",
    "                ticker,\n",
    "                interval=interval,\n",
    "                period=period,\n",
    "                #auto_adjust=True,\n",
    "                progress=False\n",
    "            )\n",
    "            \n",
    "            if df is not None and not df.empty:\n",
    "                # Traitement standard des données\n",
    "                df = df.dropna(how='all')\n",
    "                if not isinstance(df.index, pd.DatetimeIndex):\n",
    "                    df.index = pd.to_datetime(df.index)\n",
    "                df = df.sort_index()\n",
    "                \n",
    "                # Vérifier les colonnes essentielles\n",
    "                required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "                missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "                \n",
    "                if missing_columns:\n",
    "                    self.logger.warning(f\"Missing columns for {ticker}: {missing_columns}\")\n",
    "                    return None\n",
    "                    \n",
    "                return df\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error downloading {ticker}: {str(e)}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    # Dans la classe PriorityDownloader, ajoutez:\n",
    "    def download_one_by_one(self, interval, queue=None, max_tickers=None):\n",
    "        \"\"\"Télécharge les tickers un par un.\"\"\"\n",
    "        if queue is None:\n",
    "            queue = self.get_download_queue(interval)\n",
    "            \n",
    "        if not queue:\n",
    "            self.logger.info(f\"No tickers to download for interval {interval}\")\n",
    "            return\n",
    "            \n",
    "        # Limiter le nombre de tickers si nécessaire\n",
    "        if max_tickers is not None:\n",
    "            queue = queue[:min(max_tickers, len(queue))]\n",
    "        # Si max_tickers est None, utiliser toute la queue\n",
    "        \n",
    "        self.logger.info(f\"Downloading {len(queue)} tickers individually for interval {interval}\")\n",
    "        \n",
    "        # Créer le répertoire si nécessaire\n",
    "        interval_dir = os.path.join(DATA_DIR, interval)\n",
    "        os.makedirs(interval_dir, exist_ok=True)\n",
    "        \n",
    "        # Télécharger chaque ticker individuellement\n",
    "        for i, ticker in enumerate(queue):\n",
    "            self.logger.info(f\"Downloading {ticker} ({i+1}/{len(queue)}) - interval {interval}\")\n",
    "            \n",
    "            df = self._download_ticker_directly(ticker, interval)\n",
    "            \n",
    "            if df is not None and not df.empty:\n",
    "                # Mettre à jour les métadonnées et sauvegarder\n",
    "                self._save_data(ticker, interval, df)\n",
    "                self.metadata.update_success(ticker, interval)\n",
    "                self.logger.info(f\"Successfully downloaded {ticker} - {len(df)} rows\")\n",
    "            else:\n",
    "                self.metadata.update_failure(ticker)\n",
    "                self.logger.warning(f\"Failed to download {ticker}\")\n",
    "                \n",
    "            # Délai aléatoire entre chaque téléchargement\n",
    "            delay = 3 + random.uniform(1, 5)\n",
    "            time.sleep(delay)\n",
    "            \n",
    "            # Pause plus longue tous les 100 tickers\n",
    "            if (i+1) % 100 == 0:\n",
    "                long_delay = 2 + random.uniform(0, 2)\n",
    "                self.logger.info(f\"Taking a longer break ({long_delay:.1f}s) after 10 tickers\")\n",
    "                time.sleep(long_delay)\n",
    "            \n",
    "    def download_one_by_one_parallel(self, interval, queue=None, max_tickers=None, max_workers=5):\n",
    "        \"\"\"Télécharge les tickers individuellement mais en parallèle.\"\"\"\n",
    "        if queue is None:\n",
    "            queue = self.get_download_queue(interval)\n",
    "            \n",
    "        if not queue:\n",
    "            self.logger.info(f\"No tickers to download for interval {interval}\")\n",
    "            return\n",
    "            \n",
    "        # Correction ici pour gérer le cas où max_tickers est None\n",
    "        if max_tickers is not None:\n",
    "            queue = queue[:min(max_tickers, len(queue))]\n",
    "        # Si max_tickers est None, on utilise la queue complète\n",
    "        \n",
    "        self.logger.info(f\"Downloading {len(queue)} tickers in parallel for interval {interval}\")\n",
    "        \n",
    "        # Créer le répertoire si nécessaire\n",
    "        interval_dir = os.path.join(DATA_DIR, interval)\n",
    "        os.makedirs(interval_dir, exist_ok=True)\n",
    "        \n",
    "        # Fonction de téléchargement pour un ticker unique\n",
    "        def download_single(ticker_info):\n",
    "            i, ticker = ticker_info\n",
    "            try:\n",
    "                self.logger.info(f\"Downloading {ticker} ({i+1}/{len(queue)}) - interval {interval}\")\n",
    "                \n",
    "                # Ajouter rotation d'user agent avant chaque téléchargement\n",
    "                random_user_agent = random.choice(USER_AGENTS)\n",
    "                \n",
    "                # Ajouter du jitter pour éviter les accès simultanés\n",
    "                jitter = random.uniform(0.1, 0.5)\n",
    "                time.sleep(jitter)\n",
    "                \n",
    "                df = self._download_ticker_directly(ticker, interval)\n",
    "                \n",
    "                if df is not None and not df.empty:\n",
    "                    self._save_data(ticker, interval, df)\n",
    "                    self.metadata.update_success(ticker, interval)\n",
    "                    self.logger.info(f\"Successfully downloaded {ticker} - {len(df)} rows\")\n",
    "                    return (ticker, True)\n",
    "                else:\n",
    "                    self.metadata.update_failure(ticker)\n",
    "                    self.logger.warning(f\"Failed to download {ticker}\")\n",
    "                    return (ticker, False)\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error downloading {ticker}: {str(e)}\")\n",
    "                self.metadata.update_failure(ticker)\n",
    "                return (ticker, False)\n",
    "        \n",
    "        # Traiter les tickers par petits groupes de workers\n",
    "        results = []\n",
    "        for batch_start in range(0, len(queue), max_workers*2):\n",
    "            batch_end = min(batch_start + max_workers*2, len(queue))\n",
    "            current_batch = queue[batch_start:batch_end]\n",
    "            \n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "                # Soumettre les téléchargements en parallèle\n",
    "                futures = {executor.submit(download_single, (i+batch_start, ticker)): ticker \n",
    "                          for i, ticker in enumerate(current_batch)}\n",
    "                \n",
    "                # Collecter les résultats\n",
    "                for future in concurrent.futures.as_completed(futures):\n",
    "                    ticker = futures[future]\n",
    "                    try:\n",
    "                        result = future.result()\n",
    "                        results.append(result)\n",
    "                    except Exception as e:\n",
    "                        self.logger.error(f\"Worker for {ticker} raised exception: {str(e)}\")\n",
    "                        self.metadata.update_failure(ticker)\n",
    "            \n",
    "            # Pause entre les lots pour éviter de surcharger l'API\n",
    "            if batch_end < len(queue):\n",
    "                pause_time = 1 + random.uniform(0, 3)\n",
    "                self.logger.info(f\"Batch {batch_start//max_workers}-{batch_end//max_workers} complete. Pausing for {pause_time:.1f}s\")\n",
    "                time.sleep(pause_time)\n",
    "        \n",
    "        # Résumé des résultats\n",
    "        success_count = sum(1 for _, success in results if success)\n",
    "        self.logger.info(f\"Parallel download complete: {success_count}/{len(queue)} successful\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    def download_for_interval(self, interval, max_tickers=None):\n",
    "        \"\"\"Télécharge les données pour un intervalle en utilisant le mode approprié.\"\"\"\n",
    "        queue = self.get_download_queue(interval)\n",
    "        \n",
    "        if not queue:\n",
    "            self.logger.info(f\"No tickers to download for interval {interval}\")\n",
    "            return\n",
    "            \n",
    "        if max_tickers:\n",
    "            queue = queue[:max_tickers]\n",
    "            \n",
    "        self.logger.info(f\"Found {len(queue)} tickers that need updating for interval {interval}\")\n",
    "        \n",
    "        # Utiliser le mode sauvegardé ou le mode par défaut\n",
    "        mode = self.mode_manager.get_mode(interval)\n",
    "        self.logger.info(f\"Using {mode} mode for interval {interval}\")\n",
    "        \n",
    "        # Mettre à jour le mode dans le tableau de bord\n",
    "        self.dashboard.update_mode(interval, mode)\n",
    "        # Mettre à jour les téléchargements planifiés\n",
    "        self.dashboard.set_planned_downloads(interval, queue)\n",
    "        # Générer le tableau de bord\n",
    "        self.dashboard.generate_dashboard()\n",
    "        \n",
    "        try:\n",
    "            if mode == \"batch\":\n",
    "                # Essayer d'abord le mode batch\n",
    "                success = self._try_batch_download(queue, interval)\n",
    "                \n",
    "                if not success:\n",
    "                    # Si échec, basculer en mode individuel parallèle\n",
    "                    self.logger.warning(f\"Batch mode failed for {interval}, switching to parallel individual mode\")\n",
    "                    self.mode_manager.set_mode(interval, \"individual\")\n",
    "                    \n",
    "                    # Déterminer le niveau de parallélisme\n",
    "                    workers = self.max_workers.get(interval, 3)\n",
    "                    results = self.download_one_by_one_parallel(interval, queue=queue, max_workers=workers)\n",
    "                    \n",
    "                    # Ajuster le parallélisme pour la prochaine fois\n",
    "                    if results:\n",
    "                        success_rate = sum(1 for _, success in results if success) / len(results)\n",
    "                        self._adjust_parallelism(interval, success_rate)\n",
    "            else:\n",
    "                # Mode individuel direct mais parallèle\n",
    "                workers = self.max_workers.get(interval, 3)\n",
    "                results = self.download_one_by_one_parallel(interval, queue=queue, max_workers=workers)\n",
    "                \n",
    "                # Ajuster le parallélisme pour la prochaine fois\n",
    "                if results:\n",
    "                    success_rate = sum(1 for _, success in results if success) / len(results)\n",
    "                    self._adjust_parallelism(interval, success_rate)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error during download for {interval}: {str(e)}\", exc_info=True)\n",
    "            # En cas d'erreur, revenir au mode individuel séquentiel comme fallback ultime\n",
    "            self.logger.warning(f\"Error in parallel mode for {interval}, falling back to sequential mode\")\n",
    "            try:\n",
    "                self.download_one_by_one(interval, queue=queue)\n",
    "            except Exception as ex:\n",
    "                self.logger.error(f\"Sequential mode also failed: {str(ex)}\", exc_info=True)\n",
    "\n",
    "    def _adjust_parallelism(self, interval, success_rate):\n",
    "        \"\"\"Ajuste le niveau de parallélisme basé sur le taux de succès.\"\"\"\n",
    "        current_workers = self.max_workers.get(interval, 3)\n",
    "        \n",
    "        if success_rate > 0.95:  # Excellent taux de succès\n",
    "            new_workers = min(current_workers + 1, 10)  # Max 10 workers\n",
    "        elif success_rate > 0.80:  # Bon taux de succès\n",
    "            new_workers = current_workers  # Maintenir le niveau actuel\n",
    "        else:  # Taux d'échec élevé\n",
    "            new_workers = max(3, current_workers - 1)  # Réduire, mais au moins 2\n",
    "        \n",
    "        if new_workers != current_workers:\n",
    "            self.logger.info(f\"Adjusting parallelism for {interval}: {current_workers} --> {new_workers} workers (success rate: {success_rate:.2f})\")\n",
    "            self.max_workers[interval] = new_workers\n",
    "        \n",
    "        return new_workers\n",
    "    \n",
    "    def _try_batch_download(self, queue, interval):\n",
    "        \"\"\"Essaie de télécharger en mode batch et détecte les erreurs de limite de taux.\"\"\"\n",
    "        try:\n",
    "            batch_size = self.batch_sizes.get(interval, self.batch_size)\n",
    "            \n",
    "            # Pour la détection de limitations de taux\n",
    "            rate_limit_detected = False\n",
    "            \n",
    "            # Télécharger les premiers tickers pour voir si le mode batch fonctionne\n",
    "            test_batch = queue[:min(batch_size, len(queue))]\n",
    "            self.logger.info(f\"Testing batch mode with {len(test_batch)} tickers for {interval}\")\n",
    "            \n",
    "            # Capturer la sortie de log pour détecter les erreurs\n",
    "            log_capture = io.StringIO()\n",
    "            log_handler = logging.StreamHandler(log_capture)\n",
    "            yf_logger = logging.getLogger(\"yfinance\")\n",
    "            yf_logger.addHandler(log_handler)\n",
    "            \n",
    "            # Essayer de télécharger le lot test\n",
    "            results = self.downloader.download_batch(test_batch, interval)\n",
    "            \n",
    "            # Vérifier si des erreurs de limite de taux ont été détectées\n",
    "            log_output = log_capture.getvalue()\n",
    "            rate_limit_detected = \"YFRateLimitError\" in log_output or \"Too Many Requests\" in log_output\n",
    "            \n",
    "            # Nettoyer le handler temporaire\n",
    "            yf_logger.removeHandler(log_handler)\n",
    "            \n",
    "            if rate_limit_detected:\n",
    "                self.logger.warning(f\"Rate limit detected in batch mode for {interval}\")\n",
    "                return False\n",
    "                \n",
    "            # Si le test a réussi, continuer avec le reste de la file\n",
    "            if len(results) > 0:\n",
    "                self.logger.info(f\"Batch mode test successful for {interval}, continuing with remaining tickers\")\n",
    "                \n",
    "                # Sauvegarder les résultats du test\n",
    "                for ticker, df in results.items():\n",
    "                    self._save_data(ticker, interval, df)\n",
    "                    \n",
    "                # Traiter le reste de la file par lots\n",
    "                remaining_queue = queue[len(test_batch):]\n",
    "                \n",
    "                for i in range(0, len(remaining_queue), batch_size):\n",
    "                    batch = remaining_queue[i:i+batch_size]\n",
    "                    self.logger.info(f\"Processing batch {i//batch_size + 1} of {(len(remaining_queue)+batch_size-1)//batch_size}\")\n",
    "                    \n",
    "                    try:\n",
    "                        results = self.downloader.download_batch(batch, interval)\n",
    "                        \n",
    "                        # Vérifier si des erreurs de limite de taux ont été détectées\n",
    "                        log_output = log_capture.getvalue()\n",
    "                        if \"YFRateLimitError\" in log_output or \"Too Many Requests\" in log_output:\n",
    "                            self.logger.warning(f\"Rate limit detected in batch {i//batch_size + 1} for {interval}\")\n",
    "                            # Traiter les tickers restants en mode individuel\n",
    "                            remaining_tickers = queue[i+len(results):]\n",
    "                            self.download_one_by_one(interval, queue=remaining_tickers)\n",
    "                            return True\n",
    "                            \n",
    "                        # Sauvegarder les résultats\n",
    "                        for ticker, df in results.items():\n",
    "                            self._save_data(ticker, interval, df)\n",
    "                            \n",
    "                        # Pause entre les lots\n",
    "                        time.sleep(3 + random.uniform(1, 5))\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        self.logger.error(f\"Error in batch {i//batch_size + 1}: {str(e)}\")\n",
    "                        # Traiter les tickers restants en mode individuel\n",
    "                        remaining_tickers = queue[i:]\n",
    "                        self.download_one_by_one(interval, queue=remaining_tickers)\n",
    "                        return True\n",
    "                        \n",
    "                return True\n",
    "            else:\n",
    "                self.logger.warning(f\"Batch mode test failed for {interval}: no results returned\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in batch mode for {interval}: {str(e)}\", exc_info=True)\n",
    "            return False\n",
    "            \n",
    "    def run_cross_interval(self, max_batches_per_run=50):\n",
    "        \"\"\"Exécute les téléchargements en alternant entre les différents intervalles.\n",
    "\n",
    "        Cette méthode garantit que tous les intervalles reçoivent une attention équitable\n",
    "        en alternant entre eux à chaque lot de téléchargement.\n",
    "\n",
    "        Args:\n",
    "            max_batches_per_run (int): Nombre maximum de lots à télécharger au total\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Starting cross-interval download mode\")\n",
    "\n",
    "        # Collecter les queues pour tous les intervalles\n",
    "        interval_queues = {}\n",
    "        for interval in INTERVALS:\n",
    "            queue = self.get_download_queue(interval)\n",
    "            if queue:\n",
    "                interval_queues[interval] = queue\n",
    "                self.logger.info(f\"Found {len(queue)} tickers to update for interval {interval}\")\n",
    "\n",
    "        if not interval_queues:\n",
    "            self.logger.info(\"No tickers need updating for any interval\")\n",
    "            return\n",
    "\n",
    "        # Initialiser les compteurs et les indices pour suivre la progression\n",
    "        queue_positions = {interval: 0 for interval in interval_queues.keys()}\n",
    "        batch_count = 0\n",
    "\n",
    "        try:\n",
    "            # Continuer jusqu'à ce que tous les tickers soient traités ou que le maximum soit atteint\n",
    "            while interval_queues and (max_batches_per_run is None or batch_count < max_batches_per_run):\n",
    "                # Alterner entre les intervalles\n",
    "                for interval in list(interval_queues.keys()):\n",
    "                    queue = interval_queues[interval]\n",
    "                    pos = queue_positions[interval]\n",
    "\n",
    "                    # Déterminer la taille du lot pour cet intervalle\n",
    "                    batch_size = self.batch_sizes.get(interval, self.batch_size)\n",
    "\n",
    "                    # Extraire le prochain lot\n",
    "                    if pos + batch_size <= len(queue):\n",
    "                        batch = queue[pos:pos+batch_size]\n",
    "                        queue_positions[interval] += batch_size\n",
    "                    else:\n",
    "                        batch = queue[pos:]\n",
    "                        # Si nous avons traité tous les tickers pour cet intervalle, le retirer\n",
    "                        del interval_queues[interval]\n",
    "                        continue\n",
    "                    # Télécharger et traiter le lot\n",
    "                    self.logger.info(f\"Processing batch #{batch_count+1} for interval {interval}: {len(batch)} tickers\")\n",
    "                    self.downloader.batch_size = batch_size\n",
    "                    # À l'intérieur de la boucle, avant l'appel à download_batch\n",
    "                    self.downloader.session.headers.update({'User-Agent': random.choice(USER_AGENTS)})\n",
    "                    results = self.downloader.download_batch(batch, interval)\n",
    "\n",
    "                    # Sauvegarder les résultats\n",
    "                    for ticker, df in results.items():\n",
    "                        self._save_data(ticker, interval, df)\n",
    "\n",
    "                    batch_count += 1\n",
    "\n",
    "                    # Pause entre les lots pour éviter les blocages\n",
    "                    time.sleep(3)\n",
    "\n",
    "                    # Sortir si nous avons atteint le maximum\n",
    "                    if batch_count >= max_batches_per_run:\n",
    "                        break\n",
    "\n",
    "                # Si nous avons encore des intervalles à traiter mais que leurs positions sont au-delà\n",
    "                # de leurs tailles de queue respectives, nous avons terminé\n",
    "                should_break = True\n",
    "                for interval, pos in queue_positions.items():\n",
    "                    if interval in interval_queues and pos < len(interval_queues[interval]):\n",
    "                        should_break = False\n",
    "                        break\n",
    "                if should_break:\n",
    "                    break\n",
    "                if max_batches_per_run is not None and batch_count >= max_batches_per_run:\n",
    "                    break\n",
    "\n",
    "        finally:\n",
    "            # Nettoyage\n",
    "            self.clean_old_failures()\n",
    "\n",
    "            # Assurer que toutes les métadonnées sont sauvegardées\n",
    "            if self.metadata._save_counter > 0:\n",
    "                self.metadata.save()\n",
    "\n",
    "            self.logger.info(f\"Cross-interval download completed: processed {batch_count} batches across {len(INTERVALS)} intervals\")\n",
    "\n",
    "            \n",
    "            \n",
    "    def get_rotated_intervals(self):\n",
    "        \"\"\"Retourne une liste d'intervalles en rotation basée sur la date.\n",
    "\n",
    "        Cela garantit que l'ordre des intervalles change régulièrement pour\n",
    "        donner une chance égale à tous les intervalles d'être traités en premier.\n",
    "        \"\"\"\n",
    "        # Utiliser le jour de l'année pour déterminer la rotation\n",
    "        day_of_year = datetime.now().timetuple().tm_yday\n",
    "        intervals = INTERVALS.copy()\n",
    "\n",
    "        # Rotation basée sur le jour\n",
    "        rotation = day_of_year % len(intervals)\n",
    "        return intervals[rotation:] + intervals[:rotation]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def clean_old_failures(self):\n",
    "        \"\"\"Nettoie les tickers avec trop d'erreurs persistantes.\"\"\"\n",
    "        count = 0\n",
    "        for ticker in list(self.metadata.data.keys()):\n",
    "            info = self.metadata.get_ticker_info(ticker)\n",
    "            if info['consecutive_errors'] > MAX_CONSECUTIVE_ERRORS * 2:\n",
    "                del self.metadata.data[ticker]\n",
    "                count += 1\n",
    "\n",
    "        if count > 0:\n",
    "            self.logger.info(f\"Cleaned {count} tickers with persistent errors\")\n",
    "            self.metadata.save()\n",
    "\n",
    "        \n",
    "    def _get_priority_score(self, ticker: str, interval: str) -> Optional[float]:\n",
    "        \"\"\"Calcule un score de priorité pour un ticker et un intervalle.\n",
    "    \n",
    "        Args:\n",
    "            ticker (str): Le symbole du ticker\n",
    "            interval (str): L'intervalle de temps\n",
    "    \n",
    "        Returns:\n",
    "            Optional[float]: Score de priorité, ou None si le ticker ne doit pas être téléchargé\n",
    "        \"\"\"\n",
    "        info = self.metadata.get_ticker_info(ticker)\n",
    "    \n",
    "        # Vérifier le cooldown après erreur\n",
    "        if info['consecutive_errors'] >= MAX_CONSECUTIVE_ERRORS:\n",
    "            last_attempt = datetime.fromisoformat(info['last_attempt']) if info['last_attempt'] else None\n",
    "            if last_attempt and (datetime.now() - last_attempt) < ERROR_COOLDOWN:\n",
    "                return None\n",
    "    \n",
    "        # Obtenir le bonus de priorité basé sur l'intervalle\n",
    "        interval_bonus = INTERVAL_PRIORITY.get(interval, 0) * 10  # Multiplier par 10 pour donner un poids significatif\n",
    "    \n",
    "        # Calculer l'ancienneté des données\n",
    "        last_update_str = info['last_updates'].get(interval)\n",
    "        if not last_update_str:\n",
    "            return float('inf')  # Priorité maximale si jamais téléchargé\n",
    "    \n",
    "        last_update = datetime.fromisoformat(last_update_str)\n",
    "        threshold = UPDATE_THRESHOLDS.get(interval, timedelta(days=1))\n",
    "    \n",
    "        # Ne télécharger que si les données sont plus anciennes que le seuil\n",
    "        if (datetime.now() - last_update) > threshold:\n",
    "            hours_outdated = (datetime.now() - last_update).total_seconds() / 3600\n",
    "    \n",
    "            # Utiliser le nouveau compteur d'erreurs basé sur la fenêtre temporelle\n",
    "            error_count = self.metadata.get_error_count(ticker)\n",
    "            error_penalty = error_count * 0.1\n",
    "    \n",
    "            # Ajouter le bonus d'intervalle au score\n",
    "            return hours_outdated - error_penalty + interval_bonus\n",
    "    \n",
    "        return None\n",
    "    \n",
    "\n",
    "    def get_download_queue(self, interval: str) -> List[str]:\n",
    "        \"\"\"Obtient une file de téléchargement priorisée.\n",
    "        \n",
    "        Args:\n",
    "            interval (str): L'intervalle de temps\n",
    "            \n",
    "        Returns:\n",
    "            List[str]: Liste des tickers à télécharger, par ordre de priorité\n",
    "        \"\"\"\n",
    "        scores = {}\n",
    "        for ticker in TICKERS:\n",
    "            # Ignorer les tickers présents dans la liste noire\n",
    "            if ticker in BLACKLISTED_TICKERS:\n",
    "                continue\n",
    "\n",
    "            score = self._get_priority_score(ticker, interval)\n",
    "            if score is not None:\n",
    "                scores[ticker] = score\n",
    "\n",
    "        # Trier par priorité décroissante\n",
    "        sorted_tickers = sorted(scores.keys(), key=lambda x: -scores[x])\n",
    "        self.logger.info(f\"Prioritized {len(sorted_tickers)} tickers for interval {interval}\")\n",
    "        return sorted_tickers\n",
    "\n",
    "    \n",
    "    def download_batch(self, interval: str):\n",
    "        \"\"\"Télécharge un lot de tickers pour un intervalle donné.\n",
    "\n",
    "        Args:\n",
    "            interval (str): L'intervalle de temps\n",
    "        \"\"\"\n",
    "        # Assurer que le répertoire de destination existe\n",
    "        interval_dir = os.path.join(DATA_DIR, interval)\n",
    "        os.makedirs(interval_dir, exist_ok=True)\n",
    "\n",
    "        # Obtenir la file complète des tickers prioritaires\n",
    "        queue = self.get_download_queue(interval)\n",
    "\n",
    "        # Utiliser la taille de lot adaptée à l'intervalle, ou la taille par défaut\n",
    "        batch_size = self.batch_sizes.get(interval, self.batch_size)\n",
    "\n",
    "        if not queue:\n",
    "            self.logger.info(f\"No tickers to download for interval {interval}\")\n",
    "            return\n",
    "\n",
    "        # Afficher le nombre total de tickers à télécharger\n",
    "        self.logger.info(f\"Preparing to download {len(queue)} tickers for interval {interval}\")\n",
    "\n",
    "        # Créer une barre de progression pour tous les tickers\n",
    "        with tqdm(total=len(queue), desc=f\"Downloading {interval}\") as pbar:\n",
    "            # Traiter les tickers par lots\n",
    "            for i in range(0, len(queue), batch_size):\n",
    "                # Prendre le prochain lot de tickers\n",
    "                batch = queue[i:i+batch_size]\n",
    "                # Rotation de l'user agent avant chaque lot\n",
    "                self.downloader.session.headers.update({'User-Agent': random.choice(USER_AGENTS)})\n",
    "                # Utiliser le StockDownloader pour télécharger le lot\n",
    "                self.downloader.batch_size = batch_size\n",
    "                results = self.downloader.download_batch(batch, interval)\n",
    "\n",
    "                # Sauvegarder les résultats\n",
    "                for ticker, df in results.items():\n",
    "                    self._save_data(ticker, interval, df)\n",
    "                    pbar.update(1)\n",
    "\n",
    "                # Mettre à jour l'état des tickers manquants\n",
    "                missing_tickers = set(batch) - set(results.keys())\n",
    "                for ticker in missing_tickers:\n",
    "                    pbar.update(1)\n",
    "\n",
    "    def _save_data(self, ticker: str, interval: str, df: pd.DataFrame):\n",
    "        \"\"\"Sauvegarde les données téléchargées en ajoutant uniquement les nouvelles lignes.\"\"\"\n",
    "        # Vérification d'intégrité des données\n",
    "        if df.empty:\n",
    "            self.logger.warning(f\"Empty dataframe for {ticker}, interval {interval}. Skipping save.\")\n",
    "            return\n",
    "\n",
    "        # Vérifier les colonnes essentielles\n",
    "        required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            self.logger.warning(f\"Missing columns {missing_columns} for {ticker}, interval {interval}. Skipping save.\")\n",
    "            return\n",
    "\n",
    "        # Créer le chemin du dossier\n",
    "        folder_path = os.path.join(DATA_DIR, interval)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        file_path = os.path.join(folder_path, f\"{ticker}.csv\")\n",
    "\n",
    "        # Convertir l'index en datetime et normaliser la timezone (convertir en timezone UTC puis supprimer l'info de timezone)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        if df.index.tzinfo is not None:\n",
    "            df.index = df.index.tz_convert('UTC').tz_localize(None)\n",
    "\n",
    "        # Charger les données existantes si le fichier existe\n",
    "        existing_data = None\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                existing_data = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "\n",
    "                # Assurer que l'index est bien un DateTimeIndex et normaliser la timezone\n",
    "                existing_data.index = pd.to_datetime(existing_data.index)\n",
    "                if existing_data.index.tzinfo is not None:\n",
    "                    existing_data.index = existing_data.index.tz_convert('UTC').tz_localize(None)\n",
    "\n",
    "                self.logger.debug(f\"Loaded existing data for {ticker} ({interval}): {len(existing_data)} rows\")\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Error loading existing data for {ticker} ({interval}): {str(e)}\")\n",
    "                existing_data = None\n",
    "\n",
    "        # Fusionner les données\n",
    "        if existing_data is not None and not existing_data.empty:\n",
    "            # Combiner les deux DataFrames\n",
    "            combined_data = pd.concat([existing_data, df])\n",
    "\n",
    "            # Supprimer les doublons (conserver la dernière version de chaque timestamp)\n",
    "            combined_data = combined_data[~combined_data.index.duplicated(keep='last')]\n",
    "\n",
    "            # Trier par date (maintenant les index sont normalisés donc le tri fonctionnera)\n",
    "            combined_data = combined_data.sort_index()\n",
    "\n",
    "            # Vérifier si de nouvelles données ont été ajoutées\n",
    "            new_rows = len(combined_data) - len(existing_data)\n",
    "            if new_rows > 0:\n",
    "                self.logger.info(f\"Added {new_rows} new rows for {ticker} ({interval})\")\n",
    "            else:\n",
    "                self.logger.debug(f\"No new data for {ticker} ({interval})\")\n",
    "\n",
    "            # Sauvegarder les données combinées\n",
    "            combined_data.to_csv(file_path)\n",
    "        else:\n",
    "            # Aucune donnée existante, sauvegarder directement les nouvelles données\n",
    "            df.to_csv(file_path)\n",
    "            self.logger.debug(f\"Saved new data for {ticker} ({interval}): {len(df)} rows\")\n",
    "    \n",
    "\n",
    "\n",
    "    def run_with_quotas(self, total_batches=100):\n",
    "        \"\"\"Exécute les téléchargements avec des quotas par intervalle pour assurer une couverture équilibrée.\n",
    "\n",
    "        Args:\n",
    "            total_batches (int): Nombre total de lots à télécharger\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Starting download with quotas: {total_batches} total batches\")\n",
    "\n",
    "        # Déterminer les queues et le nombre total de tickers à mettre à jour\n",
    "        interval_queues = {}\n",
    "        total_tickers = 0\n",
    "\n",
    "        for interval in INTERVALS:\n",
    "            queue = self.get_download_queue(interval)\n",
    "            if queue:\n",
    "                interval_queues[interval] = queue\n",
    "                total_tickers += len(queue)\n",
    "                self.logger.info(f\"Found {len(queue)} tickers to update for interval {interval}\")\n",
    "\n",
    "        if not interval_queues:\n",
    "            self.logger.info(\"No tickers need updating for any interval\")\n",
    "            return\n",
    "\n",
    "        # Calculer les quotas proportionnels au nombre de tickers\n",
    "        quotas = {}\n",
    "        for interval, queue in interval_queues.items():\n",
    "            # Au moins 1 lot par intervalle\n",
    "            quotas[interval] = max(1, int((len(queue) / total_tickers) * total_batches))\n",
    "\n",
    "        self.logger.info(f\"Assigned quotas: {quotas}\")\n",
    "\n",
    "        # Traiter chaque intervalle selon son quota\n",
    "        for interval, quota in quotas.items():\n",
    "            queue = interval_queues[interval]\n",
    "            batch_size = self.batch_sizes.get(interval, self.batch_size)\n",
    "\n",
    "            # Calculer combien de tickers nous pouvons traiter avec le quota\n",
    "            tickers_to_process = min(len(queue), quota * batch_size)\n",
    "\n",
    "            self.logger.info(f\"Processing {tickers_to_process} tickers for interval {interval} (quota: {quota} batches)\")\n",
    "\n",
    "            # Ne prendre que le nombre de tickers correspondant au quota\n",
    "            limited_queue = queue[:tickers_to_process]\n",
    "\n",
    "            # Créer une barre de progression pour cet intervalle\n",
    "            with tqdm(total=len(limited_queue), desc=f\"Downloading {interval}\") as pbar:\n",
    "                # Traiter les tickers par lots\n",
    "                for i in range(0, len(limited_queue), batch_size):\n",
    "                    batch = limited_queue[i:i+batch_size]\n",
    "\n",
    "                    # Utiliser le StockDownloader pour télécharger le lot\n",
    "                    self.downloader.batch_size = batch_size\n",
    "                    self.downloader.session.headers.update({'User-Agent': random.choice(USER_AGENTS)})\n",
    "                    results = self.downloader.download_batch(batch, interval)\n",
    "\n",
    "                    # Sauvegarder les résultats\n",
    "                    for ticker, df in results.items():\n",
    "                        self._save_data(ticker, interval, df)\n",
    "                        pbar.update(1)\n",
    "\n",
    "                    # Mettre à jour l'état des tickers manquants\n",
    "                    missing_tickers = set(batch) - set(results.keys())\n",
    "                    for ticker in missing_tickers:\n",
    "                        pbar.update(1)\n",
    "\n",
    "                    # Pause entre les lots\n",
    "                    time.sleep(3)\n",
    "\n",
    "            # Pause entre les intervalles\n",
    "            time.sleep(6)\n",
    "\n",
    "        # Nettoyage final\n",
    "        self.clean_old_failures()\n",
    "        if self.metadata._save_counter > 0:\n",
    "            self.metadata.save()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def run_parallel(self, max_workers=3):\n",
    "        \"\"\"Exécute les téléchargements en parallèle pour différents intervalles.\n",
    "        \n",
    "        Args:\n",
    "            max_workers (int): Nombre maximum de processus parallèles\n",
    "        \"\"\"\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Soumettre les tâches pour chaque intervalle\n",
    "            futures = {executor.submit(self.download_batch, interval): interval for interval in INTERVALS}\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                interval = futures[future]\n",
    "                try:\n",
    "                    future.result()\n",
    "                    self.logger.info(f\"Completed download for interval {interval}\")\n",
    "                except Exception as exc:\n",
    "                    self.logger.error(f\"Download for interval {interval} generated an exception: {exc}\", exc_info=True)\n",
    "        \n",
    "        # Nettoyage final\n",
    "        self.clean_old_failures()\n",
    "\n",
    "\n",
    "class DownloadModeManager:\n",
    "    \"\"\"Gère les modes de téléchargement et les stratégies de fallback.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mode_file = \"download_modes.json\"\n",
    "        self.modes = self._load_modes()\n",
    "        self.logger = logging.getLogger(\"DownloadModeManager\")\n",
    "        \n",
    "    def _load_modes(self):\n",
    "        \"\"\"Charge les modes de téléchargement précédemment utilisés.\"\"\"\n",
    "        if os.path.exists(self.mode_file):\n",
    "            try:\n",
    "                with open(self.mode_file, 'r') as f:\n",
    "                    return json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                return self._default_modes()\n",
    "        return self._default_modes()\n",
    "    \n",
    "    def _default_modes(self):\n",
    "        \"\"\"Retourne les modes de téléchargement par défaut.\"\"\"\n",
    "        return {interval: \"batch\" for interval in INTERVALS}\n",
    "    \n",
    "    def save_modes(self):\n",
    "        \"\"\"Sauvegarde les modes actuels.\"\"\"\n",
    "        with open(self.mode_file, 'w') as f:\n",
    "            json.dump(self.modes, f, indent=2)\n",
    "    \n",
    "    def get_mode(self, interval):\n",
    "        \"\"\"Obtient le mode de téléchargement pour un intervalle.\"\"\"\n",
    "        return self.modes.get(interval, \"batch\")\n",
    "    \n",
    "    def set_mode(self, interval, mode):\n",
    "        \"\"\"Définit le mode de téléchargement pour un intervalle.\"\"\"\n",
    "        if mode not in [\"batch\", \"individual\"]:\n",
    "            raise ValueError(f\"Mode invalide: {mode}\")\n",
    "        self.modes[interval] = mode\n",
    "        self.save_modes()\n",
    "        self.logger.info(f\"Mode de téléchargement pour {interval} défini à {mode}\")\n",
    "\n",
    "\n",
    "class DashboardGenerator:\n",
    "    \"\"\"Génère un tableau de bord HTML pour visualiser l'état des téléchargements.\"\"\"\n",
    "    \n",
    "    def __init__(self, metadata, output_path=\"dashboard.html\", auto_refresh_seconds=30):\n",
    "        self.metadata = metadata\n",
    "        self.output_path = output_path\n",
    "        self.auto_refresh_seconds = auto_refresh_seconds\n",
    "        self.logger = logging.getLogger(\"DashboardGenerator\")\n",
    "        \n",
    "        # Statistiques de la session courante\n",
    "        self.session_stats = {\n",
    "            \"start_time\": datetime.now(),\n",
    "            \"downloads\": {interval: {\"success\": 0, \"failure\": 0} for interval in INTERVALS},\n",
    "            \"last_updated\": datetime.now(),\n",
    "            \"current_mode\": {interval: \"unknown\" for interval in INTERVALS},\n",
    "            \"planned_downloads\": {}  # Ajout de cette ligne qui manquait\n",
    "        }\n",
    "    \n",
    "    def record_download(self, ticker, interval, success):\n",
    "        \"\"\"Enregistre un téléchargement dans les statistiques.\"\"\"\n",
    "        if success:\n",
    "            self.session_stats[\"downloads\"][interval][\"success\"] += 1\n",
    "        else:\n",
    "            self.session_stats[\"downloads\"][interval][\"failure\"] += 1\n",
    "        \n",
    "        self.session_stats[\"last_updated\"] = datetime.now()\n",
    "    \n",
    "    def update_mode(self, interval, mode):\n",
    "        \"\"\"Met à jour le mode de téléchargement pour un intervalle.\"\"\"\n",
    "        self.session_stats[\"current_mode\"][interval] = mode\n",
    "    \n",
    "    def get_problem_tickers(self, min_errors=3):\n",
    "        \"\"\"Obtient la liste des tickers problématiques.\"\"\"\n",
    "        problem_tickers = []\n",
    "        \n",
    "        for ticker, info in self.metadata.data.items():\n",
    "            if 'consecutive_errors' in info and info['consecutive_errors'] >= min_errors:\n",
    "                error_count = len(info.get('error_timestamps', []))\n",
    "                last_attempt = info.get('last_attempt')\n",
    "                \n",
    "                if last_attempt:\n",
    "                    last_attempt_date = datetime.fromisoformat(last_attempt)\n",
    "                else:\n",
    "                    last_attempt_date = None\n",
    "                    \n",
    "                problem_tickers.append({\n",
    "                    \"ticker\": ticker,\n",
    "                    \"consecutive_errors\": info['consecutive_errors'],\n",
    "                    \"error_count\": error_count,\n",
    "                    \"last_attempt\": last_attempt_date\n",
    "                })\n",
    "                \n",
    "        # Trier par nombre d'erreurs consécutives décroissant\n",
    "        return sorted(problem_tickers, key=lambda x: x[\"consecutive_errors\"], reverse=True)\n",
    "    \n",
    "    def get_freshness_data(self):\n",
    "        \"\"\"Obtient les données de fraîcheur pour tous les tickers.\"\"\"\n",
    "        freshness_data = {}\n",
    "        \n",
    "        for interval in INTERVALS:\n",
    "            freshness_data[interval] = {\n",
    "                \"fresh\": 0,  # Données à jour\n",
    "                \"stale\": 0,  # Données périmées mais pas trop\n",
    "                \"outdated\": 0,  # Données très périmées\n",
    "                \"never\": 0,  # Jamais téléchargées\n",
    "                \"ticker_status\": []  # Liste de status des tickers pour la visualisation\n",
    "            }\n",
    "        \n",
    "        for ticker in TICKERS:\n",
    "            if ticker in BLACKLISTED_TICKERS:\n",
    "                continue\n",
    "                \n",
    "            info = self.metadata.data.get(ticker, {})\n",
    "            last_updates = info.get('last_updates', {})\n",
    "            \n",
    "            for interval in INTERVALS:\n",
    "                last_update_str = last_updates.get(interval)\n",
    "                if last_update_str:\n",
    "                    last_update = datetime.fromisoformat(last_update_str)\n",
    "                    age = datetime.now() - last_update\n",
    "                    threshold = UPDATE_THRESHOLDS.get(interval, timedelta(days=1))\n",
    "                    \n",
    "                    # Déterminer l'état de fraîcheur\n",
    "                    if age <= threshold:\n",
    "                        status = \"fresh\"\n",
    "                        freshness_data[interval][\"fresh\"] += 1\n",
    "                    elif age <= threshold * 2:\n",
    "                        status = \"stale\"\n",
    "                        freshness_data[interval][\"stale\"] += 1\n",
    "                    else:\n",
    "                        status = \"outdated\"\n",
    "                        freshness_data[interval][\"outdated\"] += 1\n",
    "                else:\n",
    "                    status = \"never\"\n",
    "                    freshness_data[interval][\"never\"] += 1\n",
    "                \n",
    "                # Ajouter le statut à la liste pour la visualisation\n",
    "                freshness_data[interval][\"ticker_status\"].append(status)\n",
    "            \n",
    "        return freshness_data\n",
    "    \n",
    "    def generate_dashboard(self):\n",
    "        \"\"\"Génère le tableau de bord HTML simplifié.\"\"\"\n",
    "        # Obtenir les données\n",
    "        problem_tickers = self.get_problem_tickers()\n",
    "        freshness_data = self.get_freshness_data()\n",
    "        \n",
    "        # Créer la page HTML\n",
    "        html = f\"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html lang=\"fr\">\n",
    "        <head>\n",
    "            <meta charset=\"UTF-8\">\n",
    "            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "            <title>Tableau de bord des téléchargements</title>\n",
    "            <meta http-equiv=\"refresh\" content=\"{self.auto_refresh_seconds}\">\n",
    "            <style>\n",
    "                body {{ font-family: Arial, sans-serif; margin: 0; padding: 0; background-color: #f4f4f8; }}\n",
    "                .container {{ max-width: 1200px; margin: 0 auto; padding: 20px; }}\n",
    "                h1, h2, h3 {{ color: #333; }}\n",
    "                .card {{ background-color: white; border-radius: 8px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); margin-bottom: 20px; overflow: hidden; }}\n",
    "                .card-header {{ background-color: #f0f0f5; padding: 15px; border-bottom: 1px solid #ddd; }}\n",
    "                .card-body {{ padding: 15px; }}\n",
    "                table {{ width: 100%; border-collapse: collapse; }}\n",
    "                th, td {{ padding: 12px 15px; text-align: left; border-bottom: 1px solid #ddd; }}\n",
    "                thead {{ background-color: #f8f8f8; }}\n",
    "                tr:hover {{ background-color: #f5f5f5; }}\n",
    "                .status-indicator {{ display: inline-block; width: 12px; height: 12px; border-radius: 50%; margin-right: 5px; }}\n",
    "                .status-fresh {{ background-color: #90EE90; }} /* Vert pastel pour À jour */\n",
    "                .status-stale {{ background-color: #FFD8B1; }} /* Orange pastel pour Périmées */\n",
    "                .status-outdated {{ background-color: #FFB6C1; }} /* Rouge pastel pour Obsolètes */\n",
    "                .status-never {{ background-color: #A9A9A9; }} /* Gris foncé pour Jamais téléchargées */\n",
    "                .timestamp {{ color: #777; font-size: 0.8em; text-align: right; }}\n",
    "                .tabs {{ display: flex; border-bottom: 1px solid #ddd; margin-bottom: 20px; }}\n",
    "                .tab {{ padding: 10px 20px; cursor: pointer; background-color: #f0f0f5; margin-right: 5px; border-radius: 5px 5px 0 0; }}\n",
    "                .tab.active {{ background-color: white; border: 1px solid #ddd; border-bottom: none; }}\n",
    "                .tab-content {{ display: none; }}\n",
    "                .tab-content.active {{ display: block; }}\n",
    "                .interval-tabs {{ display: flex; margin-bottom: 10px; }}\n",
    "                .interval-tab {{ padding: 8px 16px; cursor: pointer; background-color: #f0f0f5; margin-right: 5px; border-radius: 5px; }}\n",
    "                .interval-tab.active {{ background-color: #4CAF50; color: white; }}\n",
    "                \n",
    "                /* Style pour la visualisation type défragmenteur */\n",
    "                .defrag-container {{ border: 1px solid #ccc; background-color: #f9f9f9; padding: 5px; margin: 10px 0; }}\n",
    "                .defrag-header {{ display: flex; justify-content: space-between; margin-bottom: 5px; }}\n",
    "                .defrag-visualization {{ height: 30px; display: flex; overflow: hidden; }}\n",
    "                .defrag-block {{ width: 3px; height: 100%; }}\n",
    "                .defrag-block.fresh {{ background-color: #90EE90; }} /* Vert pastel pour À jour */\n",
    "                .defrag-block.stale {{ background-color: #FFD8B1; }} /* Orange pastel pour Périmées */\n",
    "                .defrag-block.outdated {{ background-color: #FFB6C1; }} /* Rouge pastel pour Obsolètes */\n",
    "                .defrag-block.never {{ background-color: #A9A9A9; }} /* Gris foncé pour Jamais téléchargées */\n",
    "                .defrag-legend {{ display: flex; margin-top: 10px; }}\n",
    "                .defrag-legend-item {{ display: flex; align-items: center; margin-right: 20px; }}\n",
    "                .defrag-legend-color {{ width: 15px; height: 15px; margin-right: 5px; }}\n",
    "                .defrag-legend-color.fresh {{ background-color: #90EE90; }}\n",
    "                .defrag-legend-color.stale {{ background-color: #FFD8B1; }}\n",
    "                .defrag-legend-color.outdated {{ background-color: #FFB6C1; }}\n",
    "                .defrag-legend-color.never {{ background-color: #A9A9A9; }}\n",
    "                .stats-summary {{ display: flex; justify-content: space-between; margin-top: 10px; }}\n",
    "                .stats-item {{ text-align: center; }}\n",
    "                .stats-value {{ font-weight: bold; font-size: 20px; }}\n",
    "                .global-legend {{ padding: 10px; border-radius: 8px; border: 1px solid #ddd; margin-bottom: 20px; display: flex; justify-content: center; }}\n",
    "                \n",
    "                /* Style pour la barre de progression de rafraîchissement */\n",
    "                .refresh-bar-container {{\n",
    "                    position: fixed;\n",
    "                    top: 10px;\n",
    "                    right: 10px;\n",
    "                    width: 100px;\n",
    "                    height: 8px;\n",
    "                    background-color: #f0f0f5;\n",
    "                    border-radius: 4px;\n",
    "                    overflow: hidden;\n",
    "                    z-index: 1000;\n",
    "                    box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n",
    "                }}\n",
    "                .refresh-bar {{\n",
    "                    height: 100%;\n",
    "                    width: 100%;\n",
    "                    background-color: #87CEFA; /* Bleu ciel */\n",
    "                    border-radius: 4px;\n",
    "                    transform-origin: left;\n",
    "                }}\n",
    "                .header-container {{\n",
    "                    display: flex;\n",
    "                    justify-content: space-between;\n",
    "                    align-items: flex-start;\n",
    "                }}\n",
    "                .header-left {{\n",
    "                    flex: 1;\n",
    "                }}\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <div class=\"refresh-bar-container\">\n",
    "                <div class=\"refresh-bar\" id=\"refreshBar\"></div>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"container\">\n",
    "                <div class=\"header-container\">\n",
    "                    <div class=\"header-left\">\n",
    "                        <h1>Tableau de bord des téléchargements de données</h1>\n",
    "                    </div>\n",
    "                </div>\n",
    "                <p class=\"timestamp\">Dernière mise à jour: {self.session_stats[\"last_updated\"].strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "                \n",
    "                <div class=\"tabs\">\n",
    "                    <div class=\"tab active\" onclick=\"showTab('overview')\">Vue d'ensemble</div>\n",
    "                    <div class=\"tab\" onclick=\"showTab('freshness')\">Fraîcheur des données</div>\n",
    "                    <div class=\"tab\" onclick=\"showTab('problems')\">Problèmes</div>\n",
    "                </div>\n",
    "                \n",
    "                <!-- Vue d'ensemble -->\n",
    "                <div id=\"overview\" class=\"tab-content active\">\n",
    "                    <h2>Statut de fraîcheur par intervalle</h2>\n",
    "                    \n",
    "                    <!-- Légende globale -->\n",
    "                    <div class=\"global-legend\">\n",
    "                        <div class=\"defrag-legend\">\n",
    "                            <div class=\"defrag-legend-item\">\n",
    "                                <div class=\"defrag-legend-color fresh\"></div>\n",
    "                                <span>À jour</span>\n",
    "                            </div>\n",
    "                            <div class=\"defrag-legend-item\">\n",
    "                                <div class=\"defrag-legend-color stale\"></div>\n",
    "                                <span>Périmées</span>\n",
    "                            </div>\n",
    "                            <div class=\"defrag-legend-item\">\n",
    "                                <div class=\"defrag-legend-color outdated\"></div>\n",
    "                                <span>Obsolètes</span>\n",
    "                            </div>\n",
    "                            <div class=\"defrag-legend-item\">\n",
    "                                <div class=\"defrag-legend-color never\"></div>\n",
    "                                <span>Jamais téléchargées</span>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "        \"\"\"\n",
    "        # Créer une visualisation de type défragmenteur pour chaque intervalle\n",
    "        for interval in INTERVALS:\n",
    "            ticker_statuses = freshness_data[interval][\"ticker_status\"]\n",
    "            fresh_count = freshness_data[interval][\"fresh\"]\n",
    "            stale_count = freshness_data[interval][\"stale\"]\n",
    "            outdated_count = freshness_data[interval][\"outdated\"]\n",
    "            never_count = freshness_data[interval][\"never\"]\n",
    "            total_count = fresh_count + stale_count + outdated_count + never_count\n",
    "            \n",
    "            # Calculer les pourcentages\n",
    "            fresh_pct = (fresh_count / total_count * 100) if total_count > 0 else 0\n",
    "            stale_pct = (stale_count / total_count * 100) if total_count > 0 else 0\n",
    "            outdated_pct = (outdated_count / total_count * 100) if total_count > 0 else 0\n",
    "            never_pct = (never_count / total_count * 100) if total_count > 0 else 0\n",
    "            \n",
    "            html += f\"\"\"\n",
    "                    <div class=\"card\">\n",
    "                        <div class=\"card-header\">\n",
    "                            <h3>Intervalle {interval}</h3>\n",
    "                        </div>\n",
    "                        <div class=\"card-body\">\n",
    "                            <div class=\"defrag-container\">\n",
    "                                <div class=\"defrag-header\">\n",
    "                                    <span>Statut de fraîcheur des données:</span>\n",
    "                                </div>\n",
    "                                <div class=\"defrag-visualization\">\n",
    "            \"\"\"\n",
    "            \n",
    "            # Générer les blocs pour la visualisation\n",
    "            for status in ticker_statuses:\n",
    "                html += f'<div class=\"defrag-block {status}\"></div>\\n'\n",
    "            \n",
    "            html += f\"\"\"\n",
    "                                </div>\n",
    "                            </div>\n",
    "                            \n",
    "                            <div class=\"stats-summary\">\n",
    "                                <div class=\"stats-item\">\n",
    "                                    <div class=\"stats-value\">{fresh_count}</div>\n",
    "                                    <div>À jour ({fresh_pct:.1f}%)</div>\n",
    "                                </div>\n",
    "                                <div class=\"stats-item\">\n",
    "                                    <div class=\"stats-value\">{stale_count}</div>\n",
    "                                    <div>Périmées ({stale_pct:.1f}%)</div>\n",
    "                                </div>\n",
    "                                <div class=\"stats-item\">\n",
    "                                    <div class=\"stats-value\">{outdated_count}</div>\n",
    "                                    <div>Obsolètes ({outdated_pct:.1f}%)</div>\n",
    "                                </div>\n",
    "                                <div class=\"stats-item\">\n",
    "                                    <div class=\"stats-value\">{never_count}</div>\n",
    "                                    <div>Jamais téléchargées ({never_pct:.1f}%)</div>\n",
    "                                </div>\n",
    "                                <div class=\"stats-item\">\n",
    "                                    <div class=\"stats-value\">{total_count}</div>\n",
    "                                    <div>Total</div>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "                </div>\n",
    "                \n",
    "                <!-- Fraîcheur des données -->\n",
    "                <div id=\"freshness\" class=\"tab-content\">\n",
    "                    <div class=\"interval-tabs\">\n",
    "        \"\"\"\n",
    "        \n",
    "        # Onglets d'intervalle pour la fraîcheur\n",
    "        for i, interval in enumerate(INTERVALS):\n",
    "            active = \"active\" if i == 0 else \"\"\n",
    "            html += f\"\"\"\n",
    "                        <div class=\"interval-tab {active}\" onclick=\"showIntervalTab('{interval}')\">{interval}</div>\n",
    "            \"\"\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "                    </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Contenu des onglets d'intervalle pour la fraîcheur\n",
    "        for i, interval in enumerate(INTERVALS):\n",
    "            display = \"block\" if i == 0 else \"none\"\n",
    "            \n",
    "            html += f\"\"\"\n",
    "                    <div id=\"interval-{interval}\" class=\"card\" style=\"display: {display}\">\n",
    "                        <div class=\"card-header\">\n",
    "                            <h2>Fraîcheur des données - Intervalle {interval}</h2>\n",
    "                        </div>\n",
    "                        <div class=\"card-body\">\n",
    "                            <table>\n",
    "                                <thead>\n",
    "                                    <tr>\n",
    "                                        <th>Ticker</th>\n",
    "                                        <th>Dernière mise à jour</th>\n",
    "                                        <th>Âge</th>\n",
    "                                        <th>Statut</th>\n",
    "                                    </tr>\n",
    "                                </thead>\n",
    "                                <tbody>\n",
    "            \"\"\"\n",
    "            \n",
    "            # Liste des tickers avec leur statut de fraîcheur\n",
    "            tickers_with_status = []\n",
    "            for ticker in TICKERS:\n",
    "                if ticker in BLACKLISTED_TICKERS:\n",
    "                    continue\n",
    "                    \n",
    "                info = self.metadata.data.get(ticker, {})\n",
    "                last_updates = info.get('last_updates', {})\n",
    "                \n",
    "                last_update_str = last_updates.get(interval)\n",
    "                if last_update_str:\n",
    "                    last_update = datetime.fromisoformat(last_update_str)\n",
    "                    age = datetime.now() - last_update\n",
    "                    threshold = UPDATE_THRESHOLDS.get(interval, timedelta(days=1))\n",
    "                    \n",
    "                    if age <= threshold:\n",
    "                        status = \"fresh\"\n",
    "                    elif age <= threshold * 2:\n",
    "                        status = \"stale\"\n",
    "                    else:\n",
    "                        status = \"outdated\"\n",
    "                else:\n",
    "                    status = \"never\"\n",
    "                    last_update = None\n",
    "                    age = None\n",
    "                \n",
    "                tickers_with_status.append((ticker, status, last_update, age))\n",
    "            \n",
    "            # Trier par statut (d'abord les plus problématiques)\n",
    "            status_order = {\"never\": 0, \"outdated\": 1, \"stale\": 2, \"fresh\": 3}\n",
    "            tickers_with_status.sort(key=lambda x: status_order[x[1]])\n",
    "            \n",
    "            for ticker, status, last_update, age in tickers_with_status:\n",
    "                status_class = f\"status-{status}\"\n",
    "                \n",
    "                if last_update:\n",
    "                    last_update_str = last_update.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                    age_str = f\"{age.days}j {age.seconds // 3600}h {(age.seconds % 3600) // 60}m\"\n",
    "                else:\n",
    "                    last_update_str = \"Jamais\"\n",
    "                    age_str = \"-\"\n",
    "                \n",
    "                html += f\"\"\"\n",
    "                                    <tr>\n",
    "                                        <td>{ticker}</td>\n",
    "                                        <td>{last_update_str}</td>\n",
    "                                        <td>{age_str}</td>\n",
    "                                        <td><span class=\"status-indicator {status_class}\"></span>{status}</td>\n",
    "                                    </tr>\n",
    "                \"\"\"\n",
    "            \n",
    "            html += \"\"\"\n",
    "                                </tbody>\n",
    "                            </table>\n",
    "                        </div>\n",
    "                    </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "                </div>\n",
    "                \n",
    "                <!-- Problèmes -->\n",
    "                <div id=\"problems\" class=\"tab-content\">\n",
    "                    <div class=\"card\">\n",
    "                        <div class=\"card-header\">\n",
    "                            <h2>Tickers problématiques</h2>\n",
    "                        </div>\n",
    "                        <div class=\"card-body\">\n",
    "        \"\"\"\n",
    "        \n",
    "        if problem_tickers:\n",
    "            html += \"\"\"\n",
    "                            <table>\n",
    "                                <thead>\n",
    "                                    <tr>\n",
    "                                        <th>Ticker</th>\n",
    "                                        <th>Erreurs consécutives</th>\n",
    "                                        <th>Nombre total d'erreurs</th>\n",
    "                                        <th>Dernière tentative</th>\n",
    "                                    </tr>\n",
    "                                </thead>\n",
    "                                <tbody>\n",
    "            \"\"\"\n",
    "            \n",
    "            for ticker in problem_tickers:\n",
    "                last_attempt = ticker[\"last_attempt\"].strftime('%Y-%m-%d %H:%M:%S') if ticker[\"last_attempt\"] else \"Jamais\"\n",
    "                \n",
    "                html += f\"\"\"\n",
    "                                    <tr>\n",
    "                                        <td>{ticker[\"ticker\"]}</td>\n",
    "                                        <td>{ticker[\"consecutive_errors\"]}</td>\n",
    "                                        <td>{ticker[\"error_count\"]}</td>\n",
    "                                        <td>{last_attempt}</td>\n",
    "                                    </tr>\n",
    "                \"\"\"\n",
    "            \n",
    "            html += \"\"\"\n",
    "                                </tbody>\n",
    "                            </table>\n",
    "            \"\"\"\n",
    "        else:\n",
    "            html += \"\"\"\n",
    "                            <p>Aucun ticker problématique détecté.</p>\n",
    "            \"\"\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <script>\n",
    "                // Animation de la barre de progression\n",
    "                const refreshTime = {self.auto_refresh_seconds};\n",
    "                const refreshBar = document.getElementById('refreshBar');\n",
    "                \n",
    "                function updateRefreshBar() {{\n",
    "                    const now = new Date();\n",
    "                    const seconds = now.getSeconds();\n",
    "                    const milliseconds = now.getMilliseconds();\n",
    "                    const currentTime = seconds + (milliseconds / 1000);\n",
    "                    \n",
    "                    // Calculer le temps écoulé depuis le dernier rafraîchissement (modulo refreshTime)\n",
    "                    const elapsedTime = currentTime % refreshTime;\n",
    "                    const progress = 1 - (elapsedTime / refreshTime);\n",
    "                    \n",
    "                    // Appliquer la transformation\n",
    "                    refreshBar.style.transform = `scaleX(${{progress}})`;\n",
    "                    \n",
    "                    // Continuer l'animation\n",
    "                    requestAnimationFrame(updateRefreshBar);\n",
    "                }}\n",
    "                \n",
    "                // Démarrer l'animation\n",
    "                updateRefreshBar();\n",
    "                \n",
    "                function showTab(tabId) {{\n",
    "                    // Masquer tous les contenus d'onglet\n",
    "                    document.querySelectorAll('.tab-content').forEach(function(tab) {{\n",
    "                        tab.classList.remove('active');\n",
    "                    }});\n",
    "                    \n",
    "                    // Désactiver tous les onglets\n",
    "                    document.querySelectorAll('.tab').forEach(function(tab) {{\n",
    "                        tab.classList.remove('active');\n",
    "                    }});\n",
    "                    \n",
    "                    // Afficher le contenu d'onglet sélectionné\n",
    "                    document.getElementById(tabId).classList.add('active');\n",
    "                    \n",
    "                    // Activer l'onglet sélectionné\n",
    "                    document.querySelectorAll('.tab').forEach(function(tab) {{\n",
    "                        if (tab.textContent.toLowerCase().includes(tabId.toLowerCase())) {{\n",
    "                            tab.classList.add('active');\n",
    "                        }}\n",
    "                    }});\n",
    "                }}\n",
    "                \n",
    "                function showIntervalTab(interval) {{\n",
    "                    // Masquer tous les contenus d'onglet d'intervalle\n",
    "                    document.querySelectorAll('[id^=\"interval-\"]').forEach(function(tab) {{\n",
    "                        tab.style.display = 'none';\n",
    "                    }});\n",
    "                    \n",
    "                    // Désactiver tous les onglets d'intervalle\n",
    "                    document.querySelectorAll('.interval-tab').forEach(function(tab) {{\n",
    "                        tab.classList.remove('active');\n",
    "                    }});\n",
    "                    \n",
    "                    // Afficher le contenu d'onglet d'intervalle sélectionné\n",
    "                    document.getElementById('interval-' + interval).style.display = 'block';\n",
    "                    \n",
    "                    // Activer l'onglet d'intervalle sélectionné\n",
    "                    document.querySelectorAll('.interval-tab').forEach(function(tab) {{\n",
    "                        if (tab.textContent.includes(interval)) {{\n",
    "                            tab.classList.add('active');\n",
    "                        }}\n",
    "                    }});\n",
    "                }}\n",
    "            </script>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Écrire le HTML dans un fichier\n",
    "        with open(self.output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(html)\n",
    "            \n",
    "        self.logger.info(f\"Tableau de bord généré: {self.output_path}\")\n",
    "        \n",
    "        return self.output_path\n",
    "\n",
    "    def set_planned_downloads(self, interval, tickers):\n",
    "        \"\"\"Définit la liste des téléchargements planifiés pour un intervalle.\"\"\"\n",
    "        self.session_stats[\"planned_downloads\"][interval] = tickers\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    # 🌟 Initialisation de PriorityDownloader avec batch_size pour des téléchargements optimisés\n",
    "    downloader = PriorityDownloader(batch_size=15)\n",
    "    \n",
    "    # 🧹 Nettoyage des tickers avec trop d'erreurs pour repartir sur des bases saines\n",
    "    downloader.clean_old_failures()\n",
    "    \n",
    "    # ⚙️ Configuration des stratégies de téléchargement\n",
    "    # Choisissez votre approche pour équilibrer vitesse, fiabilité et équité des intervalles\n",
    "    use_interval_rotation = False   # 🔄 Rotation par ticker entre intervalles\n",
    "    use_cross_interval = False     # 🔄 Rotation par lots entre intervalles\n",
    "    use_quotas = True            # 📊 Allocation proportionnelle des ressources\n",
    "    use_parallel = False          # 🚀 Parallélisation par intervalle (attention : risqué)\n",
    "    use_individual = False        # 🐢 Téléchargement séquentiel un par un\n",
    "    use_individual_parallel = False # ⚡ Téléchargement parallèle par ticker\n",
    "    \n",
    "    # 🎯 Paramètres pour le téléchargement individuel\n",
    "    individual_interval = '1d'    # Intervalle cible (ex. '1d', '1h', '5m')\n",
    "    max_tickers = None           # Limite du nombre de tickers (None = tous)\n",
    "    max_workers = 11             # Nombre de threads pour les approches parallèles\n",
    "    \n",
    "    # 🚀 Lancement de la stratégie choisie\n",
    "    if use_interval_rotation:\n",
    "        # 🔄 Rotation par ticker\n",
    "        # Fonctionnement : Alterne les intervalles à chaque ticker (ex. AAPL 1m, MSFT 1h, GOOGL 1d...)\n",
    "        # Avantage : Progrès équilibré sur tous les intervalles, même si interrompu\n",
    "        # Quand l'utiliser : Pour une répartition équitable des téléchargements\n",
    "        downloader.download_with_interval_rotation(max_tickers=max_tickers, max_workers=max_workers)\n",
    "    \n",
    "    elif use_cross_interval:\n",
    "        # 🔄 Rotation par lot\n",
    "        # Fonctionnement : Télécharge par lots, en alternant les intervalles (ex. 20 tickers 1m, puis 1h...)\n",
    "        # Avantage : Équilibre entre efficacité (lots) et équité (rotation)\n",
    "        # Quand l'utiliser : Pour un compromis performance/équité\n",
    "        downloader.run_cross_interval(max_batches_per_run=100)\n",
    "    \n",
    "    elif use_quotas:\n",
    "        # 📊 Allocation proportionnelle\n",
    "        # Fonctionnement : Alloue les ressources selon les besoins de chaque intervalle\n",
    "        # Exemple : Si 50% des tickers sont en 1d, 50% des lots y sont dédiés\n",
    "        # Avantage : Distribution équitable selon les volumes\n",
    "        # Quand l'utiliser : Quand les intervalles ont des besoins très variés\n",
    "        downloader.run_with_quotas(total_batches=10000)\n",
    "    \n",
    "    elif use_parallel:\n",
    "        # 🚀 Parallélisation par intervalle\n",
    "        # Fonctionnement : Télécharge tous les intervalles en parallèle (1m, 1h, 1d... simultanément)\n",
    "        # Avantage : Rapide si l'API le permet\n",
    "        # Inconvénient : Risque de blocage par l'API (ex. Yahoo Finance)\n",
    "        # Quand l'utiliser : Avec un accès API stable (déconseillé sinon)\n",
    "        downloader.run_parallel(max_workers=2)\n",
    "       \n",
    "    elif use_individual:\n",
    "        # 🐢 Séquentiel un par un\n",
    "        # Fonctionnement : Télécharge chaque ticker séquentiellement pour un seul intervalle\n",
    "        # Exemple : AAPL 1d, puis MSFT 1d, puis GOOGL 1d...\n",
    "        # Avantage : Très sûr, peu de risques de blocage\n",
    "        # Inconvénient : Lent, un seul intervalle à la fois\n",
    "        # Quand l'utiliser : Après des blocages avec d'autres méthodes\n",
    "        downloader.download_one_by_one(individual_interval, max_tickers=max_tickers)\n",
    "    \n",
    "    elif use_parallel_individual:\n",
    "        # ⚡ Séquentiel un par un parallèle\n",
    "        # Fonctionnement : Télécharge plusieurs tickers en parallèle pour un seul intervalle\n",
    "        # Exemple : AAPL, MSFT, GOOGL en 1d simultanément\n",
    "        # Avantage : Bon compromis vitesse/fiabilité\n",
    "        # Quand l'utiliser : Pour optimiser un intervalle spécifique\n",
    "        downloader.download_one_by_one_parallel(individual_interval, max_tickers=max_tickers, max_workers=max_workers)\n",
    "    \n",
    "    else:\n",
    "        # 🔄 Exécution séquentielle simple\n",
    "        # Fonctionnement : Télécharge chaque intervalle séquentiellement avec une pause entre chaque\n",
    "        # Simple et sûr, mais lent\n",
    "        for interval in downloader.get_rotated_intervals():\n",
    "            downloader.download_batch(interval)\n",
    "            time.sleep(1)  # Pause pour éviter les blocages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dbecfc-ecd3-4857-a8f7-381101ecd3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dictionnaire global pour stocker les seuils calculés\n",
    "seuils = {}\n",
    "\n",
    "def analyze_and_plot_csv_files_by_iqr(data_dir, intervals, iqr_factor=1.5, top_n=10):\n",
    "    \"\"\"\n",
    "    Analyse les fichiers CSV et calcule les seuils IQR par intervalle. Affiche le top-10 des fichiers les plus courts\n",
    "    et trace les graphiques.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Dossier contenant les sous-dossiers d'intervalles.\n",
    "        intervals (list): Liste des sous-dossiers à traiter.\n",
    "        iqr_factor (float): Facteur pour le calcul du seuil basé sur l'IQR.\n",
    "        top_n (int): Nombre de fichiers les plus courts à afficher.\n",
    "    \"\"\"\n",
    "    global seuils  # Accès à la variable globale seuils\n",
    "    \n",
    "    for interval in intervals:\n",
    "        folder_path = os.path.join(data_dir, interval)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Le dossier {folder_path} n'existe pas.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nTraitement des fichiers dans l'intervalle : {interval}\")\n",
    "        file_stats = []\n",
    "\n",
    "        # Lecture des fichiers et comptage des lignes\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path) and filename.endswith('.csv'):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        num_lines = sum(1 for _ in f) - 1  # Ignorer l'en-tête\n",
    "                    file_stats.append((num_lines, filename))\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur de lecture du fichier {file_path}: {e}\")\n",
    "\n",
    "        if not file_stats:\n",
    "            print(f\"Aucun fichier valide dans {interval}.\")\n",
    "            continue\n",
    "\n",
    "        # Calcul des quartiles et IQR\n",
    "        lengths = np.array([num_lines for num_lines, _ in file_stats])\n",
    "        Q1 = np.percentile(lengths, 20)\n",
    "        Q3 = np.percentile(lengths, 75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Calcul du seuil basé sur l'IQR\n",
    "        threshold = Q1 - iqr_factor * IQR\n",
    "        adjusted_iqr_factor = iqr_factor\n",
    "        while threshold <= 0 and adjusted_iqr_factor > 0.1:  # Réduire le facteur jusqu'à obtenir un seuil positif\n",
    "            adjusted_iqr_factor /= 2\n",
    "            threshold = Q1 - adjusted_iqr_factor * IQR\n",
    "\n",
    "        if threshold <= 0:  # En dernier recours, utiliser une fraction de Q1\n",
    "            threshold = Q1 * 0.5\n",
    "            print(f\"Seuil ajusté manuellement à une fraction de Q1 : {threshold:.2f}\")\n",
    "\n",
    "        # Stockage du seuil dans la variable globale\n",
    "        seuils[interval] = threshold\n",
    "        print(f\"Seuil pour {interval}: {threshold:.2f}\")\n",
    "\n",
    "        # Affichage du top-N des fichiers les plus courts\n",
    "        file_stats.sort()\n",
    "        print(f\"Top-{top_n} fichiers pour l'intervalle {interval} :\")\n",
    "        for num_lines, filename in file_stats[:top_n]:\n",
    "            print(f\"{filename}: {num_lines} lignes\")\n",
    "\n",
    "        # Calcul du nombre de fichiers à conserver et à supprimer\n",
    "        files_to_keep = [num_lines for num_lines, _ in file_stats if num_lines >= threshold]\n",
    "        files_to_delete = [num_lines for num_lines, _ in file_stats if num_lines < threshold]\n",
    "\n",
    "        print(f\"Nombre de fichiers à conserver : {len(files_to_keep)}\")\n",
    "        print(f\"Nombre de fichiers à supprimer : {len(files_to_delete)}\")\n",
    "\n",
    "        # Plot des longueurs de fichiers avec le seuil\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(len(lengths)), np.sort(lengths), label='Longueur des fichiers (triée)')\n",
    "        plt.axhline(y=threshold, color='red', linestyle='--', label=f'Seuil ajusté: {threshold:.2f}')\n",
    "        \n",
    "        # Ajouter une ligne verticale pour séparer les fichiers conservés et supprimés\n",
    "        plt.axvline(x=len(files_to_delete), color='green', linestyle='--', label=f'Fichiers supprimés : {len(files_to_delete)}')\n",
    "\n",
    "        plt.title(f'Distribution des longueurs des fichiers dans {interval}')\n",
    "        plt.xlabel('Fichiers (triés)')\n",
    "        plt.ylabel('Nombre de lignes')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Exemple d'exécution\n",
    "analyze_and_plot_csv_files_by_iqr(DATA_DIR, INTERVALS, iqr_factor=1.5, top_n=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_valid_csv_files(data_dir, intervals, seuils, data_dir_enough_data):\n",
    "    \"\"\"\n",
    "    Copie les fichiers CSV dont le nombre de lignes est supérieur au seuil respectif dans un dossier cible.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Dossier contenant les sous-dossiers d'intervalles.\n",
    "        intervals (list): Liste des sous-dossiers à traiter.\n",
    "        seuils (dict): Dictionnaire contenant les seuils calculés pour chaque intervalle.\n",
    "        data_dir_enough_data (str): Dossier où les fichiers valides seront copiés.\n",
    "    \"\"\"\n",
    "    for interval in intervals:\n",
    "        folder_path = os.path.join(data_dir, interval)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Le dossier {folder_path} n'existe pas.\")\n",
    "            continue\n",
    "\n",
    "        # Créer le dossier cible si nécessaire\n",
    "        target_folder_path = os.path.join(data_dir_enough_data, interval)\n",
    "        os.makedirs(target_folder_path, exist_ok=True)\n",
    "\n",
    "        print(f\"\\nTraitement des fichiers dans l'intervalle : {interval}\")\n",
    "\n",
    "        if interval not in seuils:\n",
    "            print(f\"Aucun seuil trouvé pour l'intervalle {interval}.\")\n",
    "            continue\n",
    "\n",
    "        threshold = seuils[interval]\n",
    "        print(f\"Seuil pour {interval}: {threshold:.2f}\")\n",
    "\n",
    "        # Lecture des fichiers et comptage des lignes\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path) and filename.endswith('.csv'):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        num_lines = sum(1 for _ in f) - 1  # Ignorer l'en-tête\n",
    "                    # Si le fichier a plus de lignes que le seuil, le copier\n",
    "                    if num_lines >= threshold:\n",
    "                        target_file_path = os.path.join(target_folder_path, filename)\n",
    "                        shutil.copy(file_path, target_file_path)  # Copier le fichier\n",
    "                        #print(f\"Fichier copié : {file_path} vers {target_file_path} ({num_lines} lignes)\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur de lecture du fichier {file_path}: {e}\")\n",
    "\n",
    "# Exemple d'exécution\n",
    "\n",
    "DATA_DIR_ENOUGH_DATA = 'datasets_enough_data'  # Dossier cible pour les données suffisamment longues\n",
    "copy_valid_csv_files(DATA_DIR, INTERVALS, seuils, DATA_DIR_ENOUGH_DATA)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR_ENOUGH_DATA = 'datasets_enough_data'\n",
    "TECH_DATA_DIR = 'datasets_technicals'\n",
    "os.makedirs(DATA_DIR_ENOUGH_DATA, exist_ok=True)\n",
    "os.makedirs(TECH_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Liste pour stocker les erreurs\n",
    "error_list = []\n",
    "\n",
    "\n",
    "# Fonction pour charger les données en tenant compte du nom de la colonne de date\n",
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    Charge les données CSV et standardise les colonnes de date à 'Date'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if os.path.getsize(filename) == 0:\n",
    "            print(f\"Le fichier {filename} est vide.\")\n",
    "            return None\n",
    "\n",
    "        # Charger d'abord sans parse_dates pour identifier la colonne de date\n",
    "        df = pd.read_csv(filename)\n",
    "        \n",
    "        # Identifier la colonne de date potentielle\n",
    "        date_column = None\n",
    "        for col in df.columns:\n",
    "            if col.lower() in ['date', 'datetime', 'time', 'timestamp']:\n",
    "                date_column = col\n",
    "                break\n",
    "        \n",
    "        # Si aucune colonne de date évidente n'est trouvée, essayer la première colonne\n",
    "        if not date_column and len(df.columns) > 0:\n",
    "            # Tenter de convertir la première colonne en datetime\n",
    "            try:\n",
    "                pd.to_datetime(df.iloc[:, 0])\n",
    "                date_column = df.columns[0]\n",
    "            except:\n",
    "                print(f\"Impossible de trouver une colonne de date dans {filename}\")\n",
    "                return None\n",
    "        \n",
    "        # Renommer la colonne identifiée en 'Date' si nécessaire\n",
    "        if date_column and date_column != 'Date':\n",
    "            df.rename(columns={date_column: 'Date'}, inplace=True)\n",
    "        \n",
    "        # Convertir la colonne Date en datetime\n",
    "        if 'Date' in df.columns:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "        else:\n",
    "            print(f\"Aucune colonne 'Date' trouvée ou créée dans {filename}\")\n",
    "            return None\n",
    "\n",
    "        # Nettoyage des données - supprimer les lignes avant la première valeur valide de Close\n",
    "        if 'Close' in df.columns:\n",
    "            first_valid_index = df['Close'].first_valid_index()\n",
    "            if first_valid_index is not None:\n",
    "                df = df.loc[first_valid_index:].reset_index(drop=True)\n",
    "            else:\n",
    "                print(f\"Aucune valeur valide trouvée dans la colonne 'Close' de {filename}.\")\n",
    "                return None\n",
    "\n",
    "        # Définir Date comme index du DataFrame\n",
    "        df.set_index('Date', inplace=True)\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        error_list.append((filename, f\"Erreur lors du chargement: {str(e)}\"))\n",
    "        print(f\"Erreur lors du chargement de {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "################### ################### ################### ###################  \n",
    "    \n",
    "    \n",
    "# Optimisation des calculs d'indicateurs\n",
    "def compute_indicators(df):\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "# RSI14:\n",
    "    def compute_rsi(series, period=14):\n",
    "        #Calcule le RSI en s'assurant que la série n'a pas de valeurs manquantes.\n",
    "        # Supprime les NaN pour éviter des erreurs dans le calcul\n",
    "        series = series.dropna()\n",
    "        delta = series.diff()  # Différence entre les prix consécutifs\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()  # Gains\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()  # Pertes\n",
    "        rs = gain / loss  # Rapport des gains et des pertes\n",
    "        rsi = 100 - (100 / (1 + rs))  # Calcul du RSI\n",
    "        # Réindexer pour conserver la structure du DataFrame d'origine\n",
    "        rsi = rsi.reindex(series.index)\n",
    "        return rsi\n",
    "    # Calcul du RSI et ajout au DataFrame\n",
    "    df['RSI14'] = compute_rsi(df['Close'])\n",
    "\n",
    "\n",
    "# Stochastiques:\n",
    "    def compute_stochastic(high, low, close, k_period=14, d_period=3):\n",
    "        # Supprimez les NaN pour éviter des erreurs dans le calcul\n",
    "        high, low, close = high.dropna(), low.dropna(), close.dropna()\n",
    "        lowest_low = low.rolling(window=k_period).min()\n",
    "        highest_high = high.rolling(window=k_period).max()\n",
    "        k = 100 * (close - lowest_low) / (highest_high - lowest_low)\n",
    "        d = k.rolling(window=d_period).mean()\n",
    "        # Réindexer pour conserver la structure du DataFrame d'origine\n",
    "        k, d = k.reindex(close.index), d.reindex(close.index)\n",
    "        return k, d\n",
    "    df['Stochastic_K14'], df['Stochastic_D14'] = compute_stochastic(\n",
    "        df['High'], df['Low'], df['Close']\n",
    "    )\n",
    "\n",
    "# Mean Reversion Channel:\n",
    "    rolling_mean = df['Close'].dropna().rolling(window=20).mean().reindex(df.index)\n",
    "    rolling_std = df['Close'].dropna().rolling(window=20).std().reindex(df.index)\n",
    "    df['MRC_Upper'] = rolling_mean + 2 * rolling_std\n",
    "    df['MRC_Lower'] = rolling_mean - 2 * rolling_std\n",
    "\n",
    "# SMA:\n",
    "    for period in [10, 20, 50, 100, 200]:\n",
    "        df[f'SMA{period}'] = df['Close'].dropna().rolling(window=period).mean().reindex(df.index)\n",
    "        \n",
    "# EMA:\n",
    "    def compute_ema(series, span):\n",
    "        series = series.dropna()\n",
    "        ema = series.ewm(span=span, adjust=False).mean()\n",
    "        return ema.reindex(series.index)\n",
    "    for span in [10, 20, 50]:\n",
    "        df[f'EMA{span}'] = compute_ema(df['Close'], span)\n",
    "\n",
    "#Volatility:\n",
    "    \n",
    "        # Volatilité :\n",
    "    def compute_volatility(series, window):\n",
    "        series = series.dropna()\n",
    "        return series.pct_change().rolling(window=window).std() * np.sqrt(window)\n",
    "    for window in [20, 50, 100, 360]:\n",
    "        df[f'Volatility{window}'] = compute_volatility(df['Close'], window)\n",
    "\n",
    "        \n",
    "        \n",
    "# Paramètres pour le Monte Carlo (méthode de Heston)\n",
    "    # Calcul des rendements journaliers moyens pour le modèle GBM\n",
    "    df['log_return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    df['mu'] = df['log_return'].mean()  # Taux de rendement moyen\n",
    "\n",
    "    def compute_heston_params(df):\n",
    "        try:\n",
    "            volatility_100 = df['Volatility100'].dropna()\n",
    "            volatility_360 = df['Volatility360'].dropna()\n",
    "\n",
    "            if len(volatility_100) < 10 or len(volatility_360) < 10:\n",
    "                return np.nan, np.nan, np.nan\n",
    "\n",
    "            ema_volatility_100 = volatility_100.ewm(span=100, adjust=False).mean()\n",
    "            ema_volatility_360 = volatility_360.ewm(span=360, adjust=False).mean()\n",
    "\n",
    "            theta = np.mean([ema_volatility_100.iloc[-1], ema_volatility_360.iloc[-1]])\n",
    "            sigma_v = np.std(volatility_360)\n",
    "            kappa = min(max(1 / np.mean(volatility_360.pct_change().dropna()), 0.1), 10)\n",
    "\n",
    "            return theta, sigma_v, kappa\n",
    "        except Exception as e:\n",
    "            print(f\"Error computing Heston params: {e}\")\n",
    "            return np.nan, np.nan, np.nan\n",
    "\n",
    "    # Calcul des paramètres pour Heston\n",
    "    theta, sigma_v, kappa = compute_heston_params(df)\n",
    "    df['theta'] = theta\n",
    "    df['sigma_v'] = sigma_v\n",
    "    df['kappa'] = kappa\n",
    "\n",
    "\n",
    "        \n",
    "#Momentum(%):\n",
    "    def compute_momentum(df, periods):\n",
    "        for period in periods:\n",
    "            df['Close'] = df['Close'].ffill()  # Remplir les NaN en avant\n",
    "            df[f'Momentum{period}'] = df['Close'].pct_change(periods=period) * 100\n",
    "    compute_momentum(df, [20, 50, 100, 252, 360])\n",
    "\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "################### ################### ################### ###################  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fonction pour traiter un ticker et un intervalle\n",
    "def process_data_for_ticker_and_interval(ticker, interval):\n",
    "    source_path = os.path.join(DATA_DIR_ENOUGH_DATA, interval, f\"{ticker}.csv\")\n",
    "    if not os.path.exists(source_path):\n",
    "        error_list.append((ticker, interval, \"Fichier manquant\"))\n",
    "        #print(f\"Fichier manquant pour {ticker} : {source_path}\")\n",
    "        return\n",
    "\n",
    "    df = load_data(source_path)\n",
    "    if df is None:\n",
    "        error_list.append((ticker, interval, \"Erreur lors du chargement\"))\n",
    "        return\n",
    "    df.name = ticker # Assigner un nom au DataFrame\n",
    "\n",
    "    # Calcul des indicateurs\n",
    "    df_with_indicators = compute_indicators(df)\n",
    "\n",
    "    # Sauvegarder les données modifiées dans le sous-dossier TECH_DATA_DIR\n",
    "    if df_with_indicators is not None:\n",
    "        destination_path = os.path.join(TECH_DATA_DIR, interval, f\"{ticker}.csv\")\n",
    "        os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n",
    "        df_with_indicators.to_csv(destination_path)\n",
    "    else:\n",
    "        print(f\"Aucun indicateur calculé pour {ticker}, DataFrame vide.\")\n",
    "        \n",
    "def process_all_data():\n",
    "    print(f\"INTERVALS définis: {INTERVALS}\")\n",
    "    for interval in INTERVALS:\n",
    "        interval_path = os.path.join(DATA_DIR_ENOUGH_DATA, interval)\n",
    "        if not os.path.exists(interval_path):\n",
    "            print(f\"Le dossier {interval_path} n'existe pas.\")\n",
    "            continue\n",
    "        \n",
    "        # Obtenir la liste des fichiers réellement présents dans le dossier\n",
    "        csv_files = [f[:-4] for f in os.listdir(interval_path) if f.endswith('.csv')]\n",
    "        file_count = len(csv_files)\n",
    "        print(f\"Traitement des données pour l'intervalle : {interval}, {file_count} fichiers trouvés\")\n",
    "        \n",
    "        # Créer le dossier de destination s'il n'existe pas\n",
    "        os.makedirs(os.path.join(TECH_DATA_DIR, interval), exist_ok=True)\n",
    "\n",
    "        # Créer un compteur de réussite/échec\n",
    "        success_count = 0\n",
    "        error_count = 0\n",
    "               \n",
    "        # Continuer avec le traitement parallèle\n",
    "        results = Parallel(n_jobs=-1)(\n",
    "            delayed(process_data_for_ticker_and_interval)(ticker, interval)\n",
    "            for ticker in tqdm(csv_files, desc=f\"Traitement pour {interval}\")\n",
    "        )\n",
    "        \n",
    "        # Vérifier le résultat final\n",
    "        dest_path = os.path.join(TECH_DATA_DIR, interval)\n",
    "        dest_files = len([f for f in os.listdir(dest_path) if f.endswith('.csv')])\n",
    "        print(f\"Intervalle {interval}: {file_count} fichiers sources, {dest_files} fichiers traités\")\n",
    "\n",
    "\n",
    "# Lancer le traitement\n",
    "process_all_data()\n",
    "\n",
    "# À ajouter à la fin de votre script\n",
    "for interval in INTERVALS:\n",
    "    source_path = os.path.join(DATA_DIR_ENOUGH_DATA, interval)\n",
    "    dest_path = os.path.join(TECH_DATA_DIR, interval)\n",
    "    \n",
    "    if os.path.exists(source_path) and os.path.exists(dest_path):\n",
    "        source_files = len([f for f in os.listdir(source_path) if f.endswith('.csv')])\n",
    "        dest_files = len([f for f in os.listdir(dest_path) if f.endswith('.csv')])\n",
    "        \n",
    "        print(f\"Intervalle {interval}: {source_files} fichiers sources, {dest_files} fichiers traités\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324712a2-e513-403c-9107-02dceb3416cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_INTERVAL = '1d'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "#DATA_INTERVAL='1d'\n",
    "\n",
    "def plot_simple_coverage(data_dir, interval):\n",
    "    \"\"\"\n",
    "    Crée un plot simple montrant toutes les dates de tous les fichiers,\n",
    "    triés par nombre de dates croissant.\n",
    "    \"\"\"\n",
    "    folder_path = os.path.join(data_dir, interval)\n",
    "    \n",
    "    # Collecter les informations de dates pour chaque ticker\n",
    "    ticker_info = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            ticker = filename[:-4]\n",
    "            df = pd.read_csv(os.path.join(folder_path, filename))\n",
    "            dates = pd.to_datetime(df['Date'])\n",
    "            ticker_info.append({\n",
    "                'ticker': ticker,\n",
    "                'start': dates.min(),\n",
    "                'end': dates.max(),\n",
    "                'count': len(dates)\n",
    "            })\n",
    "    \n",
    "    # Trier par nombre de dates\n",
    "    ticker_info = sorted(ticker_info, key=lambda x: -x['count'])\n",
    "    \n",
    "    plt.figure(figsize=(20, max(10, len(ticker_info)/4)))\n",
    "    \n",
    "    # Tracer les lignes dans l'ordre trié\n",
    "    for i, info in enumerate(ticker_info):\n",
    "        plt.plot([info['start'], info['end']], [i, i], '-', \n",
    "                linewidth=2, label=info['ticker'])\n",
    "    \n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.title(f'Couverture temporelle par ticker ({interval})\\nTrié par nombre de dates croissant')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Ticker')\n",
    "    plt.yticks(range(len(ticker_info)), \n",
    "               [f\"{info['ticker']} ({info['count']})\" for info in ticker_info])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt.gcf()\n",
    "\n",
    "# Créer la visualisation\n",
    "fig = plot_simple_coverage(TECH_DATA_DIR, DATA_INTERVAL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f4050a-fb9b-44e9-bda9-c1d6ab41fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    filename='csv_to_parquet.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "def convert_csv_to_parquet(csv_file, output_dir, date_columns=None):\n",
    "    \"\"\"Convert a single CSV file to Parquet format, overwriting existing files.\"\"\"\n",
    "    try:\n",
    "        # Create output Parquet path\n",
    "        parquet_file = os.path.join(output_dir, os.path.splitext(os.path.basename(csv_file))[0] + '.parquet')\n",
    "\n",
    "        # Read CSV with date index and optional date columns\n",
    "        parse_dates = [0]  # Index is always parsed as date\n",
    "        if date_columns:\n",
    "            parse_dates.extend(date_columns)\n",
    "        \n",
    "        df = pd.read_csv(\n",
    "            csv_file,\n",
    "            index_col=0,\n",
    "            parse_dates=parse_dates\n",
    "        )\n",
    "        \n",
    "        # Convert to Parquet (overwrites existing file)\n",
    "        table = pa.Table.from_pandas(df, preserve_index=True)\n",
    "        pq.write_table(table, parquet_file, compression='snappy')  # Use compression=None for max speed\n",
    "        \n",
    "        msg = f\"Converted {csv_file} to {parquet_file}\"\n",
    "        logging.info(msg)\n",
    "        return msg\n",
    "    except Exception as e:\n",
    "        msg = f\"Error converting {csv_file}: {str(e)}\"\n",
    "        logging.error(msg)\n",
    "        return msg\n",
    "\n",
    "def worker(task):\n",
    "    \"\"\"Worker function to unpack task arguments and call convert_csv_to_parquet.\"\"\"\n",
    "    csv_file, output_dir, date_columns = task\n",
    "    return convert_csv_to_parquet(csv_file, output_dir, date_columns)\n",
    "\n",
    "def precreate_directories(source_subfolder, source_root, target_root):\n",
    "    \"\"\"Pre-create all target directories to reduce concurrent disk operations.\"\"\"\n",
    "    relative_path = os.path.relpath(source_subfolder, source_root)\n",
    "    target_dir = os.path.join(target_root, relative_path)\n",
    "    \n",
    "    for root, _, _ in os.walk(source_subfolder):\n",
    "        relative_subpath = os.path.relpath(root, source_subfolder)\n",
    "        output_subdir = os.path.join(target_dir, relative_subpath)\n",
    "        os.makedirs(output_subdir, exist_ok=True)\n",
    "\n",
    "def process_subfolder(subfolder, source_root, target_root, date_columns):\n",
    "    \"\"\"Process all CSV files in a subfolder and its subdirectories.\"\"\"\n",
    "    relative_path = os.path.relpath(subfolder, source_root)\n",
    "    target_dir = os.path.join(target_root, relative_path)\n",
    "    \n",
    "    tasks = []\n",
    "    for root, _, files in os.walk(subfolder):\n",
    "        relative_subpath = os.path.relpath(root, subfolder)\n",
    "        output_subdir = os.path.join(target_dir, relative_subpath)\n",
    "        \n",
    "        for file in files:\n",
    "            if file.lower().endswith('.csv'):\n",
    "                csv_file = os.path.join(root, file)\n",
    "                tasks.append((csv_file, output_subdir, date_columns))\n",
    "    \n",
    "    return tasks\n",
    "\n",
    "def main():\n",
    "    source_root = r\"C:\\Users\\Alex\\Python\\Finance\\@@@ Downloader @@@\"\n",
    "    target_root = r\"C:\\Users\\Alex\\Python\\Finance\\@@@ Downloader @@@\\parquet\"\n",
    "    \n",
    "    # Find all subfolders starting with 'datasets'\n",
    "    dataset_folders = [\n",
    "        os.path.join(source_root, d) \n",
    "        for d in os.listdir(source_root) \n",
    "        if os.path.isdir(os.path.join(source_root, d)) and d.startswith('datasets')\n",
    "    ]\n",
    "    \n",
    "    # Optional: Specify additional date columns\n",
    "    date_columns = None  # Example: ['date_column1', 'date_column2']\n",
    "    \n",
    "    # Collect all conversion tasks\n",
    "    all_tasks = []\n",
    "    for folder in dataset_folders:\n",
    "        # Pre-create directories for this folder\n",
    "        precreate_directories(folder, source_root, target_root)\n",
    "        # Collect tasks for all CSV files in this folder and its subdirectories\n",
    "        tasks = process_subfolder(folder, source_root, target_root, date_columns)\n",
    "        all_tasks.extend(tasks)\n",
    "    \n",
    "    # Process conversions in parallel with threads\n",
    "    max_workers = 8  # Optimized for SSD and stability\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Use tqdm to display progress bar\n",
    "        results = tqdm(\n",
    "            executor.map(worker, all_tasks),\n",
    "            total=len(all_tasks),\n",
    "            desc=\"Converting CSV to Parquet\",\n",
    "            unit=\"file\"\n",
    "        )\n",
    "        \n",
    "        # Print only error messages\n",
    "        for result in results:\n",
    "            if result.startswith(\"Error\"):\n",
    "                print(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18c75c1-ace9-467f-8985-8d8c52cf045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    filename='csv_to_parquet.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "def convert_csv_to_parquet(csv_file, output_dir, date_format=None):\n",
    "    \"\"\"\n",
    "    Convert a single CSV file to Parquet format with proper date handling.\n",
    "    \n",
    "    Args:\n",
    "        csv_file: Path to CSV file\n",
    "        output_dir: Directory to save Parquet file\n",
    "        date_format: Optional explicit date format string (e.g., '%Y-%m-%d %H:%M:%S')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output Parquet path\n",
    "        parquet_file = os.path.join(output_dir, os.path.splitext(os.path.basename(csv_file))[0] + '.parquet')\n",
    "        \n",
    "        # Read CSV with DatetimeIndex \n",
    "        try:\n",
    "            # Try with inferred date format first\n",
    "            df = pd.read_csv(\n",
    "                csv_file,\n",
    "                index_col=0,\n",
    "                parse_dates=[0]\n",
    "            )\n",
    "        except:\n",
    "            # If that fails, try with explicit date_parser\n",
    "            df = pd.read_csv(\n",
    "                csv_file,\n",
    "                index_col=0\n",
    "            )\n",
    "            # Convert index to datetime with custom parser that handles various formats\n",
    "            df.index = pd.to_datetime(df.index, errors='coerce', format=date_format)\n",
    "        \n",
    "        # Check if we have a proper DatetimeIndex\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            raise ValueError(f\"Index could not be converted to DatetimeIndex in {csv_file}\")\n",
    "        \n",
    "        # Handle any NaT (Not a Time) in the index\n",
    "        if df.index.isna().any():\n",
    "            logging.warning(f\"Found {df.index.isna().sum()} NaT values in index for {csv_file}\")\n",
    "            df = df[~df.index.isna()]  # Remove rows with NaT index\n",
    "        \n",
    "        # Validate date range - Flag very old dates (pre-2010) as potentially invalid\n",
    "        if df.index.min().year < 2010:\n",
    "            logging.warning(f\"Very old dates detected in {csv_file}: min={df.index.min()}\")\n",
    "        \n",
    "        # Remove timezone info if present (for consistent handling)\n",
    "        if df.index.tz is not None:\n",
    "            df.index = df.index.tz_localize(None)\n",
    "        \n",
    "        # Sort by date index to ensure time series are properly ordered\n",
    "        df = df.sort_index()\n",
    "        \n",
    "        # Convert all numeric columns to float32 for efficiency\n",
    "        for col in df.select_dtypes(include=['float64']).columns:\n",
    "            df[col] = df[col].astype('float32')\n",
    "        \n",
    "        # Convert to Parquet (overwrites existing file)\n",
    "        table = pa.Table.from_pandas(df, preserve_index=True)\n",
    "        pq.write_table(table, parquet_file, compression='snappy')\n",
    "        \n",
    "        msg = f\"Converted {csv_file} to {parquet_file} - Date range: {df.index.min()} to {df.index.max()}\"\n",
    "        logging.info(msg)\n",
    "        return msg\n",
    "    except Exception as e:\n",
    "        msg = f\"Error converting {csv_file}: {str(e)}\"\n",
    "        logging.error(msg)\n",
    "        return msg\n",
    "\n",
    "def worker(task):\n",
    "    \"\"\"Worker function to unpack task arguments and call convert_csv_to_parquet.\"\"\"\n",
    "    csv_file, output_dir, date_format = task\n",
    "    return convert_csv_to_parquet(csv_file, output_dir, date_format)\n",
    "\n",
    "def precreate_directories(source_subfolder, source_root, target_root):\n",
    "    \"\"\"Pre-create all target directories to reduce concurrent disk operations.\"\"\"\n",
    "    relative_path = os.path.relpath(source_subfolder, source_root)\n",
    "    target_dir = os.path.join(target_root, relative_path)\n",
    "    \n",
    "    for root, _, _ in os.walk(source_subfolder):\n",
    "        relative_subpath = os.path.relpath(root, source_subfolder)\n",
    "        output_subdir = os.path.join(target_dir, relative_subpath)\n",
    "        os.makedirs(output_subdir, exist_ok=True)\n",
    "\n",
    "def process_subfolder(subfolder, source_root, target_root, date_format):\n",
    "    \"\"\"Process all CSV files in a subfolder and its subdirectories.\"\"\"\n",
    "    relative_path = os.path.relpath(subfolder, source_root)\n",
    "    target_dir = os.path.join(target_root, relative_path)\n",
    "    if '.ipynb_checkpoints' in root:\n",
    "        continue\n",
    "    tasks = []\n",
    "    for root, _, files in os.walk(subfolder):\n",
    "        relative_subpath = os.path.relpath(root, subfolder)\n",
    "        output_subdir = os.path.join(target_dir, relative_subpath)\n",
    "        \n",
    "        for file in files:\n",
    "            if file.lower().endswith('.csv'):\n",
    "                csv_file = os.path.join(root, file)\n",
    "                tasks.append((csv_file, output_subdir, date_format))\n",
    "    \n",
    "    return tasks\n",
    "\n",
    "def validate_dataset_dates(source_root):\n",
    "    \"\"\"Perform a quick scan of CSV files to validate date formats.\"\"\"\n",
    "    sample_files = []\n",
    "    date_formats = []\n",
    "    \n",
    "    # Find a few sample CSV files from different subdirectories\n",
    "    for root, _, files in os.walk(source_root):\n",
    "        csv_files = [f for f in files if f.lower().endswith('.csv')]\n",
    "        if csv_files:\n",
    "            sample_files.append(os.path.join(root, csv_files[0]))\n",
    "            if len(sample_files) >= 5:  # Check 5 samples\n",
    "                break\n",
    "    \n",
    "    print(f\"Validating date formats in {len(sample_files)} sample files:\")\n",
    "    \n",
    "    for file in sample_files:\n",
    "        try:\n",
    "            # Read just the first few rows to check date format\n",
    "            df = pd.read_csv(file, nrows=5)\n",
    "            date_col = df.columns[0]\n",
    "            \n",
    "            # Display sample dates\n",
    "            sample_dates = df[date_col].iloc[0]\n",
    "            print(f\"  {file} - Sample date: {sample_dates}\")\n",
    "            \n",
    "            # Try to parse with pandas\n",
    "            parsed_date = pd.to_datetime(sample_dates)\n",
    "            date_formats.append(parsed_date.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error checking {file}: {str(e)}\")\n",
    "    \n",
    "    # Return the most common date format detected\n",
    "    return date_formats[0] if date_formats else None\n",
    "\n",
    "def main():\n",
    "    source_root = r\"C:\\Users\\Alex\\Python\\Finance\\@@@ Downloader @@@\"\n",
    "    target_root = r\"C:\\Users\\Alex\\Python\\Finance\\@@@ Downloader @@@\\parquet\"\n",
    "    \n",
    "    # Find all subfolders starting with 'datasets'\n",
    "    dataset_folders = [\n",
    "        os.path.join(source_root, d) \n",
    "        for d in os.listdir(source_root) \n",
    "        if os.path.isdir(os.path.join(source_root, d)) and d.startswith('datasets')\n",
    "    ]\n",
    "    \n",
    "    print(f\"Found {len(dataset_folders)} dataset folders\")\n",
    "    \n",
    "    # Validate date formats in sample files\n",
    "    print(\"Analyzing date formats in sample files...\")\n",
    "    inferred_date_format = validate_dataset_dates(source_root)\n",
    "    print(f\"Inferred date format: {inferred_date_format}\")\n",
    "    \n",
    "    # Collect all conversion tasks\n",
    "    all_tasks = []\n",
    "    for folder in dataset_folders:\n",
    "        # Pre-create directories for this folder\n",
    "        precreate_directories(folder, source_root, target_root)\n",
    "        # Collect tasks for all CSV files in this folder and its subdirectories\n",
    "        tasks = process_subfolder(folder, source_root, target_root, inferred_date_format)\n",
    "        all_tasks.extend(tasks)\n",
    "    \n",
    "    print(f\"Found {len(all_tasks)} CSV files to convert\")\n",
    "    \n",
    "    # Process conversions in parallel with threads\n",
    "    max_workers = min(8, os.cpu_count())  # Optimized for SSD and stability\n",
    "    print(f\"Using {max_workers} worker threads\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Use tqdm to display progress bar\n",
    "        results = list(tqdm(\n",
    "            executor.map(worker, all_tasks),\n",
    "            total=len(all_tasks),\n",
    "            desc=\"Converting CSV to Parquet\",\n",
    "            unit=\"file\"\n",
    "        ))\n",
    "        \n",
    "        # Print summary statistics\n",
    "        errors = [r for r in results if r.startswith(\"Error\")]\n",
    "        print(f\"Conversion complete: {len(results)} files processed, {len(errors)} errors\")\n",
    "        \n",
    "        # Print up to 10 error messages\n",
    "        if errors:\n",
    "            print(\"Sample errors:\")\n",
    "            for error in errors[:10]:\n",
    "                print(f\"  {error}\")\n",
    "            if len(errors) > 10:\n",
    "                print(f\"  ...and {len(errors) - 10} more errors\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b553447-c65d-46c6-9454-4023a7cce9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "def verify_parquet_conversion():\n",
    "    parquet_root = r\"C:\\Users\\Alex\\Python\\Finance\\@@@ Downloader @@@\\parquet\"\n",
    "    \n",
    "    # Trouver tous les fichiers parquet récursivement\n",
    "    parquet_files = list(Path(parquet_root).rglob(\"*.parquet\"))\n",
    "    print(f\"Trouvé {len(parquet_files)} fichiers parquet\")\n",
    "    \n",
    "    # Prendre un échantillon aléatoire de 10 fichiers\n",
    "    sample_files = random.sample(parquet_files, min(10, len(parquet_files)))\n",
    "    \n",
    "    for file in sample_files:\n",
    "        try:\n",
    "            df = pd.read_parquet(file)\n",
    "            print(f\"\\nVérification de {file.name}:\")\n",
    "            print(f\"  Dimensions: {df.shape}\")\n",
    "            print(f\"  Type d'index: {type(df.index)}\")\n",
    "            print(f\"  Plage de dates: {df.index.min()} à {df.index.max()}\")\n",
    "            print(f\"  Premières colonnes: {list(df.columns)[:5]}\")\n",
    "            \n",
    "            # Vérifier les problèmes potentiels\n",
    "            if not isinstance(df.index, pd.DatetimeIndex):\n",
    "                print(\"  ⚠️ PROBLÈME: L'index n'est pas de type DatetimeIndex\")\n",
    "            if df.index.tz is not None:\n",
    "                print(f\"  ⚠️ PROBLÈME: L'index contient un fuseau horaire ({df.index.tz})\")\n",
    "            if df.index.min().year < 2000:\n",
    "                print(f\"  ⚠️ NOTE: Dates anciennes détectées ({df.index.min().year})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la vérification de {file}: {e}\")\n",
    "    \n",
    "    print(\"\\nVérification terminée\")\n",
    "\n",
    "verify_parquet_conversion()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_gpu]",
   "language": "python",
   "name": "conda-env-pytorch_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
